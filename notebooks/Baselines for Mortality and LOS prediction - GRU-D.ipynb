{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "from __future__ import print_function, division"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload\n",
    "\n",
    "import copy, math, os, pickle, time, pandas as pd, numpy as np, scipy.stats as ss\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import average_precision_score, roc_auc_score, accuracy_score, f1_score\n",
    "\n",
    "import torch, torch.utils.data as utils, torch.nn as nn, torch.nn.functional as F, torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from torch.nn.parameter import Parameter\n",
    "\n",
    "\n",
    "from mmd_grud_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x2a8a1fd5af0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dirname = os.getcwd()\n",
    "DATA_FILEPATH     = os.path.join(dirname, \"..\", \"data\", \"all_hourly_data.h5\")\n",
    "RAW_DATA_FILEPATH = os.path.join(dirname, \"..\", \"data\", \"all_hourly_data.h5\")\n",
    "GAP_TIME          = 6  # In hours\n",
    "WINDOW_SIZE       = 24 # In hours\n",
    "SEED              = 1\n",
    "ID_COLS           = ['subject_id', 'hadm_id', 'icustay_id']\n",
    "GPU               = '0'\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = GPU\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DictDist():\n",
    "    def __init__(self, dict_of_rvs): self.dict_of_rvs = dict_of_rvs\n",
    "    def rvs(self, n):\n",
    "        a = {k: v.rvs(n) for k, v in self.dict_of_rvs.items()}\n",
    "        out = []\n",
    "        for i in range(n): out.append({k: vs[i] for k, vs in a.items()})\n",
    "        return out\n",
    "    \n",
    "class Choice():\n",
    "    def __init__(self, options): self.options = options\n",
    "    def rvs(self, n): return [self.options[i] for i in ss.randint(0, len(self.options)).rvs(n)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 21.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "data_full_lvl2 = pd.read_hdf(DATA_FILEPATH, 'vitals_labs')\n",
    "data_full_raw  = pd.read_hdf(RAW_DATA_FILEPATH, 'vitals_labs') \n",
    "statics        = pd.read_hdf(DATA_FILEPATH, 'patients')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>LEVEL2</th>\n",
       "      <th colspan=\"3\" halign=\"left\">alanine aminotransferase</th>\n",
       "      <th colspan=\"3\" halign=\"left\">albumin</th>\n",
       "      <th colspan=\"3\" halign=\"left\">albumin ascites</th>\n",
       "      <th>albumin pleural</th>\n",
       "      <th>...</th>\n",
       "      <th>white blood cell count</th>\n",
       "      <th colspan=\"3\" halign=\"left\">white blood cell count urine</th>\n",
       "      <th colspan=\"3\" halign=\"left\">ph</th>\n",
       "      <th colspan=\"3\" halign=\"left\">ph urine</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Aggregation Function</th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>count</th>\n",
       "      <th>...</th>\n",
       "      <th>std</th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subject_id</th>\n",
       "      <th>hadm_id</th>\n",
       "      <th>icustay_id</th>\n",
       "      <th>hours_in</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">3</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">145834</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">211552</th>\n",
       "      <th>0</th>\n",
       "      <td>2.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.012837</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.0</td>\n",
       "      <td>7.40</td>\n",
       "      <td>0.147733</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.26</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 312 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "LEVEL2                                 alanine aminotransferase             \\\n",
       "Aggregation Function                                      count  mean  std   \n",
       "subject_id hadm_id icustay_id hours_in                                       \n",
       "3          145834  211552     0                             2.0  25.0  0.0   \n",
       "                              1                             0.0   NaN  NaN   \n",
       "                              2                             0.0   NaN  NaN   \n",
       "                              3                             0.0   NaN  NaN   \n",
       "                              4                             0.0   NaN  NaN   \n",
       "\n",
       "LEVEL2                                 albumin           albumin ascites       \\\n",
       "Aggregation Function                     count mean  std           count mean   \n",
       "subject_id hadm_id icustay_id hours_in                                          \n",
       "3          145834  211552     0            2.0  1.8  0.0             0.0  NaN   \n",
       "                              1            0.0  NaN  NaN             0.0  NaN   \n",
       "                              2            0.0  NaN  NaN             0.0  NaN   \n",
       "                              3            0.0  NaN  NaN             0.0  NaN   \n",
       "                              4            0.0  NaN  NaN             0.0  NaN   \n",
       "\n",
       "LEVEL2                                     albumin pleural  ...  \\\n",
       "Aggregation Function                   std           count  ...   \n",
       "subject_id hadm_id icustay_id hours_in                      ...   \n",
       "3          145834  211552     0        NaN             0.0  ...   \n",
       "                              1        NaN             0.0  ...   \n",
       "                              2        NaN             0.0  ...   \n",
       "                              3        NaN             0.0  ...   \n",
       "                              4        NaN             0.0  ...   \n",
       "\n",
       "LEVEL2                                 white blood cell count  \\\n",
       "Aggregation Function                                      std   \n",
       "subject_id hadm_id icustay_id hours_in                          \n",
       "3          145834  211552     0                      4.012837   \n",
       "                              1                           NaN   \n",
       "                              2                           NaN   \n",
       "                              3                           NaN   \n",
       "                              4                           NaN   \n",
       "\n",
       "LEVEL2                                 white blood cell count urine           \\\n",
       "Aggregation Function                                          count mean std   \n",
       "subject_id hadm_id icustay_id hours_in                                         \n",
       "3          145834  211552     0                                 0.0  NaN NaN   \n",
       "                              1                                 0.0  NaN NaN   \n",
       "                              2                                 0.0  NaN NaN   \n",
       "                              3                                 0.0  NaN NaN   \n",
       "                              4                                 0.0  NaN NaN   \n",
       "\n",
       "LEVEL2                                    ph                 ph urine           \n",
       "Aggregation Function                   count  mean       std    count mean std  \n",
       "subject_id hadm_id icustay_id hours_in                                          \n",
       "3          145834  211552     0          9.0  7.40  0.147733      1.0  5.0 NaN  \n",
       "                              1          0.0   NaN       NaN      0.0  NaN NaN  \n",
       "                              2          3.0  7.26  0.000000      0.0  NaN NaN  \n",
       "                              3          0.0   NaN       NaN      0.0  NaN NaN  \n",
       "                              4          0.0   NaN       NaN      0.0  NaN NaN  \n",
       "\n",
       "[5 rows x 312 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_full_lvl2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>LEVEL2</th>\n",
       "      <th colspan=\"3\" halign=\"left\">alanine aminotransferase</th>\n",
       "      <th colspan=\"3\" halign=\"left\">albumin</th>\n",
       "      <th colspan=\"3\" halign=\"left\">albumin ascites</th>\n",
       "      <th>albumin pleural</th>\n",
       "      <th>...</th>\n",
       "      <th>white blood cell count</th>\n",
       "      <th colspan=\"3\" halign=\"left\">white blood cell count urine</th>\n",
       "      <th colspan=\"3\" halign=\"left\">ph</th>\n",
       "      <th colspan=\"3\" halign=\"left\">ph urine</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Aggregation Function</th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>count</th>\n",
       "      <th>...</th>\n",
       "      <th>std</th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subject_id</th>\n",
       "      <th>hadm_id</th>\n",
       "      <th>icustay_id</th>\n",
       "      <th>hours_in</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">3</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">145834</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">211552</th>\n",
       "      <th>0</th>\n",
       "      <td>2.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.012837</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.0</td>\n",
       "      <td>7.40</td>\n",
       "      <td>0.147733</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.26</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 312 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "LEVEL2                                 alanine aminotransferase             \\\n",
       "Aggregation Function                                      count  mean  std   \n",
       "subject_id hadm_id icustay_id hours_in                                       \n",
       "3          145834  211552     0                             2.0  25.0  0.0   \n",
       "                              1                             0.0   NaN  NaN   \n",
       "                              2                             0.0   NaN  NaN   \n",
       "                              3                             0.0   NaN  NaN   \n",
       "                              4                             0.0   NaN  NaN   \n",
       "\n",
       "LEVEL2                                 albumin           albumin ascites       \\\n",
       "Aggregation Function                     count mean  std           count mean   \n",
       "subject_id hadm_id icustay_id hours_in                                          \n",
       "3          145834  211552     0            2.0  1.8  0.0             0.0  NaN   \n",
       "                              1            0.0  NaN  NaN             0.0  NaN   \n",
       "                              2            0.0  NaN  NaN             0.0  NaN   \n",
       "                              3            0.0  NaN  NaN             0.0  NaN   \n",
       "                              4            0.0  NaN  NaN             0.0  NaN   \n",
       "\n",
       "LEVEL2                                     albumin pleural  ...  \\\n",
       "Aggregation Function                   std           count  ...   \n",
       "subject_id hadm_id icustay_id hours_in                      ...   \n",
       "3          145834  211552     0        NaN             0.0  ...   \n",
       "                              1        NaN             0.0  ...   \n",
       "                              2        NaN             0.0  ...   \n",
       "                              3        NaN             0.0  ...   \n",
       "                              4        NaN             0.0  ...   \n",
       "\n",
       "LEVEL2                                 white blood cell count  \\\n",
       "Aggregation Function                                      std   \n",
       "subject_id hadm_id icustay_id hours_in                          \n",
       "3          145834  211552     0                      4.012837   \n",
       "                              1                           NaN   \n",
       "                              2                           NaN   \n",
       "                              3                           NaN   \n",
       "                              4                           NaN   \n",
       "\n",
       "LEVEL2                                 white blood cell count urine           \\\n",
       "Aggregation Function                                          count mean std   \n",
       "subject_id hadm_id icustay_id hours_in                                         \n",
       "3          145834  211552     0                                 0.0  NaN NaN   \n",
       "                              1                                 0.0  NaN NaN   \n",
       "                              2                                 0.0  NaN NaN   \n",
       "                              3                                 0.0  NaN NaN   \n",
       "                              4                                 0.0  NaN NaN   \n",
       "\n",
       "LEVEL2                                    ph                 ph urine           \n",
       "Aggregation Function                   count  mean       std    count mean std  \n",
       "subject_id hadm_id icustay_id hours_in                                          \n",
       "3          145834  211552     0          9.0  7.40  0.147733      1.0  5.0 NaN  \n",
       "                              1          0.0   NaN       NaN      0.0  NaN NaN  \n",
       "                              2          3.0  7.26  0.000000      0.0  NaN NaN  \n",
       "                              3          0.0   NaN       NaN      0.0  NaN NaN  \n",
       "                              4          0.0   NaN       NaN      0.0  NaN NaN  \n",
       "\n",
       "[5 rows x 312 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_full_raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>ethnicity</th>\n",
       "      <th>age</th>\n",
       "      <th>insurance</th>\n",
       "      <th>admittime</th>\n",
       "      <th>diagnosis_at_admission</th>\n",
       "      <th>dischtime</th>\n",
       "      <th>discharge_location</th>\n",
       "      <th>fullcode_first</th>\n",
       "      <th>dnr_first</th>\n",
       "      <th>...</th>\n",
       "      <th>outtime</th>\n",
       "      <th>los_icu</th>\n",
       "      <th>admission_type</th>\n",
       "      <th>first_careunit</th>\n",
       "      <th>mort_icu</th>\n",
       "      <th>mort_hosp</th>\n",
       "      <th>hospital_expire_flag</th>\n",
       "      <th>hospstay_seq</th>\n",
       "      <th>readmission_30</th>\n",
       "      <th>max_hours</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subject_id</th>\n",
       "      <th>hadm_id</th>\n",
       "      <th>icustay_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <th>145834</th>\n",
       "      <th>211552</th>\n",
       "      <td>M</td>\n",
       "      <td>WHITE</td>\n",
       "      <td>76.526792</td>\n",
       "      <td>Medicare</td>\n",
       "      <td>2101-10-20 19:08:00</td>\n",
       "      <td>HYPOTENSION</td>\n",
       "      <td>2101-10-31 13:58:00</td>\n",
       "      <td>SNF</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2101-10-26 20:43:09</td>\n",
       "      <td>6.064560</td>\n",
       "      <td>EMERGENCY</td>\n",
       "      <td>MICU</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <th>185777</th>\n",
       "      <th>294638</th>\n",
       "      <td>F</td>\n",
       "      <td>WHITE</td>\n",
       "      <td>47.845047</td>\n",
       "      <td>Private</td>\n",
       "      <td>2191-03-16 00:28:00</td>\n",
       "      <td>FEVER,DEHYDRATION,FAILURE TO THRIVE</td>\n",
       "      <td>2191-03-23 18:41:00</td>\n",
       "      <td>HOME WITH HOME IV PROVIDR</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2191-03-17 16:46:31</td>\n",
       "      <td>1.678472</td>\n",
       "      <td>EMERGENCY</td>\n",
       "      <td>MICU</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <th>107064</th>\n",
       "      <th>228232</th>\n",
       "      <td>F</td>\n",
       "      <td>WHITE</td>\n",
       "      <td>65.942297</td>\n",
       "      <td>Medicare</td>\n",
       "      <td>2175-05-30 07:15:00</td>\n",
       "      <td>CHRONIC RENAL FAILURE/SDA</td>\n",
       "      <td>2175-06-15 16:00:00</td>\n",
       "      <td>HOME HEALTH CARE</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2175-06-03 13:39:54</td>\n",
       "      <td>3.672917</td>\n",
       "      <td>ELECTIVE</td>\n",
       "      <td>SICU</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <th>150750</th>\n",
       "      <th>220597</th>\n",
       "      <td>M</td>\n",
       "      <td>UNKNOWN/NOT SPECIFIED</td>\n",
       "      <td>41.790228</td>\n",
       "      <td>Medicaid</td>\n",
       "      <td>2149-11-09 13:06:00</td>\n",
       "      <td>HEMORRHAGIC CVA</td>\n",
       "      <td>2149-11-14 10:15:00</td>\n",
       "      <td>DEAD/EXPIRED</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2149-11-14 20:52:14</td>\n",
       "      <td>5.323056</td>\n",
       "      <td>EMERGENCY</td>\n",
       "      <td>MICU</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <th>194540</th>\n",
       "      <th>229441</th>\n",
       "      <td>F</td>\n",
       "      <td>WHITE</td>\n",
       "      <td>50.148295</td>\n",
       "      <td>Private</td>\n",
       "      <td>2178-04-16 06:18:00</td>\n",
       "      <td>BRAIN MASS</td>\n",
       "      <td>2178-05-11 19:00:00</td>\n",
       "      <td>HOME HEALTH CARE</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2178-04-17 20:21:05</td>\n",
       "      <td>1.584410</td>\n",
       "      <td>EMERGENCY</td>\n",
       "      <td>SICU</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              gender              ethnicity        age  \\\n",
       "subject_id hadm_id icustay_id                                            \n",
       "3          145834  211552          M                  WHITE  76.526792   \n",
       "4          185777  294638          F                  WHITE  47.845047   \n",
       "6          107064  228232          F                  WHITE  65.942297   \n",
       "9          150750  220597          M  UNKNOWN/NOT SPECIFIED  41.790228   \n",
       "11         194540  229441          F                  WHITE  50.148295   \n",
       "\n",
       "                              insurance           admittime  \\\n",
       "subject_id hadm_id icustay_id                                 \n",
       "3          145834  211552      Medicare 2101-10-20 19:08:00   \n",
       "4          185777  294638       Private 2191-03-16 00:28:00   \n",
       "6          107064  228232      Medicare 2175-05-30 07:15:00   \n",
       "9          150750  220597      Medicaid 2149-11-09 13:06:00   \n",
       "11         194540  229441       Private 2178-04-16 06:18:00   \n",
       "\n",
       "                                            diagnosis_at_admission  \\\n",
       "subject_id hadm_id icustay_id                                        \n",
       "3          145834  211552                              HYPOTENSION   \n",
       "4          185777  294638      FEVER,DEHYDRATION,FAILURE TO THRIVE   \n",
       "6          107064  228232                CHRONIC RENAL FAILURE/SDA   \n",
       "9          150750  220597                          HEMORRHAGIC CVA   \n",
       "11         194540  229441                               BRAIN MASS   \n",
       "\n",
       "                                        dischtime         discharge_location  \\\n",
       "subject_id hadm_id icustay_id                                                  \n",
       "3          145834  211552     2101-10-31 13:58:00                        SNF   \n",
       "4          185777  294638     2191-03-23 18:41:00  HOME WITH HOME IV PROVIDR   \n",
       "6          107064  228232     2175-06-15 16:00:00           HOME HEALTH CARE   \n",
       "9          150750  220597     2149-11-14 10:15:00               DEAD/EXPIRED   \n",
       "11         194540  229441     2178-05-11 19:00:00           HOME HEALTH CARE   \n",
       "\n",
       "                               fullcode_first  dnr_first  ...  \\\n",
       "subject_id hadm_id icustay_id                             ...   \n",
       "3          145834  211552                 1.0        0.0  ...   \n",
       "4          185777  294638                 1.0        0.0  ...   \n",
       "6          107064  228232                 1.0        0.0  ...   \n",
       "9          150750  220597                 1.0        0.0  ...   \n",
       "11         194540  229441                 1.0        0.0  ...   \n",
       "\n",
       "                                          outtime   los_icu admission_type  \\\n",
       "subject_id hadm_id icustay_id                                                \n",
       "3          145834  211552     2101-10-26 20:43:09  6.064560      EMERGENCY   \n",
       "4          185777  294638     2191-03-17 16:46:31  1.678472      EMERGENCY   \n",
       "6          107064  228232     2175-06-03 13:39:54  3.672917       ELECTIVE   \n",
       "9          150750  220597     2149-11-14 20:52:14  5.323056      EMERGENCY   \n",
       "11         194540  229441     2178-04-17 20:21:05  1.584410      EMERGENCY   \n",
       "\n",
       "                               first_careunit  mort_icu  mort_hosp  \\\n",
       "subject_id hadm_id icustay_id                                        \n",
       "3          145834  211552                MICU         0          0   \n",
       "4          185777  294638                MICU         0          0   \n",
       "6          107064  228232                SICU         0          0   \n",
       "9          150750  220597                MICU         1          1   \n",
       "11         194540  229441                SICU         0          0   \n",
       "\n",
       "                              hospital_expire_flag hospstay_seq  \\\n",
       "subject_id hadm_id icustay_id                                     \n",
       "3          145834  211552                        0            1   \n",
       "4          185777  294638                        0            1   \n",
       "6          107064  228232                        0            1   \n",
       "9          150750  220597                        1            1   \n",
       "11         194540  229441                        0            1   \n",
       "\n",
       "                              readmission_30  max_hours  \n",
       "subject_id hadm_id icustay_id                            \n",
       "3          145834  211552                  0        145  \n",
       "4          185777  294638                  0         40  \n",
       "6          107064  228232                  0         88  \n",
       "9          150750  220597                  0        127  \n",
       "11         194540  229441                  0         38  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "statics.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_imputer(df):\n",
    "    idx = pd.IndexSlice\n",
    "    df = df.copy()\n",
    "    if len(df.columns.names) > 2: df.columns = df.columns.droplevel(('label', 'LEVEL1', 'LEVEL2'))\n",
    "    \n",
    "    df_out = df.loc[:, idx[:, ['mean', 'count']]]\n",
    "    icustay_means = df_out.loc[:, idx[:, 'mean']].groupby(ID_COLS).mean()\n",
    "    \n",
    "    df_out.loc[:,idx[:,'mean']] = df_out.loc[:,idx[:,'mean']].groupby(ID_COLS).fillna(\n",
    "        method='ffill'\n",
    "    ).groupby(ID_COLS).fillna(icustay_means).fillna(0)\n",
    "    \n",
    "    df_out.loc[:, idx[:, 'count']] = (df.loc[:, idx[:, 'count']] > 0).astype(float)\n",
    "    df_out.rename(columns={'count': 'mask'}, level='Aggregation Function', inplace=True)\n",
    "    \n",
    "    is_absent = (1 - df_out.loc[:, idx[:, 'mask']])\n",
    "    hours_of_absence = is_absent.cumsum()\n",
    "    time_since_measured = hours_of_absence - hours_of_absence[is_absent==0].fillna(method='ffill')\n",
    "    time_since_measured.rename(columns={'mask': 'time_since_measured'}, level='Aggregation Function', inplace=True)\n",
    "\n",
    "    df_out = pd.concat((df_out, time_since_measured), axis=1)\n",
    "    df_out.loc[:, idx[:, 'time_since_measured']] = df_out.loc[:, idx[:, 'time_since_measured']].fillna(100)\n",
    "    \n",
    "    df_out.sort_index(axis=1, inplace=True)\n",
    "    return df_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:1717: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  isetter(loc, v)\n"
     ]
    }
   ],
   "source": [
    "Ys = statics[statics.max_hours > WINDOW_SIZE + GAP_TIME][['mort_hosp', 'mort_icu', 'los_icu']]\n",
    "Ys['los_3'] = Ys['los_icu'] > 3\n",
    "Ys['los_7'] = Ys['los_icu'] > 7\n",
    "Ys.drop(columns=['los_icu'], inplace=True)\n",
    "Ys.astype(float)\n",
    "\n",
    "lvl2, raw = [df[\n",
    "    (df.index.get_level_values('icustay_id').isin(set(Ys.index.get_level_values('icustay_id')))) &\n",
    "    (df.index.get_level_values('hours_in') < WINDOW_SIZE)\n",
    "] for df in (data_full_lvl2, data_full_raw)]\n",
    "\n",
    "# raw.columns = raw.columns.droplevel(level=['label', 'LEVEL1', 'LEVEL2'])\n",
    "\n",
    "train_frac, dev_frac, test_frac = 0.7, 0.1, 0.2\n",
    "lvl2_subj_idx, raw_subj_idx, Ys_subj_idx = [df.index.get_level_values('subject_id') for df in (lvl2, raw, Ys)]\n",
    "lvl2_subjects = set(lvl2_subj_idx)\n",
    "assert lvl2_subjects == set(Ys_subj_idx), \"Subject ID pools differ!\"\n",
    "assert lvl2_subjects == set(raw_subj_idx), \"Subject ID pools differ!\"\n",
    "\n",
    "np.random.seed(SEED)\n",
    "subjects, N = np.random.permutation(list(lvl2_subjects)), len(lvl2_subjects)\n",
    "N_train, N_dev, N_test = int(train_frac * N), int(dev_frac * N), int(test_frac * N)\n",
    "train_subj = subjects[:N_train]\n",
    "dev_subj   = subjects[N_train:N_train + N_dev]\n",
    "test_subj  = subjects[N_train+N_dev:]\n",
    "\n",
    "[(lvl2_train, lvl2_dev, lvl2_test), (raw_train, raw_dev, raw_test), (Ys_train, Ys_dev, Ys_test)] = [\n",
    "    [df[df.index.get_level_values('subject_id').isin(s)] for s in (train_subj, dev_subj, test_subj)] \\\n",
    "    for df in (lvl2, raw, Ys)\n",
    "]\n",
    "\n",
    "idx = pd.IndexSlice\n",
    "lvl2_means, lvl2_stds = lvl2_train.loc[:, idx[:,'mean']].mean(axis=0), lvl2_train.loc[:, idx[:,'mean']].std(axis=0)\n",
    "raw_means, raw_stds = raw_train.loc[:, idx[:,'mean']].mean(axis=0), raw_train.loc[:, idx[:,'mean']].std(axis=0)\n",
    "\n",
    "lvl2_train.loc[:, idx[:,'mean']] = (lvl2_train.loc[:, idx[:,'mean']] - lvl2_means)/lvl2_stds\n",
    "lvl2_dev.loc[:, idx[:,'mean']] = (lvl2_dev.loc[:, idx[:,'mean']] - lvl2_means)/lvl2_stds\n",
    "lvl2_test.loc[:, idx[:,'mean']] = (lvl2_test.loc[:, idx[:,'mean']] - lvl2_means)/lvl2_stds\n",
    "\n",
    "raw_train.loc[:, idx[:,'mean']] = (raw_train.loc[:, idx[:,'mean']] - raw_means)/raw_stds\n",
    "raw_dev.loc[:, idx[:,'mean']] = (raw_dev.loc[:, idx[:,'mean']] - raw_means)/raw_stds\n",
    "raw_test.loc[:, idx[:,'mean']] = (raw_test.loc[:, idx[:,'mean']] - raw_means)/raw_stds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:1717: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  isetter(loc, v)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:4296: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return super().rename(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:1717: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  isetter(loc, v)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:1717: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  isetter(loc, v)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:4296: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return super().rename(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:1717: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  isetter(loc, v)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:1717: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  isetter(loc, v)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:4296: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return super().rename(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:1717: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  isetter(loc, v)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:1717: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  isetter(loc, v)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:4296: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return super().rename(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:1717: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  isetter(loc, v)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:1717: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  isetter(loc, v)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:4296: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return super().rename(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:1717: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  isetter(loc, v)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:1717: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  isetter(loc, v)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:4296: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return super().rename(\n"
     ]
    }
   ],
   "source": [
    "raw_train, raw_dev, raw_test, lvl2_train, lvl2_dev, lvl2_test = [\n",
    "    simple_imputer(df) for df in (raw_train, raw_dev, raw_test, lvl2_train, lvl2_dev, lvl2_test)\n",
    "]\n",
    "raw_flat_train, raw_flat_dev, raw_flat_test, lvl2_flat_train, lvl2_flat_dev, lvl2_flat_test = [\n",
    "    df.pivot_table(index=['subject_id', 'hadm_id', 'icustay_id'], columns=['hours_in']) for df in (\n",
    "        raw_train, raw_dev, raw_test, lvl2_train, lvl2_dev, lvl2_test\n",
    "    )\n",
    "]\n",
    "\n",
    "for df in lvl2_train, lvl2_dev, lvl2_test, raw_train, raw_dev, raw_test: assert not df.isnull().any().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ys = statics[statics.max_hours > WINDOW_SIZE + GAP_TIME][['mort_hosp', 'mort_icu', 'los_icu']]\n",
    "Ys['los_3'] = Ys['los_icu'] > 3\n",
    "Ys['los_7'] = Ys['los_icu'] > 7\n",
    "Ys.drop(columns=['los_icu'], inplace=True)\n",
    "Ys.astype(float)\n",
    "[(Ys_train, Ys_dev, Ys_test)] = [\n",
    "    [df[df.index.get_level_values('subject_id').isin(s)] for s in (train_subj, dev_subj, test_subj)] \\\n",
    "    for df in (Ys,)\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hyperparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 10\n",
    "\n",
    "GRU_D_dist = DictDist({\n",
    "    'cell_size': ss.randint(50, 75),\n",
    "    'hidden_size': ss.randint(65, 95), \n",
    "    'learning_rate': ss.uniform(2e-3, 1e-1),\n",
    "    'num_epochs': ss.randint(15, 150),\n",
    "    'patience': ss.randint(3, 7),\n",
    "    'batch_size': ss.randint(35, 65),\n",
    "    'early_stop_frac': ss.uniform(0.05, 0.1),\n",
    "    'seed': ss.randint(1, 10000),\n",
    "})\n",
    "np.random.seed(SEED)\n",
    "GRU_D_hyperparams_list = GRU_D_dist.rvs(N)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/scratch/mmd/extraction_baselines_gru-d.pkl', mode='rb') as f: results = pickle.load(f)\n",
    "results "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GRU-D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model GRU-D on target mort_icu with representation raw\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\wilso\\Documents\\GitHub\\MIMIC_Extract\\notebooks\\mmd_grud_utils.py:13: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
      "  return np.dstack((df.loc[idx[:,:,:,i], :].values for i in sorted(set(df.index.get_level_values('hours_in')))))\n",
      "<ipython-input-21-2bcb798dd325>:12: RuntimeWarning: Mean of empty slice\n",
      "  X_mean = np.nanmean(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On sample 1 / 10 (hyperparams = {'cell_size': 55, 'hidden_size': 66, 'learning_rate': 0.07052195003967596, 'num_epochs': 22, 'patience': 6, 'batch_size': 60, 'early_stop_frac': 0.051828827734419186, 'seed': 9496})\n",
      "<class 'numpy.int32'>\n",
      "Model Structure:  GRUD(\n",
      "  (zl): Linear(in_features=274, out_features=66, bias=True)\n",
      "  (rl): Linear(in_features=274, out_features=66, bias=True)\n",
      "  (hl): Linear(in_features=274, out_features=66, bias=True)\n",
      "  (gamma_x_l): FilterLinear(in_features=104, out_features=104, bias=True)\n",
      "  (gamma_h_l): Linear(in_features=104, out_features=66, bias=True)\n",
      "  (fc): Linear(in_features=66, out_features=2, bias=True)\n",
      "  (bn): BatchNorm1d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (drop): Dropout(p=0.5, inplace=False)\n",
      ")\n",
      "Start Training ... \n",
      "Output type dermined by the model\n",
      "Epoch: 0, train_loss: nan, valid_loss: nan, time: [18.1], best model: 1\n",
      "Epoch: 1, train_loss: nan, valid_loss: nan, time: [17.95], best model: 0\n",
      "Epoch: 2, train_loss: nan, valid_loss: nan, time: [18.37], best model: 0\n",
      "Epoch: 3, train_loss: nan, valid_loss: nan, time: [17.93], best model: 0\n",
      "Epoch: 4, train_loss: nan, valid_loss: nan, time: [18.01], best model: 0\n",
      "Epoch: 5, train_loss: nan, valid_loss: nan, time: [17.7], best model: 0\n",
      "Early Stopped at Epoch: 6\n",
      "[nan nan nan ... nan nan nan]\n",
      "[0 0 0 ... 0 0 0]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN, infinity or a value too large for dtype('float32').",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-21-2bcb798dd325>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     76\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprobabilities_dev\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     77\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels_dev\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 78\u001b[1;33m                 \u001b[0ms\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mroc_auc_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels_dev\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprobabilities_dev\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     79\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0ms\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mbest_s\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     80\u001b[0m                     \u001b[0mbest_s\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbest_hyperparams\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhyperparams\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     70\u001b[0m                           FutureWarning)\n\u001b[0;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_ranking.py\u001b[0m in \u001b[0;36mroc_auc_score\u001b[1;34m(y_true, y_score, average, sample_weight, max_fpr, multi_class, labels)\u001b[0m\n\u001b[0;32m    370\u001b[0m     \u001b[0my_type\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    371\u001b[0m     \u001b[0my_true\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 372\u001b[1;33m     \u001b[0my_score\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_score\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    373\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    374\u001b[0m     if y_type == \"multiclass\" or (y_type == \"binary\" and\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     70\u001b[0m                           FutureWarning)\n\u001b[0;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[0;32m    642\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    643\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 644\u001b[1;33m             _assert_all_finite(array,\n\u001b[0m\u001b[0;32m    645\u001b[0m                                allow_nan=force_all_finite == 'allow-nan')\n\u001b[0;32m    646\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[1;34m(X, allow_nan, msg_dtype)\u001b[0m\n\u001b[0;32m     94\u001b[0m                 not allow_nan and not np.isfinite(X).all()):\n\u001b[0;32m     95\u001b[0m             \u001b[0mtype_err\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'infinity'\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mallow_nan\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m'NaN, infinity'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 96\u001b[1;33m             raise ValueError(\n\u001b[0m\u001b[0;32m     97\u001b[0m                     \u001b[0mmsg_err\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     98\u001b[0m                     (type_err,\n",
      "\u001b[1;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float32')."
     ]
    }
   ],
   "source": [
    "model_name       = 'GRU-D'\n",
    "hyperparams_list = GRU_D_hyperparams_list\n",
    "RERUN            = False\n",
    "if model_name not in results: results[model_name] = {}\n",
    "for t in ['los_3', 'los_7']:\n",
    "    if t not in results[model_name]: results[model_name][t] = {}\n",
    "    for n, X_train, X_dev, X_test in (\n",
    "#        ('lvl2', lvl2_train, lvl2_dev, lvl2_test),\n",
    "         ('raw', raw_train, raw_dev, raw_test),\n",
    "    ):\n",
    "        print(\"Running model %s on target %s with representation %s\" % (model_name, t, n))\n",
    "        X_mean = np.nanmean(\n",
    "            to_3D_tensor(\n",
    "                X_train.loc[:, pd.IndexSlice[:, 'mean']] * \n",
    "                np.where((X_train.loc[:, pd.IndexSlice[:, 'mask']] == 1).values, 1, np.NaN)\n",
    "            ),\n",
    "            axis=0, keepdims=True\n",
    "        ).transpose([0, 2, 1])\n",
    "        base_params = {'X_mean': X_mean, 'output_last': True, 'input_size': X_mean.shape[2]}\n",
    "    \n",
    "        if n in results[model_name][t]:\n",
    "            if not RERUN: \n",
    "                print(\"Final results for model %s on target %s with representation %s\" % (model_name, t, n))\n",
    "                print(results[model_name][t][n])\n",
    "                continue\n",
    "            best_s, best_hyperparams = results[model_name][t][n][-1], results[model_name][t][n][1]\n",
    "            print(\"Loading best hyperparams\", best_hyperparams)\n",
    "        else:\n",
    "            best_s, best_hyperparams = -np.Inf, None\n",
    "            for i, hyperparams in enumerate(hyperparams_list):\n",
    "                print(\"On sample %d / %d (hyperparams = %s)\" % (i+1, len(hyperparams_list), repr((hyperparams))))\n",
    "\n",
    "                early_stop_frac,batch_size,seed = [hyperparams[k] for k in ('early_stop_frac','batch_size','seed')]\n",
    "                \n",
    "                print(type(batch_size))\n",
    "                batch_size = int(batch_size)\n",
    "\n",
    "                np.random.seed(seed)\n",
    "                all_train_subjects = list(\n",
    "                    np.random.permutation(Ys_train.index.get_level_values('subject_id').values)\n",
    "                )\n",
    "                N_early_stop        = int(len(all_train_subjects) * early_stop_frac)\n",
    "                train_subjects      = all_train_subjects[:-N_early_stop]\n",
    "                early_stop_subjects = all_train_subjects[-N_early_stop:]\n",
    "                X_train_obs         = X_train[X_train.index.get_level_values('subject_id').isin(train_subjects)]\n",
    "                Ys_train_obs        = Ys_train[Ys_train.index.get_level_values('subject_id').isin(train_subjects)]\n",
    "\n",
    "                X_train_early_stop  = X_train[X_train.index.get_level_values('subject_id').isin(early_stop_subjects)]\n",
    "                Ys_train_early_stop = Ys_train[\n",
    "                    Ys_train.index.get_level_values('subject_id').isin(early_stop_subjects)\n",
    "                ]\n",
    "\n",
    "                train_dataloader      = prepare_dataloader(X_train_obs, Ys_train_obs[t], batch_size=batch_size)\n",
    "                early_stop_dataloader = prepare_dataloader(\n",
    "                    X_train_early_stop, Ys_train_early_stop[t], batch_size=batch_size\n",
    "                )\n",
    "                dev_dataloader        = prepare_dataloader(X_dev, Ys_dev[t], batch_size=batch_size)\n",
    "                test_dataloader       = prepare_dataloader(X_test, Ys_test[t], batch_size=batch_size)\n",
    "\n",
    "                model_hyperparams = copy.copy(base_params)\n",
    "                model_hyperparams.update(\n",
    "                    {k: v for k, v in hyperparams.items() if k in ('cell_size', 'hidden_size', 'batch_size')}\n",
    "                )\n",
    "                model = GRUD(**model_hyperparams)\n",
    "\n",
    "                best_model, _ = Train_Model(\n",
    "                    model, train_dataloader, early_stop_dataloader,\n",
    "                    **{k: v for k, v in hyperparams.items() if k in (\n",
    "                        'num_epochs', 'patience', 'learning_rate', 'batch_size'\n",
    "                    )}\n",
    "                )\n",
    "\n",
    "                probabilities_dev, labels_dev = predict_proba(best_model, dev_dataloader)\n",
    "                probabilities_dev = np.concatenate(probabilities_dev)[:, 1]\n",
    "                labels_dev        = np.concatenate(labels_dev)\n",
    "                print(probabilities_dev)\n",
    "                print(labels_dev)\n",
    "                s = roc_auc_score(labels_dev, probabilities_dev)\n",
    "                if s > best_s:\n",
    "                    best_s, best_hyperparams = s, hyperparams\n",
    "                    print(\"New Best Score: %.2f @ hyperparams = %s\" % (100*best_s, repr((best_hyperparams))))\n",
    "                \n",
    "        ## Test\n",
    "        np.random.seed(seed)\n",
    "        early_stop_frac,batch_size,seed = [best_hyperparams[k] for k in ('early_stop_frac','batch_size','seed')]\n",
    "        \n",
    "        X_train_concat, Ys_train_concat = pd.concat((X_train, X_dev)), pd.concat((Ys_train, Ys_dev))\n",
    "        \n",
    "        all_train_subjects = list(np.random.permutation(Ys_train_concat.index.get_level_values('subject_id').values))\n",
    "        N_early_stop = int(len(all_train_subjects) * early_stop_frac)\n",
    "        train_subjects, early_stop_subjects = all_train_subjects[:-N_early_stop], all_train_subjects[-N_early_stop:]\n",
    "        X_train_obs         = X_train_concat[X_train_concat.index.get_level_values('subject_id').isin(train_subjects)]\n",
    "        Ys_train_obs        = Ys_train_concat[Ys_train_concat.index.get_level_values('subject_id').isin(train_subjects)]\n",
    "\n",
    "        X_train_early_stop  = X_train_concat[X_train_concat.index.get_level_values('subject_id').isin(early_stop_subjects)]\n",
    "        Ys_train_early_stop = Ys_train_concat[Ys_train_concat.index.get_level_values('subject_id').isin(early_stop_subjects)]\n",
    "\n",
    "        train_dataloader      = prepare_dataloader(X_train_obs, Ys_train_obs[t], batch_size=batch_size)\n",
    "        early_stop_dataloader = prepare_dataloader(X_train_early_stop, Ys_train_early_stop[t], batch_size=batch_size)\n",
    "        test_dataloader       = prepare_dataloader(X_test, Ys_test[t], batch_size=batch_size)\n",
    "\n",
    "        model_hyperparams = copy.copy(base_params)\n",
    "        model_hyperparams.update(\n",
    "            {k: v for k, v in best_hyperparams.items() if k in ('cell_size', 'hidden_size', 'batch_size')}\n",
    "        )\n",
    "        model = GRUD(**model_hyperparams)\n",
    "\n",
    "        best_model, (losses_train, losses_early_stop, losses_epochs_train, losses_epochs_early_stop) = Train_Model(\n",
    "            model, train_dataloader, early_stop_dataloader,\n",
    "            **{k: v for k, v in best_hyperparams.items() if k in (\n",
    "                'num_epochs', 'patience', 'learning_rate', 'batch_size'\n",
    "            )}\n",
    "        )\n",
    "\n",
    "        probabilities_test, labels_test = predict_proba(best_model, test_dataloader)\n",
    "\n",
    "        y_score = np.concatenate(probabilities_test)[:, 1]\n",
    "        y_pred  = np.argmax(probabilities_test)\n",
    "        y_true  = np.concatenate(labels_test)\n",
    "\n",
    "        auc   = roc_auc_score(y_true, y_score)\n",
    "        auprc = average_precision_score(y_true, y_score)\n",
    "        acc   = accuracy_score(y_true, y_pred)\n",
    "        F1    = f1_score(y_true, y_pred)\n",
    "        print(\"Final results for model %s on target %s with representation %s\" % (model_name, t, n))\n",
    "        print(auc, auprc, acc, F1)\n",
    "        \n",
    "        results[model_name][t][n] = None, best_hyperparams, auc, auprc, acc, F1, best_s\n",
    "        # with open('/scratch/mmd/extraction_baselines_gru-d.pkl', mode='wb') as f: pickle.dump(results, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_score = np.concatenate(probabilities_test)[:, 1]\n",
    "y_pred  = np.concatenate(probabilities_test).argmax(axis=1)\n",
    "y_true  = np.concatenate(labels_test)\n",
    "\n",
    "auc   = roc_auc_score(y_true, y_score)\n",
    "auprc = average_precision_score(y_true, y_score)\n",
    "acc   = accuracy_score(y_true, y_pred)\n",
    "F1    = f1_score(y_true, y_pred)\n",
    "print(\"Final results for model %s on target %s with representation %s\" % (model_name, t, n))\n",
    "print(auc, auprc, acc, F1)\n",
    "\n",
    "results[model_name][t][n] = None, best_hyperparams, auc, auprc, acc, F1, best_s\n",
    "with open('/scratch/mmd/extraction_baselines_gru-d.pkl', mode='wb') as f: pickle.dump(results, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
