{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rewrite of the \"Baselines for mortality and LOS prediction\" notebooks.\n",
    "#### This notebook contains code to predict LOS using GRU-D, Random Forest and Logistic Regression in a simple notebook with explanations.\n",
    "\n",
    "Author(s): Tomass Wilson, thwmi@kth.se\n",
    "\n",
    "Credit: Shirly Wang, Matthew B. A. McDermott, Geeticka Chauhan, Michael C. Hughes, Tristan Naumann, \n",
    "and Marzyeh Ghassemi. MIMIC-Extract: A Data Extraction, Preprocessing, and Representation \n",
    "Pipeline for MIMIC-III. arXiv:1907.08322. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload\n",
    "\n",
    "import copy, math, os, pickle, time, pandas as pd, numpy as np, scipy.stats as ss\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import average_precision_score, roc_auc_score, accuracy_score, f1_score\n",
    "\n",
    "import torch, torch.utils.data as utils, torch.nn as nn, torch.nn.functional as F, torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from torch.nn.parameter import Parameter\n",
    "\n",
    "\n",
    "from mmd_grud_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirname = os.getcwd()\n",
    "DATA_FILEPATH     = os.path.join(dirname, \"..\", \"data\", \"all_hourly_data.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x217bad8a070>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GAP_TIME          = 6  # In hours\n",
    "WINDOW_SIZE       = 24 # In hours\n",
    "SEED              = 2\n",
    "ID_COLS           = ['subject_id', 'hadm_id', 'icustay_id']\n",
    "GPU               = '0'  # set this to the ID(s) of your most powerful GPU(s)\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = GPU\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 10.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "data_full = pd.read_hdf(DATA_FILEPATH, 'vitals_labs')\n",
    "statics        = pd.read_hdf(DATA_FILEPATH, 'patients')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create True/False mappings of the targets LOS 3/7 days\n",
    "Also we create a list of subjects that all have lengths of stay that are at least 30 hours long.\n",
    "\n",
    "Ys is a dataframe containing the target results for each subject (eg that they did stay for longer than 3 days).\n",
    "\n",
    "data_df contains the metrics which we want to evaluate to predict length of stay. They are also the ones on which differential privacy will be applied."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All patients in ys ahave been in icu at some point for at least 30 hours\n",
    "Ys = statics[statics.max_hours > WINDOW_SIZE + GAP_TIME][['los_icu']]\n",
    "Ys['los_3'] = Ys['los_icu'] > 3  # True/False column\n",
    "Ys['los_7'] = Ys['los_icu'] > 7\n",
    "\n",
    "# Get only the medical data of the chosen subjects\n",
    "data_df = data_full[\n",
    "    (data_full.index.get_level_values('icustay_id').isin(set(Ys.index.get_level_values('icustay_id')))) &\n",
    "    (data_full.index.get_level_values('hours_in') < WINDOW_SIZE)\n",
    "]\n",
    "\n",
    "# Collect the subject id's\n",
    "subj_idx, Ys_subj_idx = [df.index.get_level_values('subject_id') for df in (data_df, Ys)]\n",
    "subjects = set(subj_idx)\n",
    "assert subjects == set(Ys_subj_idx), \"Subject ID pools differ!\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create train, dev and test fractions of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_frac, dev_frac, test_frac = 0.7, 0.1, 0.2\n",
    "np.random.seed(SEED)\n",
    "subjects, N = np.random.permutation(list(subjects)), len(subjects)\n",
    "N_train, N_dev, N_test = int(train_frac * N), int(dev_frac * N), int(test_frac * N)\n",
    "train_subj = subjects[:N_train]\n",
    "dev_subj   = subjects[N_train:N_train + N_dev]\n",
    "test_subj  = subjects[N_train+N_dev:]\n",
    "\n",
    "# Create train, dev and test fractions for data and Ys\n",
    "[(data_train, data_dev, data_test), (Ys_train, Ys_dev, Ys_test)] = [\n",
    "    [df[df.index.get_level_values('subject_id').isin(s)].copy() for s in (train_subj, dev_subj, test_subj)] \\\n",
    "    for df in (data_df, Ys)\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### smthng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = pd.IndexSlice\n",
    "data_means = data_train.loc[:, idx[:,'mean']].mean(axis=0)\n",
    "data_stds = data_train.loc[:, idx[:,'mean']].std(axis=0)\n",
    "\n",
    "data_train.loc[:, idx[:,'mean']] = (data_train.loc[:, idx[:,'mean']] - data_means)/data_stds\n",
    "data_dev.loc[:, idx[:,'mean']] = (data_dev.loc[:, idx[:,'mean']] - data_means)/data_stds\n",
    "data_test.loc[:, idx[:,'mean']] = (data_test.loc[:, idx[:,'mean']] - data_means)/data_stds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### smthng else"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_imputer(df):\n",
    "    idx = pd.IndexSlice\n",
    "    if len(df.columns.names) > 2: \n",
    "        df.columns = df.columns.droplevel(('label', 'LEVEL1', 'LEVEL2'))\n",
    "    \n",
    "    df_out = df.loc[:, idx[:, ['mean', 'count']]].copy()\n",
    "    icustay_means = df_out.loc[:, idx[:, 'mean']].groupby(ID_COLS).mean()\n",
    "    \n",
    "    df_out.loc[:,idx[:,'mean']] = df_out.loc[:,idx[:,'mean']].groupby(ID_COLS).fillna(\n",
    "        method='ffill'\n",
    "    ).groupby(ID_COLS).fillna(icustay_means).fillna(0)\n",
    "    \n",
    "    df_out.loc[:, idx[:, 'count']] = (df.loc[:, idx[:, 'count']] > 0).astype(float)\n",
    "    df_out.rename(columns={'count': 'mask'}, level='Aggregation Function', inplace=True)\n",
    "    \n",
    "    is_absent = (1 - df_out.loc[:, idx[:, 'mask']])\n",
    "    hours_of_absence = is_absent.cumsum()\n",
    "    time_since_measured = hours_of_absence - hours_of_absence[is_absent==0].fillna(method='ffill')\n",
    "    time_since_measured.rename(columns={'mask': 'time_since_measured'}, level='Aggregation Function', inplace=True)\n",
    "\n",
    "    df_out = pd.concat((df_out, time_since_measured), axis=1)\n",
    "    df_out.loc[:, idx[:, 'time_since_measured']] = df_out.loc[:, idx[:, 'time_since_measured']].fillna(100)\n",
    "    \n",
    "    df_out.sort_index(axis=1, inplace=True)\n",
    "    return df_out\n",
    "\n",
    "data_train, data_dev, data_test = [\n",
    "    simple_imputer(df) for df in (data_train, data_dev, data_test)\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add differential privacy\n",
    "We will use a high privacy budget in initial testing, 7\n",
    "\n",
    "We add noise to train and dev sets, as they are used in training, but not to test so as to get accurate results. IRL, test would also not be able to have local diff privacy (just as with actual used data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_noise(df, epsilon):\n",
    "    \"\"\"\n",
    "    Add noise to the mimic 3 dataset\n",
    "    \n",
    "    Args:\n",
    "        df: The dataframe on which to add noise, as formatted  by mimic extract\n",
    "        epsilon: The differential privacy budget to use\n",
    "        \n",
    "    returns:\n",
    "        noisy_df: The dataframe with added noise\n",
    "    \"\"\"\n",
    "    \n",
    "    generator = np.random.default_rng()\n",
    "    noisy_df = df.copy()\n",
    "    idx = pd.IndexSlice\n",
    "    \n",
    "    for feature_name in df.loc[:, idx[:, \"mean\"]]:\n",
    "        feature = df.loc[:, feature_name].copy()\n",
    "        sensitivity = max(feature) - min(feature)\n",
    "        scale = sensitivity / epsilon  # Definition of scale parameter for laplace noise to fulfill diff privacy\n",
    "        noise = generator.laplace(0, scale, len(feature))\n",
    "        noisy_feature = feature + noise\n",
    "        noisy_df.loc[:, feature_name] = noisy_feature\n",
    "        \n",
    "    return noisy_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 9.83 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "epsilon = 7\n",
    "data_train = add_noise(data_train, epsilon)\n",
    "data_dev = add_noise(data_dev, epsilon)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Flatten Arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_flat_train, data_flat_dev, data_flat_test = [\n",
    "    df.pivot_table(index=['subject_id', 'hadm_id', 'icustay_id'], columns=['hours_in']) for df in (\n",
    "        data_train, data_dev, data_test\n",
    "    )\n",
    "]\n",
    "\n",
    "for df in data_train, data_dev, data_test: \n",
    "    assert not df.isnull().any().any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DictDist():\n",
    "    def __init__(self, dict_of_rvs): self.dict_of_rvs = dict_of_rvs\n",
    "    def rvs(self, n):\n",
    "        a = {k: v.rvs(n) for k, v in self.dict_of_rvs.items()}\n",
    "        out = []\n",
    "        for i in range(n): out.append({k: vs[i] for k, vs in a.items()})\n",
    "        return out\n",
    "\n",
    "class Choice():\n",
    "    def __init__(self, options): self.options = options\n",
    "    def rvs(self, n): return [self.options[i] for i in ss.randint(0, len(self.options)).rvs(n)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 15\n",
    "\n",
    "LR_dist = DictDist({\n",
    "    'C': Choice(np.geomspace(1e-3, 1e3, 10000)),\n",
    "    'penalty': Choice(['l1', 'l2']),\n",
    "    'solver': Choice(['liblinear', 'lbfgs']),\n",
    "    'max_iter': Choice([100, 500])\n",
    "})\n",
    "np.random.seed(SEED)\n",
    "LR_hyperparams_list = LR_dist.rvs(N)\n",
    "for i in range(N):\n",
    "    if LR_hyperparams_list[i]['solver'] == 'lbfgs': LR_hyperparams_list[i]['penalty'] = 'l2'\n",
    "\n",
    "RF_dist = DictDist({\n",
    "    'n_estimators': ss.randint(50, 500),\n",
    "    'max_depth': ss.randint(2, 10),\n",
    "    'min_samples_split': ss.randint(2, 75),\n",
    "    'min_samples_leaf': ss.randint(1, 50),\n",
    "})\n",
    "np.random.seed(SEED)\n",
    "RF_hyperparams_list = RF_dist.rvs(N)\n",
    "\n",
    "GRU_D_dist = DictDist({\n",
    "    'cell_size': ss.randint(50, 75),\n",
    "    'hidden_size': ss.randint(65, 95),\n",
    "    'learning_rate': ss.uniform(2e-3, 1e-1),\n",
    "    'num_epochs': ss.randint(60, 150),\n",
    "    'patience': ss.randint(5, 9),\n",
    "    'batch_size': Choice([64, 128, 256, 512]),\n",
    "    'early_stop_frac': ss.uniform(0.05, 0.1),\n",
    "    'seed': ss.randint(1, 10000),\n",
    "})\n",
    "np.random.seed(SEED)\n",
    "GRU_D_hyperparams_list = GRU_D_dist.rvs(N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}  # Declare results dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest and Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_basic(model, hyperparams_list, X_flat_train, X_flat_dev, X_flat_test, target):\n",
    "    best_s, best_hyperparams = -np.Inf, None\n",
    "    for i, hyperparams in enumerate(hyperparams_list):\n",
    "        print(\"On sample %d / %d (hyperparams = %s)\" % (i+1, len(hyperparams_list), repr((hyperparams))))\n",
    "        M = model(**hyperparams)\n",
    "        M.fit(X_flat_train, Ys_train[target])\n",
    "        s = roc_auc_score(Ys_dev[target], M.predict_proba(X_flat_dev)[:, 1])\n",
    "        if s > best_s:\n",
    "            best_s, best_hyperparams = s, hyperparams\n",
    "            print(\"New Best Score: %.2f @ hyperparams = %s\" % (100*best_s, repr((best_hyperparams))))\n",
    "\n",
    "    return run_only_final(model, best_hyperparams, X_flat_train, X_flat_dev, X_flat_test, target)\n",
    "\n",
    "def run_only_final(model, best_hyperparams, X_flat_train, X_flat_dev, X_flat_test, target):\n",
    "    best_M = model(**best_hyperparams)\n",
    "    best_M.fit(pd.concat((X_flat_train, X_flat_dev)), pd.concat((Ys_train, Ys_dev))[target])\n",
    "    y_true  = Ys_test[target]\n",
    "    y_score = best_M.predict_proba(X_flat_test)[:, 1]\n",
    "    y_pred  = best_M.predict(X_flat_test)\n",
    "\n",
    "    auc   = roc_auc_score(y_true, y_score)\n",
    "    auprc = average_precision_score(y_true, y_score)\n",
    "    acc   = accuracy_score(y_true, y_pred)\n",
    "    F1    = f1_score(y_true, y_pred)\n",
    "    \n",
    "    return best_M, best_hyperparams, auc, auprc, acc, F1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model RF on target los_7 with representation data\n",
      "On sample 1 / 15 (hyperparams = {'n_estimators': 218, 'max_depth': 9, 'min_samples_split': 35, 'min_samples_leaf': 47})\n",
      "New Best Score: 71.40 @ hyperparams = {'n_estimators': 218, 'max_depth': 9, 'min_samples_split': 35, 'min_samples_leaf': 47}\n",
      "On sample 2 / 15 (hyperparams = {'n_estimators': 65, 'max_depth': 4, 'min_samples_split': 60, 'min_samples_leaf': 9})\n",
      "On sample 3 / 15 (hyperparams = {'n_estimators': 122, 'max_depth': 6, 'min_samples_split': 69, 'min_samples_leaf': 46})\n",
      "On sample 4 / 15 (hyperparams = {'n_estimators': 72, 'max_depth': 6, 'min_samples_split': 71, 'min_samples_leaf': 16})\n",
      "On sample 5 / 15 (hyperparams = {'n_estimators': 349, 'max_depth': 6, 'min_samples_split': 70, 'min_samples_leaf': 42})\n",
      "New Best Score: 71.50 @ hyperparams = {'n_estimators': 349, 'max_depth': 6, 'min_samples_split': 70, 'min_samples_leaf': 42}\n",
      "On sample 6 / 15 (hyperparams = {'n_estimators': 125, 'max_depth': 7, 'min_samples_split': 48, 'min_samples_leaf': 46})\n",
      "On sample 7 / 15 (hyperparams = {'n_estimators': 410, 'max_depth': 9, 'min_samples_split': 72, 'min_samples_leaf': 9})\n",
      "On sample 8 / 15 (hyperparams = {'n_estimators': 313, 'max_depth': 5, 'min_samples_split': 33, 'min_samples_leaf': 18})\n",
      "On sample 9 / 15 (hyperparams = {'n_estimators': 212, 'max_depth': 8, 'min_samples_split': 68, 'min_samples_leaf': 23})\n",
      "New Best Score: 71.81 @ hyperparams = {'n_estimators': 212, 'max_depth': 8, 'min_samples_split': 68, 'min_samples_leaf': 23}\n",
      "On sample 10 / 15 (hyperparams = {'n_estimators': 483, 'max_depth': 6, 'min_samples_split': 54, 'min_samples_leaf': 10})\n",
      "On sample 11 / 15 (hyperparams = {'n_estimators': 145, 'max_depth': 4, 'min_samples_split': 52, 'min_samples_leaf': 42})\n",
      "On sample 12 / 15 (hyperparams = {'n_estimators': 125, 'max_depth': 5, 'min_samples_split': 6, 'min_samples_leaf': 47})\n",
      "On sample 13 / 15 (hyperparams = {'n_estimators': 263, 'max_depth': 5, 'min_samples_split': 65, 'min_samples_leaf': 27})\n",
      "On sample 14 / 15 (hyperparams = {'n_estimators': 97, 'max_depth': 9, 'min_samples_split': 51, 'min_samples_leaf': 20})\n",
      "On sample 15 / 15 (hyperparams = {'n_estimators': 369, 'max_depth': 8, 'min_samples_split': 41, 'min_samples_leaf': 33})\n",
      "Final results for model RF on target los_7 with representation data\n",
      "(0.7385474609932444, 0.1878883097891938, 0.9288100208768267, 0.0)\n",
      "Running model RF on target los_3 with representation data\n",
      "On sample 1 / 15 (hyperparams = {'n_estimators': 218, 'max_depth': 9, 'min_samples_split': 35, 'min_samples_leaf': 47})\n",
      "New Best Score: 70.15 @ hyperparams = {'n_estimators': 218, 'max_depth': 9, 'min_samples_split': 35, 'min_samples_leaf': 47}\n",
      "On sample 2 / 15 (hyperparams = {'n_estimators': 65, 'max_depth': 4, 'min_samples_split': 60, 'min_samples_leaf': 9})\n",
      "On sample 3 / 15 (hyperparams = {'n_estimators': 122, 'max_depth': 6, 'min_samples_split': 69, 'min_samples_leaf': 46})\n",
      "On sample 4 / 15 (hyperparams = {'n_estimators': 72, 'max_depth': 6, 'min_samples_split': 71, 'min_samples_leaf': 16})\n",
      "On sample 5 / 15 (hyperparams = {'n_estimators': 349, 'max_depth': 6, 'min_samples_split': 70, 'min_samples_leaf': 42})\n",
      "On sample 6 / 15 (hyperparams = {'n_estimators': 125, 'max_depth': 7, 'min_samples_split': 48, 'min_samples_leaf': 46})\n",
      "On sample 7 / 15 (hyperparams = {'n_estimators': 410, 'max_depth': 9, 'min_samples_split': 72, 'min_samples_leaf': 9})\n"
     ]
    }
   ],
   "source": [
    "for model_name, model, hyperparams_list in [\n",
    "    ('RF', RandomForestClassifier, RF_hyperparams_list), ('LR', LogisticRegression, LR_hyperparams_list)\n",
    "]:\n",
    "    if model_name not in results: \n",
    "        results[model_name] = {}\n",
    "    for t in ['los_7', 'los_3']:\n",
    "        if t not in results[model_name]: \n",
    "            results[model_name][t] = {}\n",
    "        \n",
    "        if \"data\" in results[model_name][t]:\n",
    "            print(\"Finished model %s on target %s with representation %s\" % (model_name, t, \"data\"))\n",
    "            if RERUN: \n",
    "                h = results[model_name][t][\"data\"][1]\n",
    "                results[model_name][t][\"data\"] = run_only_final(model, h, data_flat_train, data_flat_dev, data_flat_test, t)\n",
    "\n",
    "                print(\"Final results for model %s on target %s with representation %s\" % (model_name, t, \"data\"))\n",
    "                print(results[model_name][t][\"data\"][2:])\n",
    "\n",
    "                with open(RESULTS_PATH, mode='wb') as f: pickle.dump(results, f)\n",
    "            continue\n",
    "\n",
    "        print(\"Running model %s on target %s with representation %s\" % (model_name, t, \"data\"))\n",
    "        results[model_name][t][\"data\"] = run_basic(\n",
    "            model, hyperparams_list, data_flat_train, data_flat_dev, data_flat_test, t\n",
    "        )\n",
    "        print(\"Final results for model %s on target %s with representation %s\" % (model_name, t, \"data\"))\n",
    "        print(results[model_name][t][\"data\"][2:])  # auc, auprc, acc, F1\n",
    "        # with open(RESULTS_PATH, mode='wb') as f: pickle.dump(results, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GRU-D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model GRU-D on target los_3 with representation data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-32-7d35c2d9607d>:22: RuntimeWarning: Mean of empty slice\n",
      "  X_mean = np.nanmean(tensor, axis=0, keepdims=True).transpose([0, 2, 1])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On sample 1 / 60 (hyperparams = {'cell_size': 65, 'hidden_size': 151, 'learning_rate': 0.0933915477165132, 'num_epochs': 145, 'patience': 10, 'batch_size': 64, 'early_stop_frac': 0.13332124901226045, 'seed': 4241})\n",
      "Model Structure:  GRUD(\n",
      "  (zl): Linear(in_features=359, out_features=151, bias=True)\n",
      "  (rl): Linear(in_features=359, out_features=151, bias=True)\n",
      "  (hl): Linear(in_features=359, out_features=151, bias=True)\n",
      "  (gamma_x_l): FilterLinear(in_features=104, out_features=104, bias=True)\n",
      "  (gamma_h_l): Linear(in_features=104, out_features=151, bias=True)\n",
      "  (fc): Linear(in_features=151, out_features=2, bias=True)\n",
      "  (bn): BatchNorm1d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (drop): Dropout(p=0.5, inplace=False)\n",
      ")\n",
      "Start Training ... \n",
      "Output type dermined by the model\n",
      "Epoch: 0, train_loss: 0.68283182, valid_loss: 0.68485942, time: [15.23], best model: 1\n",
      "Epoch: 1, train_loss: 0.67329643, valid_loss: 0.67721024, time: [14.91], best model: 1\n",
      "Epoch: 2, train_loss: 0.67374873, valid_loss: 0.67376378, time: [15.09], best model: 1\n",
      "Epoch: 3, train_loss: 0.66890892, valid_loss: 0.67217808, time: [14.5], best model: 1\n",
      "Epoch: 4, train_loss: 0.66653199, valid_loss: 0.66612507, time: [14.27], best model: 1\n",
      "Epoch: 5, train_loss: 0.65881624, valid_loss: 0.65853281, time: [14.7], best model: 1\n",
      "Epoch: 6, train_loss: 0.66300012, valid_loss: 0.66409889, time: [14.3], best model: 0\n",
      "Epoch: 7, train_loss: 0.65985067, valid_loss: 0.66315156, time: [15.11], best model: 0\n",
      "Epoch: 8, train_loss: 0.66231638, valid_loss: 0.65957365, time: [14.82], best model: 0\n",
      "Epoch: 9, train_loss: 0.66174411, valid_loss: 0.66296799, time: [14.53], best model: 0\n",
      "Epoch: 10, train_loss: 0.6570731, valid_loss: 0.66326303, time: [14.46], best model: 0\n",
      "Epoch: 11, train_loss: 0.66197873, valid_loss: 0.66187496, time: [14.83], best model: 0\n",
      "Epoch: 12, train_loss: 0.66316493, valid_loss: 0.66424689, time: [14.84], best model: 0\n",
      "Epoch: 13, train_loss: 0.65762268, valid_loss: 0.65818206, time: [14.9], best model: 1\n",
      "Epoch: 14, train_loss: 0.66103383, valid_loss: 0.66047864, time: [14.88], best model: 0\n",
      "Epoch: 15, train_loss: 0.65617884, valid_loss: 0.65794764, time: [14.85], best model: 1\n",
      "Epoch: 16, train_loss: 0.65691565, valid_loss: 0.65570595, time: [14.38], best model: 1\n",
      "Epoch: 17, train_loss: 0.65404943, valid_loss: 0.65826706, time: [14.66], best model: 0\n",
      "Epoch: 18, train_loss: 0.65255602, valid_loss: 0.6570999, time: [14.66], best model: 0\n",
      "Epoch: 19, train_loss: 0.65252551, valid_loss: 0.65144173, time: [14.81], best model: 1\n",
      "Epoch: 20, train_loss: 0.65734148, valid_loss: 0.65562608, time: [14.68], best model: 0\n",
      "Epoch: 21, train_loss: 0.65489771, valid_loss: 0.64919544, time: [14.78], best model: 1\n",
      "Epoch: 22, train_loss: 0.65451874, valid_loss: 0.65536067, time: [14.58], best model: 0\n",
      "Epoch: 23, train_loss: 0.65603395, valid_loss: 0.65635499, time: [14.75], best model: 0\n",
      "Epoch: 24, train_loss: 0.65807538, valid_loss: 0.65086446, time: [14.92], best model: 0\n",
      "Epoch: 25, train_loss: 0.65179005, valid_loss: 0.65836226, time: [14.9], best model: 0\n",
      "Epoch: 26, train_loss: 0.65345568, valid_loss: 0.65287119, time: [15.16], best model: 0\n",
      "Epoch: 27, train_loss: 0.65046773, valid_loss: 0.65734458, time: [14.58], best model: 0\n",
      "Epoch: 28, train_loss: 0.65665193, valid_loss: 0.65989428, time: [14.31], best model: 0\n",
      "Epoch: 29, train_loss: 0.65190563, valid_loss: 0.66051807, time: [14.43], best model: 0\n",
      "Epoch: 30, train_loss: 0.65006364, valid_loss: 0.65594435, time: [14.4], best model: 0\n",
      "Early Stopped at Epoch: 31\n",
      "New Best Score: 69.10 @ hyperparams = {'cell_size': 65, 'hidden_size': 151, 'learning_rate': 0.0933915477165132, 'num_epochs': 145, 'patience': 10, 'batch_size': 64, 'early_stop_frac': 0.13332124901226045, 'seed': 4241}\n",
      "On sample 2 / 60 (hyperparams = {'cell_size': 122, 'hidden_size': 84, 'learning_rate': 0.04397354613068208, 'num_epochs': 61, 'patience': 8, 'batch_size': 512, 'early_stop_frac': 0.08237505822561465, 'seed': 2709})\n",
      "Model Structure:  GRUD(\n",
      "  (zl): Linear(in_features=292, out_features=84, bias=True)\n",
      "  (rl): Linear(in_features=292, out_features=84, bias=True)\n",
      "  (hl): Linear(in_features=292, out_features=84, bias=True)\n",
      "  (gamma_x_l): FilterLinear(in_features=104, out_features=104, bias=True)\n",
      "  (gamma_h_l): Linear(in_features=104, out_features=84, bias=True)\n",
      "  (fc): Linear(in_features=84, out_features=2, bias=True)\n",
      "  (bn): BatchNorm1d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (drop): Dropout(p=0.5, inplace=False)\n",
      ")\n",
      "Start Training ... \n",
      "Output type dermined by the model\n",
      "Epoch: 0, train_loss: 0.71302382, valid_loss: 0.69783395, time: [4.13], best model: 1\n",
      "Epoch: 1, train_loss: 0.64498202, valid_loss: 0.64834944, time: [4.04], best model: 1\n",
      "Epoch: 2, train_loss: 0.63339685, valid_loss: 0.6403422, time: [3.98], best model: 1\n",
      "Epoch: 3, train_loss: 0.6299188, valid_loss: 0.63128217, time: [4.33], best model: 1\n",
      "Epoch: 4, train_loss: 0.63736121, valid_loss: 0.6394659, time: [4.08], best model: 0\n",
      "Epoch: 5, train_loss: 0.6349631, valid_loss: 0.63399754, time: [3.98], best model: 0\n",
      "Epoch: 6, train_loss: 0.63098462, valid_loss: 0.64155649, time: [3.84], best model: 0\n",
      "Epoch: 7, train_loss: 0.62602317, valid_loss: 0.64003874, time: [3.89], best model: 0\n",
      "Epoch: 8, train_loss: 0.62126172, valid_loss: 0.64430777, time: [4.2], best model: 0\n",
      "Epoch: 9, train_loss: 0.61655636, valid_loss: 0.64263592, time: [4.19], best model: 0\n",
      "Epoch: 10, train_loss: 0.61776237, valid_loss: 0.64690793, time: [4.11], best model: 0\n",
      "Early Stopped at Epoch: 11\n",
      "New Best Score: 71.38 @ hyperparams = {'cell_size': 122, 'hidden_size': 84, 'learning_rate': 0.04397354613068208, 'num_epochs': 61, 'patience': 8, 'batch_size': 512, 'early_stop_frac': 0.08237505822561465, 'seed': 2709}\n",
      "On sample 3 / 60 (hyperparams = {'cell_size': 72, 'hidden_size': 121, 'learning_rate': 0.05601915156671309, 'num_epochs': 111, 'patience': 11, 'batch_size': 512, 'early_stop_frac': 0.14888620933197066, 'seed': 7882})\n",
      "Model Structure:  GRUD(\n",
      "  (zl): Linear(in_features=329, out_features=121, bias=True)\n",
      "  (rl): Linear(in_features=329, out_features=121, bias=True)\n",
      "  (hl): Linear(in_features=329, out_features=121, bias=True)\n",
      "  (gamma_x_l): FilterLinear(in_features=104, out_features=104, bias=True)\n",
      "  (gamma_h_l): Linear(in_features=104, out_features=121, bias=True)\n",
      "  (fc): Linear(in_features=121, out_features=2, bias=True)\n",
      "  (bn): BatchNorm1d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (drop): Dropout(p=0.5, inplace=False)\n",
      ")\n",
      "Start Training ... \n",
      "Output type dermined by the model\n",
      "Epoch: 0, train_loss: 0.71188362, valid_loss: 0.70526865, time: [3.7], best model: 1\n",
      "Epoch: 1, train_loss: 0.6373628, valid_loss: 0.64602061, time: [3.67], best model: 1\n",
      "Epoch: 2, train_loss: 0.63087979, valid_loss: 0.6388867, time: [3.65], best model: 1\n",
      "Epoch: 3, train_loss: 0.63212027, valid_loss: 0.64232671, time: [3.85], best model: 0\n",
      "Epoch: 4, train_loss: 0.63111842, valid_loss: 0.64245718, time: [3.64], best model: 0\n",
      "Epoch: 5, train_loss: 0.62938528, valid_loss: 0.64815274, time: [3.79], best model: 0\n",
      "Epoch: 6, train_loss: 0.62711737, valid_loss: 0.63767935, time: [3.64], best model: 1\n",
      "Epoch: 7, train_loss: 0.6286667, valid_loss: 0.64824832, time: [3.64], best model: 0\n",
      "Epoch: 8, train_loss: 0.62972874, valid_loss: 0.64532117, time: [3.62], best model: 0\n",
      "Epoch: 9, train_loss: 0.62591828, valid_loss: 0.64496344, time: [3.74], best model: 0\n",
      "Epoch: 10, train_loss: 0.62816132, valid_loss: 0.64210051, time: [3.62], best model: 0\n",
      "Epoch: 11, train_loss: 0.63022564, valid_loss: 0.63847641, time: [3.75], best model: 0\n",
      "Epoch: 12, train_loss: 0.62642797, valid_loss: 0.64987656, time: [3.53], best model: 0\n",
      "Epoch: 13, train_loss: 0.62420852, valid_loss: 0.64482194, time: [3.99], best model: 0\n",
      "Epoch: 14, train_loss: 0.61974956, valid_loss: 0.64566499, time: [3.83], best model: 0\n",
      "Epoch: 15, train_loss: 0.61866146, valid_loss: 0.65297515, time: [3.67], best model: 0\n",
      "Epoch: 16, train_loss: 0.62564256, valid_loss: 0.64828004, time: [3.63], best model: 0\n",
      "Early Stopped at Epoch: 17\n",
      "On sample 4 / 60 (hyperparams = {'cell_size': 93, 'hidden_size': 194, 'learning_rate': 0.06284421578050496, 'num_epochs': 105, 'patience': 11, 'batch_size': 256, 'early_stop_frac': 0.14949502599677933, 'seed': 3185})\n",
      "Model Structure:  GRUD(\n",
      "  (zl): Linear(in_features=402, out_features=194, bias=True)\n",
      "  (rl): Linear(in_features=402, out_features=194, bias=True)\n",
      "  (hl): Linear(in_features=402, out_features=194, bias=True)\n",
      "  (gamma_x_l): FilterLinear(in_features=104, out_features=104, bias=True)\n",
      "  (gamma_h_l): Linear(in_features=104, out_features=194, bias=True)\n",
      "  (fc): Linear(in_features=194, out_features=2, bias=True)\n",
      "  (bn): BatchNorm1d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (drop): Dropout(p=0.5, inplace=False)\n",
      ")\n",
      "Start Training ... \n",
      "Output type dermined by the model\n",
      "Epoch: 0, train_loss: 0.69961909, valid_loss: 0.6863567, time: [5.55], best model: 1\n",
      "Epoch: 1, train_loss: 0.6505052, valid_loss: 0.64886669, time: [5.76], best model: 1\n",
      "Epoch: 2, train_loss: 0.64806588, valid_loss: 0.65174332, time: [5.92], best model: 0\n",
      "Epoch: 3, train_loss: 0.6475855, valid_loss: 0.65026301, time: [5.69], best model: 0\n",
      "Epoch: 4, train_loss: 0.65401341, valid_loss: 0.65580403, time: [5.63], best model: 0\n",
      "Epoch: 5, train_loss: 0.6560447, valid_loss: 0.65431283, time: [5.74], best model: 0\n",
      "Epoch: 6, train_loss: 0.65217722, valid_loss: 0.65121169, time: [5.63], best model: 0\n",
      "Epoch: 7, train_loss: 0.65240125, valid_loss: 0.65662023, time: [5.82], best model: 0\n",
      "Epoch: 8, train_loss: 0.64840941, valid_loss: 0.64855784, time: [6.12], best model: 1\n",
      "Epoch: 9, train_loss: 0.64971473, valid_loss: 0.64914662, time: [5.84], best model: 0\n",
      "Epoch: 10, train_loss: 0.64904861, valid_loss: 0.65140325, time: [5.77], best model: 0\n",
      "Epoch: 11, train_loss: 0.64630196, valid_loss: 0.65009745, time: [5.76], best model: 0\n",
      "Epoch: 12, train_loss: 0.64779289, valid_loss: 0.64886121, time: [5.89], best model: 0\n",
      "Epoch: 13, train_loss: 0.64650393, valid_loss: 0.64327087, time: [5.68], best model: 1\n",
      "Epoch: 14, train_loss: 0.64567497, valid_loss: 0.64086748, time: [5.63], best model: 1\n",
      "Epoch: 15, train_loss: 0.64745719, valid_loss: 0.64586265, time: [5.6], best model: 0\n",
      "Epoch: 16, train_loss: 0.64579717, valid_loss: 0.64564979, time: [5.48], best model: 0\n",
      "Epoch: 17, train_loss: 0.64208936, valid_loss: 0.64275138, time: [5.57], best model: 0\n",
      "Epoch: 18, train_loss: 0.64400343, valid_loss: 0.6484599, time: [5.55], best model: 0\n",
      "Epoch: 19, train_loss: 0.65001935, valid_loss: 0.6496383, time: [5.58], best model: 0\n",
      "Epoch: 20, train_loss: 0.64318251, valid_loss: 0.64799604, time: [5.57], best model: 0\n",
      "Epoch: 21, train_loss: 0.63984528, valid_loss: 0.64614091, time: [5.59], best model: 0\n",
      "Epoch: 22, train_loss: 0.6448822, valid_loss: 0.64517032, time: [5.69], best model: 0\n",
      "Epoch: 23, train_loss: 0.64014948, valid_loss: 0.64717823, time: [5.71], best model: 0\n",
      "Epoch: 24, train_loss: 0.64182399, valid_loss: 0.64776944, time: [5.63], best model: 0\n",
      "Early Stopped at Epoch: 25\n",
      "On sample 5 / 60 (hyperparams = {'cell_size': 125, 'hidden_size': 133, 'learning_rate': 0.0846249828434158, 'num_epochs': 88, 'patience': 9, 'batch_size': 128, 'early_stop_frac': 0.1326150819439797, 'seed': 6044})\n",
      "Model Structure:  GRUD(\n",
      "  (zl): Linear(in_features=341, out_features=133, bias=True)\n",
      "  (rl): Linear(in_features=341, out_features=133, bias=True)\n",
      "  (hl): Linear(in_features=341, out_features=133, bias=True)\n",
      "  (gamma_x_l): FilterLinear(in_features=104, out_features=104, bias=True)\n",
      "  (gamma_h_l): Linear(in_features=104, out_features=133, bias=True)\n",
      "  (fc): Linear(in_features=133, out_features=2, bias=True)\n",
      "  (bn): BatchNorm1d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (drop): Dropout(p=0.5, inplace=False)\n",
      ")\n",
      "Start Training ... \n",
      "Output type dermined by the model\n",
      "Epoch: 0, train_loss: 0.67171721, valid_loss: 0.67356177, time: [8.5], best model: 1\n",
      "Epoch: 1, train_loss: 0.65385734, valid_loss: 0.6683673, time: [8.47], best model: 1\n",
      "Epoch: 2, train_loss: 0.66711169, valid_loss: 0.67157847, time: [8.45], best model: 0\n",
      "Epoch: 3, train_loss: 0.65774489, valid_loss: 0.66309451, time: [8.55], best model: 1\n",
      "Epoch: 4, train_loss: 0.65556734, valid_loss: 0.66793742, time: [8.49], best model: 0\n",
      "Epoch: 5, train_loss: 0.658606, valid_loss: 0.67282077, time: [8.36], best model: 0\n",
      "Epoch: 6, train_loss: 0.65329162, valid_loss: 0.66551951, time: [8.4], best model: 0\n",
      "Epoch: 7, train_loss: 0.65831095, valid_loss: 0.66855905, time: [8.31], best model: 0\n",
      "Epoch: 8, train_loss: 0.66095983, valid_loss: 0.66579437, time: [8.17], best model: 0\n",
      "Epoch: 9, train_loss: 0.65710139, valid_loss: 0.66665886, time: [8.14], best model: 0\n",
      "Epoch: 10, train_loss: 0.65739259, valid_loss: 0.66634571, time: [8.13], best model: 0\n",
      "Epoch: 11, train_loss: 0.65679783, valid_loss: 0.66593845, time: [8.07], best model: 0\n",
      "Early Stopped at Epoch: 12\n",
      "On sample 6 / 60 (hyperparams = {'cell_size': 154, 'hidden_size': 146, 'learning_rate': 0.06435631845621308, 'num_epochs': 83, 'patience': 10, 'batch_size': 64, 'early_stop_frac': 0.11941525454251833, 'seed': 7121})\n",
      "Model Structure:  GRUD(\n",
      "  (zl): Linear(in_features=354, out_features=146, bias=True)\n",
      "  (rl): Linear(in_features=354, out_features=146, bias=True)\n",
      "  (hl): Linear(in_features=354, out_features=146, bias=True)\n",
      "  (gamma_x_l): FilterLinear(in_features=104, out_features=104, bias=True)\n",
      "  (gamma_h_l): Linear(in_features=104, out_features=146, bias=True)\n",
      "  (fc): Linear(in_features=146, out_features=2, bias=True)\n",
      "  (bn): BatchNorm1d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (drop): Dropout(p=0.5, inplace=False)\n",
      ")\n",
      "Start Training ... \n",
      "Output type dermined by the model\n",
      "Epoch: 0, train_loss: 0.6841832, valid_loss: 0.68103684, time: [14.52], best model: 1\n",
      "Epoch: 1, train_loss: 0.66518654, valid_loss: 0.65987834, time: [14.83], best model: 1\n",
      "Epoch: 2, train_loss: 0.66320456, valid_loss: 0.66191745, time: [14.43], best model: 0\n",
      "Epoch: 3, train_loss: 0.65677716, valid_loss: 0.65930793, time: [14.4], best model: 1\n",
      "Epoch: 4, train_loss: 0.65939616, valid_loss: 0.6684155, time: [14.47], best model: 0\n",
      "Epoch: 5, train_loss: 0.66101552, valid_loss: 0.66440005, time: [14.6], best model: 0\n",
      "Epoch: 6, train_loss: 0.66096948, valid_loss: 0.66343178, time: [14.65], best model: 0\n",
      "Epoch: 7, train_loss: 0.65521008, valid_loss: 0.65513996, time: [14.45], best model: 1\n",
      "Epoch: 8, train_loss: 0.6544212, valid_loss: 0.65340722, time: [14.49], best model: 1\n",
      "Epoch: 9, train_loss: 0.65777395, valid_loss: 0.66250816, time: [14.76], best model: 0\n",
      "Epoch: 10, train_loss: 0.65422343, valid_loss: 0.65802665, time: [14.53], best model: 0\n",
      "Epoch: 11, train_loss: 0.65420307, valid_loss: 0.66363061, time: [14.73], best model: 0\n",
      "Epoch: 12, train_loss: 0.65856277, valid_loss: 0.6563259, time: [14.75], best model: 0\n",
      "Epoch: 13, train_loss: 0.65767769, valid_loss: 0.6551643, time: [15.04], best model: 0\n",
      "Epoch: 14, train_loss: 0.65221929, valid_loss: 0.65589003, time: [15.21], best model: 0\n",
      "Epoch: 15, train_loss: 0.65094067, valid_loss: 0.65229127, time: [14.63], best model: 1\n",
      "Epoch: 16, train_loss: 0.64978684, valid_loss: 0.65136414, time: [14.59], best model: 1\n",
      "Epoch: 17, train_loss: 0.64870884, valid_loss: 0.65492169, time: [14.63], best model: 0\n",
      "Epoch: 18, train_loss: 0.65004578, valid_loss: 0.64976369, time: [14.64], best model: 1\n",
      "Epoch: 19, train_loss: 0.65503646, valid_loss: 0.65696053, time: [15.07], best model: 0\n",
      "Epoch: 20, train_loss: 0.64752443, valid_loss: 0.65470269, time: [14.63], best model: 0\n",
      "Epoch: 21, train_loss: 0.64577789, valid_loss: 0.65181268, time: [14.61], best model: 0\n",
      "Epoch: 22, train_loss: 0.64901441, valid_loss: 0.66022564, time: [14.57], best model: 0\n",
      "Epoch: 23, train_loss: 0.64791326, valid_loss: 0.65648445, time: [14.59], best model: 0\n",
      "Epoch: 24, train_loss: 0.64407674, valid_loss: 0.65481528, time: [14.62], best model: 0\n",
      "Epoch: 25, train_loss: 0.64857125, valid_loss: 0.65358323, time: [14.55], best model: 0\n",
      "Epoch: 26, train_loss: 0.64458267, valid_loss: 0.65519137, time: [14.91], best model: 0\n",
      "Epoch: 27, train_loss: 0.64573537, valid_loss: 0.65205125, time: [15.15], best model: 0\n",
      "Early Stopped at Epoch: 28\n",
      "On sample 7 / 60 (hyperparams = {'cell_size': 57, 'hidden_size': 126, 'learning_rate': 0.019671216158442605, 'num_epochs': 96, 'patience': 8, 'batch_size': 256, 'early_stop_frac': 0.12336697980969767, 'seed': 6892})\n",
      "Model Structure:  GRUD(\n",
      "  (zl): Linear(in_features=334, out_features=126, bias=True)\n",
      "  (rl): Linear(in_features=334, out_features=126, bias=True)\n",
      "  (hl): Linear(in_features=334, out_features=126, bias=True)\n",
      "  (gamma_x_l): FilterLinear(in_features=104, out_features=104, bias=True)\n",
      "  (gamma_h_l): Linear(in_features=104, out_features=126, bias=True)\n",
      "  (fc): Linear(in_features=126, out_features=2, bias=True)\n",
      "  (bn): BatchNorm1d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (drop): Dropout(p=0.5, inplace=False)\n",
      ")\n",
      "Start Training ... \n",
      "Output type dermined by the model\n",
      "Epoch: 0, train_loss: 0.73316587, valid_loss: 0.72415737, time: [5.27], best model: 1\n",
      "Epoch: 1, train_loss: 0.63959583, valid_loss: 0.64376858, time: [5.36], best model: 1\n",
      "Epoch: 2, train_loss: 0.63548486, valid_loss: 0.63689429, time: [5.48], best model: 1\n",
      "Epoch: 3, train_loss: 0.62937318, valid_loss: 0.63341977, time: [5.59], best model: 1\n",
      "Epoch: 4, train_loss: 0.62564368, valid_loss: 0.63162352, time: [5.91], best model: 1\n",
      "Epoch: 5, train_loss: 0.62317644, valid_loss: 0.63322355, time: [5.36], best model: 0\n",
      "Epoch: 6, train_loss: 0.62051894, valid_loss: 0.62894928, time: [5.6], best model: 1\n",
      "Epoch: 7, train_loss: 0.61831491, valid_loss: 0.63682315, time: [5.3], best model: 0\n",
      "Epoch: 8, train_loss: 0.61451862, valid_loss: 0.63107708, time: [5.38], best model: 0\n",
      "Epoch: 9, train_loss: 0.61052911, valid_loss: 0.63972165, time: [5.34], best model: 0\n",
      "Epoch: 10, train_loss: 0.60289784, valid_loss: 0.64425887, time: [5.76], best model: 0\n",
      "Epoch: 11, train_loss: 0.59933592, valid_loss: 0.64400228, time: [5.4], best model: 0\n",
      "Epoch: 12, train_loss: 0.59633503, valid_loss: 0.64207037, time: [5.35], best model: 0\n",
      "Epoch: 13, train_loss: 0.5971598, valid_loss: 0.65257009, time: [5.87], best model: 0\n",
      "Early Stopped at Epoch: 14\n",
      "On sample 8 / 60 (hyperparams = {'cell_size': 145, 'hidden_size': 190, 'learning_rate': 0.061125735265354586, 'num_epochs': 141, 'patience': 8, 'batch_size': 128, 'early_stop_frac': 0.13752688098046628, 'seed': 971})\n",
      "Model Structure:  GRUD(\n",
      "  (zl): Linear(in_features=398, out_features=190, bias=True)\n",
      "  (rl): Linear(in_features=398, out_features=190, bias=True)\n",
      "  (hl): Linear(in_features=398, out_features=190, bias=True)\n",
      "  (gamma_x_l): FilterLinear(in_features=104, out_features=104, bias=True)\n",
      "  (gamma_h_l): Linear(in_features=104, out_features=190, bias=True)\n",
      "  (fc): Linear(in_features=190, out_features=2, bias=True)\n",
      "  (bn): BatchNorm1d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (drop): Dropout(p=0.5, inplace=False)\n",
      ")\n",
      "Start Training ... \n",
      "Output type dermined by the model\n",
      "Epoch: 0, train_loss: 0.6926621, valid_loss: 0.68785708, time: [8.51], best model: 1\n",
      "Epoch: 1, train_loss: 0.66626406, valid_loss: 0.66647094, time: [8.58], best model: 1\n",
      "Epoch: 2, train_loss: 0.65984256, valid_loss: 0.66305467, time: [8.95], best model: 1\n",
      "Epoch: 3, train_loss: 0.6629012, valid_loss: 0.66588184, time: [8.56], best model: 0\n",
      "Epoch: 4, train_loss: 0.65512453, valid_loss: 0.66269629, time: [9.42], best model: 1\n",
      "Epoch: 5, train_loss: 0.66342844, valid_loss: 0.6655191, time: [8.68], best model: 0\n",
      "Epoch: 6, train_loss: 0.65531227, valid_loss: 0.66341632, time: [8.48], best model: 0\n",
      "Epoch: 7, train_loss: 0.65864985, valid_loss: 0.65806661, time: [8.42], best model: 1\n",
      "Epoch: 8, train_loss: 0.65417487, valid_loss: 0.65959351, time: [8.77], best model: 0\n",
      "Epoch: 9, train_loss: 0.66018568, valid_loss: 0.66122818, time: [8.57], best model: 0\n",
      "Epoch: 10, train_loss: 0.65259375, valid_loss: 0.6528024, time: [8.49], best model: 1\n",
      "Epoch: 11, train_loss: 0.65327719, valid_loss: 0.65613488, time: [8.6], best model: 0\n",
      "Epoch: 12, train_loss: 0.65864979, valid_loss: 0.66105734, time: [8.49], best model: 0\n",
      "Epoch: 13, train_loss: 0.65450185, valid_loss: 0.65609012, time: [8.34], best model: 0\n",
      "Epoch: 14, train_loss: 0.65098885, valid_loss: 0.65096787, time: [8.45], best model: 1\n",
      "Epoch: 15, train_loss: 0.65191119, valid_loss: 0.65223803, time: [8.56], best model: 0\n",
      "Epoch: 16, train_loss: 0.65315723, valid_loss: 0.65332406, time: [8.71], best model: 0\n",
      "Epoch: 17, train_loss: 0.65051426, valid_loss: 0.65981109, time: [8.47], best model: 0\n",
      "Epoch: 18, train_loss: 0.65184069, valid_loss: 0.65546431, time: [8.39], best model: 0\n",
      "Epoch: 19, train_loss: 0.65062898, valid_loss: 0.65121603, time: [8.3], best model: 0\n",
      "Epoch: 20, train_loss: 0.64876481, valid_loss: 0.65245056, time: [8.36], best model: 0\n",
      "Epoch: 21, train_loss: 0.64490891, valid_loss: 0.64694384, time: [8.34], best model: 1\n",
      "Epoch: 22, train_loss: 0.64953886, valid_loss: 0.65154982, time: [8.34], best model: 0\n",
      "Epoch: 23, train_loss: 0.64709282, valid_loss: 0.65446084, time: [8.41], best model: 0\n",
      "Epoch: 24, train_loss: 0.64448227, valid_loss: 0.65279082, time: [8.33], best model: 0\n",
      "Epoch: 25, train_loss: 0.65167665, valid_loss: 0.65352045, time: [8.35], best model: 0\n",
      "Epoch: 26, train_loss: 0.64723028, valid_loss: 0.6542748, time: [8.35], best model: 0\n",
      "Epoch: 27, train_loss: 0.64363159, valid_loss: 0.65030677, time: [8.31], best model: 0\n",
      "Epoch: 28, train_loss: 0.64341961, valid_loss: 0.64975752, time: [8.34], best model: 0\n",
      "Early Stopped at Epoch: 29\n",
      "On sample 9 / 60 (hyperparams = {'cell_size': 125, 'hidden_size': 162, 'learning_rate': 0.05092661669948592, 'num_epochs': 142, 'patience': 10, 'batch_size': 256, 'early_stop_frac': 0.14515101483457324, 'seed': 589})\n",
      "Model Structure:  GRUD(\n",
      "  (zl): Linear(in_features=370, out_features=162, bias=True)\n",
      "  (rl): Linear(in_features=370, out_features=162, bias=True)\n",
      "  (hl): Linear(in_features=370, out_features=162, bias=True)\n",
      "  (gamma_x_l): FilterLinear(in_features=104, out_features=104, bias=True)\n",
      "  (gamma_h_l): Linear(in_features=104, out_features=162, bias=True)\n",
      "  (fc): Linear(in_features=162, out_features=2, bias=True)\n",
      "  (bn): BatchNorm1d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (drop): Dropout(p=0.5, inplace=False)\n",
      ")\n",
      "Start Training ... \n",
      "Output type dermined by the model\n",
      "Epoch: 0, train_loss: 0.68812492, valid_loss: 0.68084467, time: [6.17], best model: 1\n",
      "Epoch: 1, train_loss: 0.63950015, valid_loss: 0.6472881, time: [5.99], best model: 1\n",
      "Epoch: 2, train_loss: 0.64576381, valid_loss: 0.65779467, time: [6.21], best model: 0\n",
      "Epoch: 3, train_loss: 0.64938736, valid_loss: 0.65859389, time: [5.87], best model: 0\n",
      "Epoch: 4, train_loss: 0.64867353, valid_loss: 0.65366142, time: [6.22], best model: 0\n",
      "Epoch: 5, train_loss: 0.6493773, valid_loss: 0.65681319, time: [6.], best model: 0\n",
      "Epoch: 6, train_loss: 0.64401675, valid_loss: 0.65469353, time: [5.87], best model: 0\n",
      "Epoch: 7, train_loss: 0.64502106, valid_loss: 0.65262971, time: [6.31], best model: 0\n",
      "Epoch: 8, train_loss: 0.63742593, valid_loss: 0.65465143, time: [6.47], best model: 0\n",
      "Epoch: 9, train_loss: 0.63872771, valid_loss: 0.64980108, time: [6.06], best model: 0\n",
      "Epoch: 10, train_loss: 0.63675482, valid_loss: 0.65101263, time: [5.89], best model: 0\n",
      "Early Stopped at Epoch: 11\n",
      "On sample 10 / 60 (hyperparams = {'cell_size': 97, 'hidden_size': 152, 'learning_rate': 0.056790778009037673, 'num_epochs': 98, 'patience': 11, 'batch_size': 256, 'early_stop_frac': 0.1352262926597551, 'seed': 2159})\n",
      "Model Structure:  GRUD(\n",
      "  (zl): Linear(in_features=360, out_features=152, bias=True)\n",
      "  (rl): Linear(in_features=360, out_features=152, bias=True)\n",
      "  (hl): Linear(in_features=360, out_features=152, bias=True)\n",
      "  (gamma_x_l): FilterLinear(in_features=104, out_features=104, bias=True)\n",
      "  (gamma_h_l): Linear(in_features=104, out_features=152, bias=True)\n",
      "  (fc): Linear(in_features=152, out_features=2, bias=True)\n",
      "  (bn): BatchNorm1d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (drop): Dropout(p=0.5, inplace=False)\n",
      ")\n",
      "Start Training ... \n",
      "Output type dermined by the model\n",
      "Epoch: 0, train_loss: 0.69350018, valid_loss: 0.68447515, time: [5.98], best model: 1\n",
      "Epoch: 1, train_loss: 0.652946, valid_loss: 0.65064103, time: [6.09], best model: 1\n",
      "Epoch: 2, train_loss: 0.6502332, valid_loss: 0.65100431, time: [5.79], best model: 0\n",
      "Epoch: 3, train_loss: 0.64504385, valid_loss: 0.64634773, time: [5.68], best model: 1\n",
      "Epoch: 4, train_loss: 0.64154741, valid_loss: 0.63747072, time: [5.67], best model: 1\n",
      "Epoch: 5, train_loss: 0.64062343, valid_loss: 0.64205136, time: [5.7], best model: 0\n",
      "Epoch: 6, train_loss: 0.64564392, valid_loss: 0.65039035, time: [5.78], best model: 0\n",
      "Epoch: 7, train_loss: 0.64502839, valid_loss: 0.64904179, time: [5.79], best model: 0\n",
      "Epoch: 8, train_loss: 0.64773035, valid_loss: 0.64555447, time: [5.87], best model: 0\n",
      "Epoch: 9, train_loss: 0.64109244, valid_loss: 0.64711257, time: [5.72], best model: 0\n",
      "Epoch: 10, train_loss: 0.64214672, valid_loss: 0.65257747, time: [5.76], best model: 0\n",
      "Epoch: 11, train_loss: 0.6403718, valid_loss: 0.65022939, time: [5.86], best model: 0\n",
      "Epoch: 12, train_loss: 0.6376056, valid_loss: 0.66237681, time: [5.75], best model: 0\n",
      "Epoch: 13, train_loss: 0.63597005, valid_loss: 0.65844236, time: [5.64], best model: 0\n",
      "Epoch: 14, train_loss: 0.63118437, valid_loss: 0.65725088, time: [5.64], best model: 0\n",
      "Early Stopped at Epoch: 15\n",
      "On sample 11 / 60 (hyperparams = {'cell_size': 113, 'hidden_size': 108, 'learning_rate': 0.07195206197905482, 'num_epochs': 134, 'patience': 11, 'batch_size': 256, 'early_stop_frac': 0.11409386397788643, 'seed': 8469})\n",
      "Model Structure:  GRUD(\n",
      "  (zl): Linear(in_features=316, out_features=108, bias=True)\n",
      "  (rl): Linear(in_features=316, out_features=108, bias=True)\n",
      "  (hl): Linear(in_features=316, out_features=108, bias=True)\n",
      "  (gamma_x_l): FilterLinear(in_features=104, out_features=104, bias=True)\n",
      "  (gamma_h_l): Linear(in_features=104, out_features=108, bias=True)\n",
      "  (fc): Linear(in_features=108, out_features=2, bias=True)\n",
      "  (bn): BatchNorm1d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (drop): Dropout(p=0.5, inplace=False)\n",
      ")\n",
      "Start Training ... \n",
      "Output type dermined by the model\n",
      "Epoch: 0, train_loss: 0.68405921, valid_loss: 0.67303467, time: [5.05], best model: 1\n",
      "Epoch: 1, train_loss: 0.6458314, valid_loss: 0.64560075, time: [5.13], best model: 1\n",
      "Epoch: 2, train_loss: 0.64369655, valid_loss: 0.64432914, time: [5.], best model: 1\n",
      "Epoch: 3, train_loss: 0.64074996, valid_loss: 0.64091604, time: [5.08], best model: 1\n",
      "Epoch: 4, train_loss: 0.63893897, valid_loss: 0.64106191, time: [5.02], best model: 0\n",
      "Epoch: 5, train_loss: 0.64251623, valid_loss: 0.64901852, time: [5.12], best model: 0\n",
      "Epoch: 6, train_loss: 0.65307571, valid_loss: 0.65289366, time: [5.42], best model: 0\n",
      "Epoch: 7, train_loss: 0.64337809, valid_loss: 0.64438682, time: [5.56], best model: 0\n",
      "Epoch: 8, train_loss: 0.64589454, valid_loss: 0.6467566, time: [5.02], best model: 0\n",
      "Epoch: 9, train_loss: 0.64329608, valid_loss: 0.64398193, time: [5.02], best model: 0\n",
      "Epoch: 10, train_loss: 0.64337632, valid_loss: 0.64099713, time: [5.03], best model: 0\n",
      "Epoch: 11, train_loss: 0.64468009, valid_loss: 0.64608982, time: [5.], best model: 0\n",
      "Epoch: 12, train_loss: 0.64506768, valid_loss: 0.64724455, time: [5.11], best model: 0\n",
      "Epoch: 13, train_loss: 0.64385144, valid_loss: 0.6432745, time: [5.14], best model: 0\n",
      "Early Stopped at Epoch: 14\n",
      "On sample 12 / 60 (hyperparams = {'cell_size': 81, 'hidden_size': 117, 'learning_rate': 0.026581116390413072, 'num_epochs': 86, 'patience': 10, 'batch_size': 512, 'early_stop_frac': 0.05734983847144366, 'seed': 6248})\n",
      "Model Structure:  GRUD(\n",
      "  (zl): Linear(in_features=325, out_features=117, bias=True)\n",
      "  (rl): Linear(in_features=325, out_features=117, bias=True)\n",
      "  (hl): Linear(in_features=325, out_features=117, bias=True)\n",
      "  (gamma_x_l): FilterLinear(in_features=104, out_features=104, bias=True)\n",
      "  (gamma_h_l): Linear(in_features=104, out_features=117, bias=True)\n",
      "  (fc): Linear(in_features=117, out_features=2, bias=True)\n",
      "  (bn): BatchNorm1d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (drop): Dropout(p=0.5, inplace=False)\n",
      ")\n",
      "Start Training ... \n",
      "Output type dermined by the model\n",
      "Epoch: 0, train_loss: 0.75344423, valid_loss: 0.7386905, time: [4.48], best model: 1\n",
      "Epoch: 1, train_loss: 0.64311434, valid_loss: 0.63853817, time: [4.17], best model: 1\n",
      "Epoch: 2, train_loss: 0.63634491, valid_loss: 0.637887, time: [4.32], best model: 1\n",
      "Epoch: 3, train_loss: 0.62795798, valid_loss: 0.63179588, time: [4.38], best model: 1\n",
      "Epoch: 4, train_loss: 0.62901014, valid_loss: 0.63103809, time: [4.51], best model: 1\n",
      "Epoch: 5, train_loss: 0.62713521, valid_loss: 0.62460175, time: [4.31], best model: 1\n",
      "Epoch: 6, train_loss: 0.62459609, valid_loss: 0.6249424, time: [4.35], best model: 0\n",
      "Epoch: 7, train_loss: 0.62116483, valid_loss: 0.62646147, time: [4.15], best model: 0\n",
      "Epoch: 8, train_loss: 0.62127921, valid_loss: 0.62224611, time: [4.13], best model: 1\n",
      "Epoch: 9, train_loss: 0.61414038, valid_loss: 0.62357413, time: [4.11], best model: 0\n",
      "Epoch: 10, train_loss: 0.61088702, valid_loss: 0.63320128, time: [4.05], best model: 0\n",
      "Epoch: 11, train_loss: 0.62305489, valid_loss: 0.63505109, time: [4.16], best model: 0\n",
      "Epoch: 12, train_loss: 0.61862354, valid_loss: 0.6263389, time: [4.03], best model: 0\n",
      "Epoch: 13, train_loss: 0.62157065, valid_loss: 0.63425166, time: [4.08], best model: 0\n",
      "Epoch: 14, train_loss: 0.62085234, valid_loss: 0.62542731, time: [4.05], best model: 0\n",
      "Epoch: 15, train_loss: 0.62133134, valid_loss: 0.63026015, time: [4.07], best model: 0\n",
      "Epoch: 16, train_loss: 0.62056033, valid_loss: 0.63449338, time: [4.13], best model: 0\n",
      "Epoch: 17, train_loss: 0.6144132, valid_loss: 0.64028753, time: [4.13], best model: 0\n",
      "Early Stopped at Epoch: 18\n",
      "On sample 13 / 60 (hyperparams = {'cell_size': 198, 'hidden_size': 81, 'learning_rate': 0.020662714558648022, 'num_epochs': 122, 'patience': 8, 'batch_size': 128, 'early_stop_frac': 0.11233847142958386, 'seed': 3991})\n",
      "Model Structure:  GRUD(\n",
      "  (zl): Linear(in_features=289, out_features=81, bias=True)\n",
      "  (rl): Linear(in_features=289, out_features=81, bias=True)\n",
      "  (hl): Linear(in_features=289, out_features=81, bias=True)\n",
      "  (gamma_x_l): FilterLinear(in_features=104, out_features=104, bias=True)\n",
      "  (gamma_h_l): Linear(in_features=104, out_features=81, bias=True)\n",
      "  (fc): Linear(in_features=81, out_features=2, bias=True)\n",
      "  (bn): BatchNorm1d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (drop): Dropout(p=0.5, inplace=False)\n",
      ")\n",
      "Start Training ... \n",
      "Output type dermined by the model\n",
      "Epoch: 0, train_loss: 0.67918015, valid_loss: 0.66820888, time: [8.36], best model: 1\n",
      "Epoch: 1, train_loss: 0.63451971, valid_loss: 0.62844408, time: [8.33], best model: 1\n",
      "Epoch: 2, train_loss: 0.63155845, valid_loss: 0.62943748, time: [8.43], best model: 0\n",
      "Epoch: 3, train_loss: 0.62435078, valid_loss: 0.6254915, time: [8.34], best model: 1\n",
      "Epoch: 4, train_loss: 0.62940894, valid_loss: 0.63145388, time: [8.28], best model: 0\n",
      "Epoch: 5, train_loss: 0.62559851, valid_loss: 0.63210323, time: [8.31], best model: 0\n",
      "Epoch: 6, train_loss: 0.63066068, valid_loss: 0.63395928, time: [8.29], best model: 0\n",
      "Epoch: 7, train_loss: 0.63652196, valid_loss: 0.63543774, time: [8.28], best model: 0\n",
      "Epoch: 8, train_loss: 0.63044759, valid_loss: 0.6322572, time: [8.22], best model: 0\n",
      "Epoch: 9, train_loss: 0.63101939, valid_loss: 0.63596193, time: [8.31], best model: 0\n",
      "Epoch: 10, train_loss: 0.63045791, valid_loss: 0.63317779, time: [8.25], best model: 0\n",
      "Early Stopped at Epoch: 11\n",
      "On sample 14 / 60 (hyperparams = {'cell_size': 174, 'hidden_size': 120, 'learning_rate': 0.013058314779616107, 'num_epochs': 93, 'patience': 10, 'batch_size': 256, 'early_stop_frac': 0.08532138917855187, 'seed': 2438})\n",
      "Model Structure:  GRUD(\n",
      "  (zl): Linear(in_features=328, out_features=120, bias=True)\n",
      "  (rl): Linear(in_features=328, out_features=120, bias=True)\n",
      "  (hl): Linear(in_features=328, out_features=120, bias=True)\n",
      "  (gamma_x_l): FilterLinear(in_features=104, out_features=104, bias=True)\n",
      "  (gamma_h_l): Linear(in_features=104, out_features=120, bias=True)\n",
      "  (fc): Linear(in_features=120, out_features=2, bias=True)\n",
      "  (bn): BatchNorm1d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (drop): Dropout(p=0.5, inplace=False)\n",
      ")\n",
      "Start Training ... \n",
      "Output type dermined by the model\n",
      "Epoch: 0, train_loss: 0.71875304, valid_loss: 0.7134402, time: [5.31], best model: 1\n",
      "Epoch: 1, train_loss: 0.63146682, valid_loss: 0.63935037, time: [5.3], best model: 1\n",
      "Epoch: 2, train_loss: 0.62396531, valid_loss: 0.63713733, time: [5.27], best model: 1\n",
      "Epoch: 3, train_loss: 0.61876737, valid_loss: 0.63690405, time: [5.21], best model: 1\n",
      "Epoch: 4, train_loss: 0.61503659, valid_loss: 0.639866, time: [5.24], best model: 0\n",
      "Epoch: 5, train_loss: 0.60957233, valid_loss: 0.640788, time: [5.24], best model: 0\n",
      "Epoch: 6, train_loss: 0.60356166, valid_loss: 0.64322772, time: [5.23], best model: 0\n",
      "Epoch: 7, train_loss: 0.60624029, valid_loss: 0.64861944, time: [5.3], best model: 0\n",
      "Epoch: 8, train_loss: 0.59874648, valid_loss: 0.65624017, time: [5.22], best model: 0\n",
      "Epoch: 9, train_loss: 0.58436707, valid_loss: 0.66121544, time: [5.31], best model: 0\n",
      "Epoch: 10, train_loss: 0.58343402, valid_loss: 0.66630606, time: [5.25], best model: 0\n",
      "Epoch: 11, train_loss: 0.57741973, valid_loss: 0.6635309, time: [5.25], best model: 0\n",
      "Epoch: 12, train_loss: 0.56652703, valid_loss: 0.67822996, time: [5.32], best model: 0\n",
      "Early Stopped at Epoch: 13\n",
      "On sample 15 / 60 (hyperparams = {'cell_size': 166, 'hidden_size': 188, 'learning_rate': 0.029405925253605372, 'num_epochs': 62, 'patience': 10, 'batch_size': 64, 'early_stop_frac': 0.06647786232242964, 'seed': 9245})\n",
      "Model Structure:  GRUD(\n",
      "  (zl): Linear(in_features=396, out_features=188, bias=True)\n",
      "  (rl): Linear(in_features=396, out_features=188, bias=True)\n",
      "  (hl): Linear(in_features=396, out_features=188, bias=True)\n",
      "  (gamma_x_l): FilterLinear(in_features=104, out_features=104, bias=True)\n",
      "  (gamma_h_l): Linear(in_features=104, out_features=188, bias=True)\n",
      "  (fc): Linear(in_features=188, out_features=2, bias=True)\n",
      "  (bn): BatchNorm1d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (drop): Dropout(p=0.5, inplace=False)\n",
      ")\n",
      "Start Training ... \n",
      "Output type dermined by the model\n",
      "Epoch: 0, train_loss: 0.67593884, valid_loss: 0.66763274, time: [15.57], best model: 1\n",
      "Epoch: 1, train_loss: 0.65329423, valid_loss: 0.65152228, time: [15.61], best model: 1\n",
      "Epoch: 2, train_loss: 0.65227434, valid_loss: 0.64876919, time: [15.7], best model: 1\n",
      "Epoch: 3, train_loss: 0.65363781, valid_loss: 0.65124443, time: [15.74], best model: 0\n",
      "Epoch: 4, train_loss: 0.64457546, valid_loss: 0.64286266, time: [15.77], best model: 1\n",
      "Epoch: 5, train_loss: 0.65053252, valid_loss: 0.65158863, time: [15.69], best model: 0\n",
      "Epoch: 6, train_loss: 0.64461242, valid_loss: 0.65275267, time: [15.68], best model: 0\n",
      "Epoch: 7, train_loss: 0.64056553, valid_loss: 0.6489346, time: [15.93], best model: 0\n",
      "Epoch: 8, train_loss: 0.64312982, valid_loss: 0.64705989, time: [16.33], best model: 0\n",
      "Epoch: 9, train_loss: 0.63826814, valid_loss: 0.64671401, time: [15.77], best model: 0\n",
      "Epoch: 10, train_loss: 0.64214456, valid_loss: 0.64312338, time: [15.42], best model: 0\n",
      "Epoch: 11, train_loss: 0.63999107, valid_loss: 0.64371134, time: [15.54], best model: 0\n",
      "Epoch: 12, train_loss: 0.63616162, valid_loss: 0.6399907, time: [15.62], best model: 1\n",
      "Epoch: 13, train_loss: 0.63656841, valid_loss: 0.6447999, time: [15.61], best model: 0\n",
      "Epoch: 14, train_loss: 0.63706551, valid_loss: 0.64509614, time: [15.52], best model: 0\n",
      "Epoch: 15, train_loss: 0.63655109, valid_loss: 0.64560024, time: [15.44], best model: 0\n",
      "Epoch: 16, train_loss: 0.64617382, valid_loss: 0.64954626, time: [15.49], best model: 0\n",
      "Epoch: 17, train_loss: 0.64730679, valid_loss: 0.65343688, time: [15.58], best model: 0\n",
      "Epoch: 18, train_loss: 0.65013854, valid_loss: 0.65578817, time: [15.69], best model: 0\n",
      "Epoch: 19, train_loss: 0.64484674, valid_loss: 0.65639252, time: [15.53], best model: 0\n",
      "Epoch: 20, train_loss: 0.64603261, valid_loss: 0.64931419, time: [15.57], best model: 0\n",
      "Epoch: 21, train_loss: 0.6419335, valid_loss: 0.6439092, time: [15.49], best model: 0\n",
      "Early Stopped at Epoch: 22\n",
      "On sample 16 / 60 (hyperparams = {'cell_size': 87, 'hidden_size': 108, 'learning_rate': 0.0030250039399590907, 'num_epochs': 119, 'patience': 11, 'batch_size': 128, 'early_stop_frac': 0.13931661865670436, 'seed': 6518})\n",
      "Model Structure:  GRUD(\n",
      "  (zl): Linear(in_features=316, out_features=108, bias=True)\n",
      "  (rl): Linear(in_features=316, out_features=108, bias=True)\n",
      "  (hl): Linear(in_features=316, out_features=108, bias=True)\n",
      "  (gamma_x_l): FilterLinear(in_features=104, out_features=104, bias=True)\n",
      "  (gamma_h_l): Linear(in_features=104, out_features=108, bias=True)\n",
      "  (fc): Linear(in_features=108, out_features=2, bias=True)\n",
      "  (bn): BatchNorm1d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (drop): Dropout(p=0.5, inplace=False)\n",
      ")\n",
      "Start Training ... \n",
      "Output type dermined by the model\n",
      "Epoch: 0, train_loss: 0.75491183, valid_loss: 0.74496841, time: [8.17], best model: 1\n",
      "Epoch: 1, train_loss: 0.6671789, valid_loss: 0.66302879, time: [8.03], best model: 1\n",
      "Epoch: 2, train_loss: 0.63356447, valid_loss: 0.64084332, time: [7.99], best model: 1\n",
      "Epoch: 3, train_loss: 0.62318414, valid_loss: 0.62791232, time: [8.02], best model: 1\n",
      "Epoch: 4, train_loss: 0.6139132, valid_loss: 0.62728453, time: [8.08], best model: 1\n",
      "Epoch: 5, train_loss: 0.61118977, valid_loss: 0.62430688, time: [8.08], best model: 1\n",
      "Epoch: 6, train_loss: 0.60859714, valid_loss: 0.63246257, time: [8.12], best model: 0\n",
      "Epoch: 7, train_loss: 0.60252196, valid_loss: 0.63490786, time: [8.06], best model: 0\n",
      "Epoch: 8, train_loss: 0.59784249, valid_loss: 0.63773257, time: [8.01], best model: 0\n",
      "Epoch: 9, train_loss: 0.5852903, valid_loss: 0.64235319, time: [7.88], best model: 0\n",
      "Epoch: 10, train_loss: 0.57423673, valid_loss: 0.65616574, time: [7.89], best model: 0\n",
      "Epoch: 11, train_loss: 0.56412383, valid_loss: 0.66676038, time: [7.86], best model: 0\n",
      "Epoch: 12, train_loss: 0.54665477, valid_loss: 0.68221821, time: [7.94], best model: 0\n",
      "Epoch: 13, train_loss: 0.52319029, valid_loss: 0.70582655, time: [8.], best model: 0\n",
      "Epoch: 14, train_loss: 0.5108381, valid_loss: 0.7327872, time: [7.89], best model: 0\n",
      "Epoch: 15, train_loss: 0.48375123, valid_loss: 0.76426172, time: [8.07], best model: 0\n",
      "Early Stopped at Epoch: 16\n",
      "On sample 17 / 60 (hyperparams = {'cell_size': 152, 'hidden_size': 135, 'learning_rate': 0.06493597228295822, 'num_epochs': 117, 'patience': 10, 'batch_size': 512, 'early_stop_frac': 0.13248904812066795, 'seed': 1450})\n",
      "Model Structure:  GRUD(\n",
      "  (zl): Linear(in_features=343, out_features=135, bias=True)\n",
      "  (rl): Linear(in_features=343, out_features=135, bias=True)\n",
      "  (hl): Linear(in_features=343, out_features=135, bias=True)\n",
      "  (gamma_x_l): FilterLinear(in_features=104, out_features=104, bias=True)\n",
      "  (gamma_h_l): Linear(in_features=104, out_features=135, bias=True)\n",
      "  (fc): Linear(in_features=135, out_features=2, bias=True)\n",
      "  (bn): BatchNorm1d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (drop): Dropout(p=0.5, inplace=False)\n",
      ")\n",
      "Start Training ... \n",
      "Output type dermined by the model\n",
      "Epoch: 0, train_loss: 0.71016291, valid_loss: 0.69709819, time: [3.83], best model: 1\n",
      "Epoch: 1, train_loss: 0.65606594, valid_loss: 0.64905562, time: [3.8], best model: 1\n",
      "Epoch: 2, train_loss: 0.64301171, valid_loss: 0.64694234, time: [3.81], best model: 1\n",
      "Epoch: 3, train_loss: 0.64008147, valid_loss: 0.64372771, time: [3.78], best model: 1\n",
      "Epoch: 4, train_loss: 0.64262921, valid_loss: 0.65014253, time: [3.93], best model: 0\n",
      "Epoch: 5, train_loss: 0.64402785, valid_loss: 0.64372008, time: [3.87], best model: 0\n",
      "Epoch: 6, train_loss: 0.64639657, valid_loss: 0.64843103, time: [3.79], best model: 0\n",
      "Epoch: 7, train_loss: 0.64715978, valid_loss: 0.64393296, time: [3.79], best model: 0\n",
      "Epoch: 8, train_loss: 0.64022391, valid_loss: 0.64371354, time: [3.89], best model: 1\n",
      "Epoch: 9, train_loss: 0.64160599, valid_loss: 0.64473193, time: [3.81], best model: 0\n",
      "Epoch: 10, train_loss: 0.63773796, valid_loss: 0.6432128, time: [3.77], best model: 1\n",
      "Epoch: 11, train_loss: 0.6399827, valid_loss: 0.64079564, time: [3.84], best model: 1\n",
      "Epoch: 12, train_loss: 0.63431672, valid_loss: 0.63836316, time: [3.78], best model: 1\n",
      "Epoch: 13, train_loss: 0.63617795, valid_loss: 0.64580781, time: [3.99], best model: 0\n",
      "Epoch: 14, train_loss: 0.63766834, valid_loss: 0.64272663, time: [4.05], best model: 0\n",
      "Epoch: 15, train_loss: 0.63682229, valid_loss: 0.64702191, time: [3.94], best model: 0\n",
      "Epoch: 16, train_loss: 0.63267429, valid_loss: 0.64144741, time: [3.88], best model: 0\n",
      "Epoch: 17, train_loss: 0.63169418, valid_loss: 0.64163869, time: [3.88], best model: 0\n",
      "Epoch: 18, train_loss: 0.63579982, valid_loss: 0.6422314, time: [3.94], best model: 0\n",
      "Epoch: 19, train_loss: 0.63423763, valid_loss: 0.64477416, time: [3.84], best model: 0\n",
      "Epoch: 20, train_loss: 0.63570867, valid_loss: 0.64447165, time: [3.86], best model: 0\n",
      "Epoch: 21, train_loss: 0.63440548, valid_loss: 0.64326899, time: [3.75], best model: 0\n",
      "Early Stopped at Epoch: 22\n",
      "On sample 18 / 60 (hyperparams = {'cell_size': 54, 'hidden_size': 124, 'learning_rate': 0.03151723052197425, 'num_epochs': 98, 'patience': 10, 'batch_size': 128, 'early_stop_frac': 0.10266384238528334, 'seed': 1271})\n",
      "Model Structure:  GRUD(\n",
      "  (zl): Linear(in_features=332, out_features=124, bias=True)\n",
      "  (rl): Linear(in_features=332, out_features=124, bias=True)\n",
      "  (hl): Linear(in_features=332, out_features=124, bias=True)\n",
      "  (gamma_x_l): FilterLinear(in_features=104, out_features=104, bias=True)\n",
      "  (gamma_h_l): Linear(in_features=104, out_features=124, bias=True)\n",
      "  (fc): Linear(in_features=124, out_features=2, bias=True)\n",
      "  (bn): BatchNorm1d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (drop): Dropout(p=0.5, inplace=False)\n",
      ")\n",
      "Start Training ... \n",
      "Output type dermined by the model\n",
      "Epoch: 0, train_loss: 0.67243664, valid_loss: 0.66424717, time: [8.45], best model: 1\n",
      "Epoch: 1, train_loss: 0.64081723, valid_loss: 0.63673153, time: [8.51], best model: 1\n",
      "Epoch: 2, train_loss: 0.63682106, valid_loss: 0.64046309, time: [8.53], best model: 0\n",
      "Epoch: 3, train_loss: 0.63770738, valid_loss: 0.64152853, time: [8.66], best model: 0\n",
      "Epoch: 4, train_loss: 0.64090266, valid_loss: 0.64509961, time: [8.59], best model: 0\n",
      "Epoch: 5, train_loss: 0.64579153, valid_loss: 0.64748148, time: [8.43], best model: 0\n",
      "Epoch: 6, train_loss: 0.63680978, valid_loss: 0.64112737, time: [8.47], best model: 0\n",
      "Epoch: 7, train_loss: 0.63838059, valid_loss: 0.64377555, time: [8.46], best model: 0\n",
      "Epoch: 8, train_loss: 0.63592288, valid_loss: 0.64489003, time: [8.51], best model: 0\n",
      "Epoch: 9, train_loss: 0.63837107, valid_loss: 0.64642171, time: [8.45], best model: 0\n",
      "Epoch: 10, train_loss: 0.64042651, valid_loss: 0.65318592, time: [8.4], best model: 0\n",
      "Early Stopped at Epoch: 11\n",
      "On sample 19 / 60 (hyperparams = {'cell_size': 157, 'hidden_size': 82, 'learning_rate': 0.020728654470189775, 'num_epochs': 145, 'patience': 11, 'batch_size': 256, 'early_stop_frac': 0.09634492561535725, 'seed': 4848})\n",
      "Model Structure:  GRUD(\n",
      "  (zl): Linear(in_features=290, out_features=82, bias=True)\n",
      "  (rl): Linear(in_features=290, out_features=82, bias=True)\n",
      "  (hl): Linear(in_features=290, out_features=82, bias=True)\n",
      "  (gamma_x_l): FilterLinear(in_features=104, out_features=104, bias=True)\n",
      "  (gamma_h_l): Linear(in_features=104, out_features=82, bias=True)\n",
      "  (fc): Linear(in_features=82, out_features=2, bias=True)\n",
      "  (bn): BatchNorm1d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (drop): Dropout(p=0.5, inplace=False)\n",
      ")\n",
      "Start Training ... \n",
      "Output type dermined by the model\n",
      "Epoch: 0, train_loss: 0.6978933, valid_loss: 0.70211488, time: [5.18], best model: 1\n",
      "Epoch: 1, train_loss: 0.63017098, valid_loss: 0.63589297, time: [5.24], best model: 1\n",
      "Epoch: 2, train_loss: 0.62493353, valid_loss: 0.6369625, time: [5.32], best model: 0\n",
      "Epoch: 3, train_loss: 0.62407115, valid_loss: 0.6358554, time: [5.19], best model: 1\n",
      "Epoch: 4, train_loss: 0.62049303, valid_loss: 0.63645903, time: [5.13], best model: 0\n",
      "Epoch: 5, train_loss: 0.61162619, valid_loss: 0.63110836, time: [5.03], best model: 1\n",
      "Epoch: 6, train_loss: 0.61280803, valid_loss: 0.63931261, time: [5.07], best model: 0\n",
      "Epoch: 7, train_loss: 0.60594358, valid_loss: 0.63904688, time: [5.08], best model: 0\n",
      "Epoch: 8, train_loss: 0.60117916, valid_loss: 0.64149255, time: [5.06], best model: 0\n",
      "Epoch: 9, train_loss: 0.59401412, valid_loss: 0.6457634, time: [5.05], best model: 0\n",
      "Epoch: 10, train_loss: 0.58517385, valid_loss: 0.65474875, time: [5.09], best model: 0\n",
      "Epoch: 11, train_loss: 0.58490798, valid_loss: 0.65332277, time: [5.07], best model: 0\n",
      "Epoch: 12, train_loss: 0.57779351, valid_loss: 0.66201097, time: [5.03], best model: 0\n",
      "Epoch: 13, train_loss: 0.57227351, valid_loss: 0.67093594, time: [5.08], best model: 0\n",
      "Epoch: 14, train_loss: 0.56671369, valid_loss: 0.67031615, time: [5.04], best model: 0\n",
      "Epoch: 15, train_loss: 0.56693216, valid_loss: 0.67738931, time: [5.07], best model: 0\n",
      "Early Stopped at Epoch: 16\n",
      "On sample 20 / 60 (hyperparams = {'cell_size': 101, 'hidden_size': 91, 'learning_rate': 0.011528805226080373, 'num_epochs': 136, 'patience': 11, 'batch_size': 128, 'early_stop_frac': 0.09893012881271257, 'seed': 6447})\n",
      "Model Structure:  GRUD(\n",
      "  (zl): Linear(in_features=299, out_features=91, bias=True)\n",
      "  (rl): Linear(in_features=299, out_features=91, bias=True)\n",
      "  (hl): Linear(in_features=299, out_features=91, bias=True)\n",
      "  (gamma_x_l): FilterLinear(in_features=104, out_features=104, bias=True)\n",
      "  (gamma_h_l): Linear(in_features=104, out_features=91, bias=True)\n",
      "  (fc): Linear(in_features=91, out_features=2, bias=True)\n",
      "  (bn): BatchNorm1d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (drop): Dropout(p=0.5, inplace=False)\n",
      ")\n",
      "Start Training ... \n",
      "Output type dermined by the model\n",
      "Epoch: 0, train_loss: 0.6960189, valid_loss: 0.68525507, time: [8.37], best model: 1\n",
      "Epoch: 1, train_loss: 0.63144267, valid_loss: 0.63483312, time: [8.19], best model: 1\n",
      "Epoch: 2, train_loss: 0.6221693, valid_loss: 0.63393154, time: [8.22], best model: 1\n",
      "Epoch: 3, train_loss: 0.62099574, valid_loss: 0.63459582, time: [8.22], best model: 0\n",
      "Epoch: 4, train_loss: 0.61485864, valid_loss: 0.63480821, time: [8.37], best model: 0\n",
      "Epoch: 5, train_loss: 0.61042186, valid_loss: 0.63694274, time: [8.2], best model: 0\n",
      "Epoch: 6, train_loss: 0.60454696, valid_loss: 0.6364765, time: [8.09], best model: 0\n",
      "Epoch: 7, train_loss: 0.60305688, valid_loss: 0.64114099, time: [8.65], best model: 0\n",
      "Epoch: 8, train_loss: 0.59254625, valid_loss: 0.64303158, time: [8.69], best model: 0\n",
      "Epoch: 9, train_loss: 0.58589564, valid_loss: 0.64929297, time: [8.58], best model: 0\n",
      "Epoch: 10, train_loss: 0.58166752, valid_loss: 0.6528051, time: [8.29], best model: 0\n",
      "Epoch: 11, train_loss: 0.57893926, valid_loss: 0.66465322, time: [8.22], best model: 0\n",
      "Epoch: 12, train_loss: 0.56458426, valid_loss: 0.66524219, time: [8.2], best model: 0\n",
      "Early Stopped at Epoch: 13\n",
      "New Best Score: 72.89 @ hyperparams = {'cell_size': 101, 'hidden_size': 91, 'learning_rate': 0.011528805226080373, 'num_epochs': 136, 'patience': 11, 'batch_size': 128, 'early_stop_frac': 0.09893012881271257, 'seed': 6447}\n",
      "On sample 21 / 60 (hyperparams = {'cell_size': 153, 'hidden_size': 104, 'learning_rate': 0.030375580746525466, 'num_epochs': 79, 'patience': 10, 'batch_size': 256, 'early_stop_frac': 0.0760720019719452, 'seed': 1259})\n",
      "Model Structure:  GRUD(\n",
      "  (zl): Linear(in_features=312, out_features=104, bias=True)\n",
      "  (rl): Linear(in_features=312, out_features=104, bias=True)\n",
      "  (hl): Linear(in_features=312, out_features=104, bias=True)\n",
      "  (gamma_x_l): FilterLinear(in_features=104, out_features=104, bias=True)\n",
      "  (gamma_h_l): Linear(in_features=104, out_features=104, bias=True)\n",
      "  (fc): Linear(in_features=104, out_features=2, bias=True)\n",
      "  (bn): BatchNorm1d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (drop): Dropout(p=0.5, inplace=False)\n",
      ")\n",
      "Start Training ... \n",
      "Output type dermined by the model\n",
      "Epoch: 0, train_loss: 0.68509572, valid_loss: 0.67335033, time: [5.18], best model: 1\n",
      "Epoch: 1, train_loss: 0.63135567, valid_loss: 0.64075839, time: [5.17], best model: 1\n",
      "Epoch: 2, train_loss: 0.62716878, valid_loss: 0.63951422, time: [5.28], best model: 1\n",
      "Epoch: 3, train_loss: 0.62338479, valid_loss: 0.63835341, time: [5.15], best model: 1\n",
      "Epoch: 4, train_loss: 0.62088896, valid_loss: 0.64343688, time: [5.14], best model: 0\n",
      "Epoch: 5, train_loss: 0.61716112, valid_loss: 0.6431537, time: [5.2], best model: 0\n",
      "Epoch: 6, train_loss: 0.61405633, valid_loss: 0.64052359, time: [5.23], best model: 0\n",
      "Epoch: 7, train_loss: 0.6120985, valid_loss: 0.63851941, time: [5.12], best model: 0\n",
      "Epoch: 8, train_loss: 0.61374429, valid_loss: 0.63843803, time: [5.32], best model: 0\n",
      "Epoch: 9, train_loss: 0.60884088, valid_loss: 0.64196014, time: [5.27], best model: 0\n",
      "Epoch: 10, train_loss: 0.61177038, valid_loss: 0.64707909, time: [5.27], best model: 0\n",
      "Epoch: 11, train_loss: 0.61919797, valid_loss: 0.65026658, time: [5.36], best model: 0\n",
      "Epoch: 12, train_loss: 0.61825263, valid_loss: 0.64469674, time: [5.15], best model: 0\n",
      "Early Stopped at Epoch: 13\n",
      "On sample 22 / 60 (hyperparams = {'cell_size': 88, 'hidden_size': 128, 'learning_rate': 0.023492438413069527, 'num_epochs': 113, 'patience': 11, 'batch_size': 128, 'early_stop_frac': 0.09026379231331474, 'seed': 9594})\n",
      "Model Structure:  GRUD(\n",
      "  (zl): Linear(in_features=336, out_features=128, bias=True)\n",
      "  (rl): Linear(in_features=336, out_features=128, bias=True)\n",
      "  (hl): Linear(in_features=336, out_features=128, bias=True)\n",
      "  (gamma_x_l): FilterLinear(in_features=104, out_features=104, bias=True)\n",
      "  (gamma_h_l): Linear(in_features=104, out_features=128, bias=True)\n",
      "  (fc): Linear(in_features=128, out_features=2, bias=True)\n",
      "  (bn): BatchNorm1d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (drop): Dropout(p=0.5, inplace=False)\n",
      ")\n",
      "Start Training ... \n",
      "Output type dermined by the model\n",
      "Epoch: 0, train_loss: 0.6821559, valid_loss: 0.67047927, time: [8.92], best model: 1\n",
      "Epoch: 1, train_loss: 0.64372382, valid_loss: 0.63450552, time: [8.96], best model: 1\n",
      "Epoch: 2, train_loss: 0.63800844, valid_loss: 0.6305969, time: [8.66], best model: 1\n",
      "Epoch: 3, train_loss: 0.63658854, valid_loss: 0.63007034, time: [8.61], best model: 1\n",
      "Epoch: 4, train_loss: 0.63787464, valid_loss: 0.63105178, time: [8.61], best model: 0\n",
      "Epoch: 5, train_loss: 0.63451405, valid_loss: 0.62691267, time: [8.65], best model: 1\n",
      "Epoch: 6, train_loss: 0.62532973, valid_loss: 0.62178623, time: [8.68], best model: 1\n",
      "Epoch: 7, train_loss: 0.62406793, valid_loss: 0.62136937, time: [8.71], best model: 1\n",
      "Epoch: 8, train_loss: 0.62368563, valid_loss: 0.62196927, time: [8.54], best model: 0\n",
      "Epoch: 9, train_loss: 0.62282171, valid_loss: 0.62918469, time: [8.65], best model: 0\n",
      "Epoch: 10, train_loss: 0.61870139, valid_loss: 0.62647574, time: [8.72], best model: 0\n",
      "Epoch: 11, train_loss: 0.62819813, valid_loss: 0.62913584, time: [8.59], best model: 0\n",
      "Epoch: 12, train_loss: 0.6404174, valid_loss: 0.63651058, time: [8.68], best model: 0\n",
      "Epoch: 13, train_loss: 0.64281169, valid_loss: 0.63571327, time: [8.79], best model: 0\n",
      "Epoch: 14, train_loss: 0.63149928, valid_loss: 0.63159584, time: [8.58], best model: 0\n",
      "Epoch: 15, train_loss: 0.63415502, valid_loss: 0.6332593, time: [8.61], best model: 0\n",
      "Epoch: 16, train_loss: 0.63175349, valid_loss: 0.63244911, time: [8.54], best model: 0\n",
      "Epoch: 17, train_loss: 0.63613654, valid_loss: 0.6344927, time: [8.61], best model: 0\n",
      "Early Stopped at Epoch: 18\n",
      "On sample 23 / 60 (hyperparams = {'cell_size': 83, 'hidden_size': 165, 'learning_rate': 0.03056037339109023, 'num_epochs': 142, 'patience': 9, 'batch_size': 512, 'early_stop_frac': 0.09366698797270301, 'seed': 3297})\n",
      "Model Structure:  GRUD(\n",
      "  (zl): Linear(in_features=373, out_features=165, bias=True)\n",
      "  (rl): Linear(in_features=373, out_features=165, bias=True)\n",
      "  (hl): Linear(in_features=373, out_features=165, bias=True)\n",
      "  (gamma_x_l): FilterLinear(in_features=104, out_features=104, bias=True)\n",
      "  (gamma_h_l): Linear(in_features=104, out_features=165, bias=True)\n",
      "  (fc): Linear(in_features=165, out_features=2, bias=True)\n",
      "  (bn): BatchNorm1d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (drop): Dropout(p=0.5, inplace=False)\n",
      ")\n",
      "Start Training ... \n",
      "Output type dermined by the model\n",
      "Epoch: 0, train_loss: 0.71811518, valid_loss: 0.70057974, time: [4.17], best model: 1\n",
      "Epoch: 1, train_loss: 0.64194962, valid_loss: 0.6457461, time: [4.02], best model: 1\n",
      "Epoch: 2, train_loss: 0.63244195, valid_loss: 0.63585808, time: [3.97], best model: 1\n",
      "Epoch: 3, train_loss: 0.62989064, valid_loss: 0.63602553, time: [3.99], best model: 0\n",
      "Epoch: 4, train_loss: 0.62538357, valid_loss: 0.63617029, time: [4.06], best model: 0\n",
      "Epoch: 5, train_loss: 0.61965206, valid_loss: 0.63861156, time: [3.94], best model: 0\n",
      "Epoch: 6, train_loss: 0.61706115, valid_loss: 0.63989107, time: [3.96], best model: 0\n",
      "Epoch: 7, train_loss: 0.60899498, valid_loss: 0.64203262, time: [4.01], best model: 0\n",
      "Epoch: 8, train_loss: 0.60133664, valid_loss: 0.64540705, time: [4.09], best model: 0\n",
      "Epoch: 9, train_loss: 0.60022893, valid_loss: 0.65128366, time: [4.07], best model: 0\n",
      "Epoch: 10, train_loss: 0.59830889, valid_loss: 0.65374361, time: [4.04], best model: 0\n",
      "Early Stopped at Epoch: 11\n",
      "On sample 24 / 60 (hyperparams = {'cell_size': 108, 'hidden_size': 92, 'learning_rate': 0.0491409857469679, 'num_epochs': 68, 'patience': 8, 'batch_size': 64, 'early_stop_frac': 0.051505613424837005, 'seed': 3433})\n",
      "Model Structure:  GRUD(\n",
      "  (zl): Linear(in_features=300, out_features=92, bias=True)\n",
      "  (rl): Linear(in_features=300, out_features=92, bias=True)\n",
      "  (hl): Linear(in_features=300, out_features=92, bias=True)\n",
      "  (gamma_x_l): FilterLinear(in_features=104, out_features=104, bias=True)\n",
      "  (gamma_h_l): Linear(in_features=104, out_features=92, bias=True)\n",
      "  (fc): Linear(in_features=92, out_features=2, bias=True)\n",
      "  (bn): BatchNorm1d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (drop): Dropout(p=0.5, inplace=False)\n",
      ")\n",
      "Start Training ... \n",
      "Output type dermined by the model\n",
      "Epoch: 0, train_loss: 0.66855972, valid_loss: 0.6600407, time: [14.56], best model: 1\n",
      "Epoch: 1, train_loss: 0.6605715, valid_loss: 0.65269027, time: [14.34], best model: 1\n",
      "Epoch: 2, train_loss: 0.65566506, valid_loss: 0.64792572, time: [14.14], best model: 1\n",
      "Epoch: 3, train_loss: 0.65213517, valid_loss: 0.64357093, time: [14.06], best model: 1\n",
      "Epoch: 4, train_loss: 0.65240786, valid_loss: 0.64471306, time: [14.15], best model: 0\n",
      "Epoch: 5, train_loss: 0.64968571, valid_loss: 0.64516775, time: [14.11], best model: 0\n",
      "Epoch: 6, train_loss: 0.6452486, valid_loss: 0.64090366, time: [14.12], best model: 1\n",
      "Epoch: 7, train_loss: 0.64219333, valid_loss: 0.63688734, time: [14.26], best model: 1\n",
      "Epoch: 8, train_loss: 0.64931765, valid_loss: 0.64001834, time: [14.32], best model: 0\n",
      "Epoch: 9, train_loss: 0.64328618, valid_loss: 0.64094057, time: [14.16], best model: 0\n",
      "Epoch: 10, train_loss: 0.64740839, valid_loss: 0.64483673, time: [14.2], best model: 0\n",
      "Epoch: 11, train_loss: 0.64604273, valid_loss: 0.63567863, time: [14.27], best model: 1\n",
      "Epoch: 12, train_loss: 0.64007236, valid_loss: 0.6305243, time: [14.17], best model: 1\n",
      "Epoch: 13, train_loss: 0.64255678, valid_loss: 0.63040703, time: [14.45], best model: 1\n",
      "Epoch: 14, train_loss: 0.6382522, valid_loss: 0.63277011, time: [14.79], best model: 0\n",
      "Epoch: 15, train_loss: 0.64191997, valid_loss: 0.6377761, time: [14.46], best model: 0\n",
      "Epoch: 16, train_loss: 0.64379243, valid_loss: 0.63772928, time: [14.58], best model: 0\n",
      "Epoch: 17, train_loss: 0.64424139, valid_loss: 0.63742976, time: [14.63], best model: 0\n",
      "Epoch: 18, train_loss: 0.64369202, valid_loss: 0.64467344, time: [14.5], best model: 0\n",
      "Epoch: 19, train_loss: 0.64370254, valid_loss: 0.64917835, time: [14.57], best model: 0\n",
      "Epoch: 20, train_loss: 0.64433473, valid_loss: 0.64086305, time: [14.63], best model: 0\n",
      "Early Stopped at Epoch: 21\n",
      "On sample 25 / 60 (hyperparams = {'cell_size': 174, 'hidden_size': 65, 'learning_rate': 0.056949682108840806, 'num_epochs': 71, 'patience': 8, 'batch_size': 64, 'early_stop_frac': 0.13929058830787158, 'seed': 8642})\n",
      "Model Structure:  GRUD(\n",
      "  (zl): Linear(in_features=273, out_features=65, bias=True)\n",
      "  (rl): Linear(in_features=273, out_features=65, bias=True)\n",
      "  (hl): Linear(in_features=273, out_features=65, bias=True)\n",
      "  (gamma_x_l): FilterLinear(in_features=104, out_features=104, bias=True)\n",
      "  (gamma_h_l): Linear(in_features=104, out_features=65, bias=True)\n",
      "  (fc): Linear(in_features=65, out_features=2, bias=True)\n",
      "  (bn): BatchNorm1d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (drop): Dropout(p=0.5, inplace=False)\n",
      ")\n",
      "Start Training ... \n",
      "Output type dermined by the model\n",
      "Epoch: 0, train_loss: 0.66742879, valid_loss: 0.66440409, time: [13.49], best model: 1\n",
      "Epoch: 1, train_loss: 0.6527533, valid_loss: 0.65263238, time: [13.33], best model: 1\n",
      "Epoch: 2, train_loss: 0.65778788, valid_loss: 0.65412828, time: [13.27], best model: 0\n",
      "Epoch: 3, train_loss: 0.65067457, valid_loss: 0.65003411, time: [13.32], best model: 1\n",
      "Epoch: 4, train_loss: 0.65055128, valid_loss: 0.65408983, time: [13.31], best model: 0\n",
      "Epoch: 5, train_loss: 0.64832594, valid_loss: 0.65065592, time: [13.25], best model: 0\n",
      "Epoch: 6, train_loss: 0.64535509, valid_loss: 0.65033766, time: [13.24], best model: 0\n",
      "Epoch: 7, train_loss: 0.64284363, valid_loss: 0.65397583, time: [13.25], best model: 0\n",
      "Epoch: 8, train_loss: 0.64266317, valid_loss: 0.65107917, time: [13.21], best model: 0\n",
      "Epoch: 9, train_loss: 0.64667365, valid_loss: 0.65015883, time: [13.25], best model: 0\n",
      "Epoch: 10, train_loss: 0.64380507, valid_loss: 0.65080227, time: [13.2], best model: 0\n",
      "Early Stopped at Epoch: 11\n",
      "On sample 26 / 60 (hyperparams = {'cell_size': 117, 'hidden_size': 127, 'learning_rate': 0.08651131155747016, 'num_epochs': 101, 'patience': 9, 'batch_size': 256, 'early_stop_frac': 0.05291493178475118, 'seed': 5499})\n",
      "Model Structure:  GRUD(\n",
      "  (zl): Linear(in_features=335, out_features=127, bias=True)\n",
      "  (rl): Linear(in_features=335, out_features=127, bias=True)\n",
      "  (hl): Linear(in_features=335, out_features=127, bias=True)\n",
      "  (gamma_x_l): FilterLinear(in_features=104, out_features=104, bias=True)\n",
      "  (gamma_h_l): Linear(in_features=104, out_features=127, bias=True)\n",
      "  (fc): Linear(in_features=127, out_features=2, bias=True)\n",
      "  (bn): BatchNorm1d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (drop): Dropout(p=0.5, inplace=False)\n",
      ")\n",
      "Start Training ... \n",
      "Output type dermined by the model\n",
      "Epoch: 0, train_loss: 0.69058695, valid_loss: 0.68715846, time: [5.62], best model: 1\n",
      "Epoch: 1, train_loss: 0.65037217, valid_loss: 0.65644338, time: [5.52], best model: 1\n",
      "Epoch: 2, train_loss: 0.64407515, valid_loss: 0.65388335, time: [5.54], best model: 1\n",
      "Epoch: 3, train_loss: 0.64758092, valid_loss: 0.65426125, time: [5.48], best model: 0\n",
      "Epoch: 4, train_loss: 0.64650788, valid_loss: 0.65601773, time: [5.49], best model: 0\n",
      "Epoch: 5, train_loss: 0.64909541, valid_loss: 0.65522102, time: [5.51], best model: 0\n",
      "Epoch: 6, train_loss: 0.64846863, valid_loss: 0.65574228, time: [5.48], best model: 0\n",
      "Epoch: 7, train_loss: 0.65032701, valid_loss: 0.6520387, time: [5.5], best model: 1\n",
      "Epoch: 8, train_loss: 0.65722367, valid_loss: 0.66428228, time: [5.45], best model: 0\n",
      "Epoch: 9, train_loss: 0.65001291, valid_loss: 0.65809164, time: [5.49], best model: 0\n",
      "Epoch: 10, train_loss: 0.64514234, valid_loss: 0.65825936, time: [5.63], best model: 0\n",
      "Epoch: 11, train_loss: 0.64637387, valid_loss: 0.65370873, time: [5.79], best model: 0\n",
      "Epoch: 12, train_loss: 0.64706046, valid_loss: 0.65095618, time: [5.84], best model: 1\n",
      "Epoch: 13, train_loss: 0.64903862, valid_loss: 0.6537112, time: [5.62], best model: 0\n",
      "Epoch: 14, train_loss: 0.64612222, valid_loss: 0.65794176, time: [5.49], best model: 0\n",
      "Epoch: 15, train_loss: 0.64652363, valid_loss: 0.6505517, time: [5.63], best model: 1\n",
      "Epoch: 16, train_loss: 0.64827814, valid_loss: 0.65828785, time: [5.53], best model: 0\n",
      "Epoch: 17, train_loss: 0.6456388, valid_loss: 0.65349413, time: [5.51], best model: 0\n",
      "Epoch: 18, train_loss: 0.64207618, valid_loss: 0.65485579, time: [5.63], best model: 0\n",
      "Epoch: 19, train_loss: 0.64289345, valid_loss: 0.656851, time: [5.61], best model: 0\n",
      "Epoch: 20, train_loss: 0.64501399, valid_loss: 0.65750793, time: [5.71], best model: 0\n",
      "Epoch: 21, train_loss: 0.64554393, valid_loss: 0.65798864, time: [5.55], best model: 0\n",
      "Epoch: 22, train_loss: 0.64202093, valid_loss: 0.65263484, time: [5.64], best model: 0\n",
      "Epoch: 23, train_loss: 0.64055449, valid_loss: 0.65300055, time: [5.76], best model: 0\n",
      "Early Stopped at Epoch: 24\n",
      "On sample 27 / 60 (hyperparams = {'cell_size': 119, 'hidden_size': 157, 'learning_rate': 0.10085097007841644, 'num_epochs': 118, 'patience': 10, 'batch_size': 256, 'early_stop_frac': 0.08728928840117262, 'seed': 658})\n",
      "Model Structure:  GRUD(\n",
      "  (zl): Linear(in_features=365, out_features=157, bias=True)\n",
      "  (rl): Linear(in_features=365, out_features=157, bias=True)\n",
      "  (hl): Linear(in_features=365, out_features=157, bias=True)\n",
      "  (gamma_x_l): FilterLinear(in_features=104, out_features=104, bias=True)\n",
      "  (gamma_h_l): Linear(in_features=104, out_features=157, bias=True)\n",
      "  (fc): Linear(in_features=157, out_features=2, bias=True)\n",
      "  (bn): BatchNorm1d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (drop): Dropout(p=0.5, inplace=False)\n",
      ")\n",
      "Start Training ... \n",
      "Output type dermined by the model\n",
      "Epoch: 0, train_loss: 0.69430064, valid_loss: 0.68485131, time: [6.24], best model: 1\n",
      "Epoch: 1, train_loss: 0.65592847, valid_loss: 0.6590765, time: [6.08], best model: 1\n",
      "Epoch: 2, train_loss: 0.65966551, valid_loss: 0.65413006, time: [6.34], best model: 1\n",
      "Epoch: 3, train_loss: 0.65210123, valid_loss: 0.65498456, time: [6.05], best model: 0\n",
      "Epoch: 4, train_loss: 0.65822116, valid_loss: 0.66035636, time: [6.12], best model: 0\n",
      "Epoch: 5, train_loss: 0.65729801, valid_loss: 0.65973754, time: [6.08], best model: 0\n",
      "Epoch: 6, train_loss: 0.65040401, valid_loss: 0.65514813, time: [6.01], best model: 0\n",
      "Epoch: 7, train_loss: 0.65809935, valid_loss: 0.65115951, time: [6.], best model: 1\n",
      "Epoch: 8, train_loss: 0.6580497, valid_loss: 0.65851729, time: [6.32], best model: 0\n",
      "Epoch: 9, train_loss: 0.64765736, valid_loss: 0.64864905, time: [6.61], best model: 1\n",
      "Epoch: 10, train_loss: 0.64807581, valid_loss: 0.64954266, time: [6.59], best model: 0\n",
      "Epoch: 11, train_loss: 0.64971096, valid_loss: 0.65179042, time: [6.31], best model: 0\n",
      "Epoch: 12, train_loss: 0.6481589, valid_loss: 0.65047468, time: [6.02], best model: 0\n",
      "Epoch: 13, train_loss: 0.64674183, valid_loss: 0.65449505, time: [6.1], best model: 0\n",
      "Epoch: 14, train_loss: 0.64719772, valid_loss: 0.65618483, time: [6.15], best model: 0\n",
      "Epoch: 15, train_loss: 0.64979392, valid_loss: 0.65590267, time: [5.95], best model: 0\n",
      "Epoch: 16, train_loss: 0.64709731, valid_loss: 0.64602693, time: [6.17], best model: 1\n",
      "Epoch: 17, train_loss: 0.64855537, valid_loss: 0.65186821, time: [6.49], best model: 0\n",
      "Epoch: 18, train_loss: 0.64481735, valid_loss: 0.65285304, time: [6.18], best model: 0\n",
      "Epoch: 19, train_loss: 0.64649175, valid_loss: 0.64799551, time: [6.38], best model: 0\n",
      "Epoch: 20, train_loss: 0.64520108, valid_loss: 0.65011623, time: [6.33], best model: 0\n",
      "Epoch: 21, train_loss: 0.64950911, valid_loss: 0.64952721, time: [6.32], best model: 0\n",
      "Epoch: 22, train_loss: 0.64473194, valid_loss: 0.64724822, time: [6.24], best model: 0\n",
      "Epoch: 23, train_loss: 0.64759193, valid_loss: 0.65206715, time: [5.98], best model: 0\n",
      "Epoch: 24, train_loss: 0.64793189, valid_loss: 0.65094298, time: [6.04], best model: 0\n",
      "Epoch: 25, train_loss: 0.64413291, valid_loss: 0.64843795, time: [6.11], best model: 0\n",
      "Early Stopped at Epoch: 26\n",
      "On sample 28 / 60 (hyperparams = {'cell_size': 138, 'hidden_size': 101, 'learning_rate': 0.006886808622935135, 'num_epochs': 83, 'patience': 11, 'batch_size': 512, 'early_stop_frac': 0.05958733146927722, 'seed': 26})\n",
      "Model Structure:  GRUD(\n",
      "  (zl): Linear(in_features=309, out_features=101, bias=True)\n",
      "  (rl): Linear(in_features=309, out_features=101, bias=True)\n",
      "  (hl): Linear(in_features=309, out_features=101, bias=True)\n",
      "  (gamma_x_l): FilterLinear(in_features=104, out_features=104, bias=True)\n",
      "  (gamma_h_l): Linear(in_features=104, out_features=101, bias=True)\n",
      "  (fc): Linear(in_features=101, out_features=2, bias=True)\n",
      "  (bn): BatchNorm1d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (drop): Dropout(p=0.5, inplace=False)\n",
      ")\n",
      "Start Training ... \n",
      "Output type dermined by the model\n",
      "Epoch: 0, train_loss: 0.77819996, valid_loss: 0.72896837, time: [3.98], best model: 1\n",
      "Epoch: 1, train_loss: 0.68644746, valid_loss: 0.64487387, time: [4.02], best model: 1\n",
      "Epoch: 2, train_loss: 0.64321645, valid_loss: 0.61701508, time: [4.04], best model: 1\n",
      "Epoch: 3, train_loss: 0.6292305, valid_loss: 0.61249415, time: [3.95], best model: 1\n",
      "Epoch: 4, train_loss: 0.62078508, valid_loss: 0.61002261, time: [4.03], best model: 1\n",
      "Epoch: 5, train_loss: 0.61045869, valid_loss: 0.60920092, time: [4.05], best model: 1\n",
      "Epoch: 6, train_loss: 0.60132669, valid_loss: 0.61355686, time: [4.2], best model: 0\n",
      "Epoch: 7, train_loss: 0.59380754, valid_loss: 0.62405052, time: [3.99], best model: 0\n",
      "Epoch: 8, train_loss: 0.59021912, valid_loss: 0.61284078, time: [4.05], best model: 0\n",
      "Epoch: 9, train_loss: 0.57532177, valid_loss: 0.62206961, time: [4.12], best model: 0\n",
      "Epoch: 10, train_loss: 0.56208216, valid_loss: 0.6345129, time: [4.63], best model: 0\n",
      "Epoch: 11, train_loss: 0.55425771, valid_loss: 0.64939696, time: [4.56], best model: 0\n",
      "Epoch: 12, train_loss: 0.53428936, valid_loss: 0.6550148, time: [4.6], best model: 0\n",
      "Epoch: 13, train_loss: 0.52362728, valid_loss: 0.67199968, time: [4.37], best model: 0\n",
      "Epoch: 14, train_loss: 0.50027307, valid_loss: 0.68190047, time: [4.12], best model: 0\n",
      "Epoch: 15, train_loss: 0.47079856, valid_loss: 0.7226443, time: [4.16], best model: 0\n",
      "Early Stopped at Epoch: 16\n",
      "On sample 29 / 60 (hyperparams = {'cell_size': 96, 'hidden_size': 128, 'learning_rate': 0.025211825143616397, 'num_epochs': 87, 'patience': 10, 'batch_size': 64, 'early_stop_frac': 0.06969643203500386, 'seed': 1123})\n",
      "Model Structure:  GRUD(\n",
      "  (zl): Linear(in_features=336, out_features=128, bias=True)\n",
      "  (rl): Linear(in_features=336, out_features=128, bias=True)\n",
      "  (hl): Linear(in_features=336, out_features=128, bias=True)\n",
      "  (gamma_x_l): FilterLinear(in_features=104, out_features=104, bias=True)\n",
      "  (gamma_h_l): Linear(in_features=104, out_features=128, bias=True)\n",
      "  (fc): Linear(in_features=128, out_features=2, bias=True)\n",
      "  (bn): BatchNorm1d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (drop): Dropout(p=0.5, inplace=False)\n",
      ")\n",
      "Start Training ... \n",
      "Output type dermined by the model\n",
      "Epoch: 0, train_loss: 0.66691106, valid_loss: 0.6635427, time: [15.92], best model: 1\n",
      "Epoch: 1, train_loss: 0.64290986, valid_loss: 0.64369026, time: [15.44], best model: 1\n",
      "Epoch: 2, train_loss: 0.64774728, valid_loss: 0.64925413, time: [15.28], best model: 0\n",
      "Epoch: 3, train_loss: 0.64430419, valid_loss: 0.64248123, time: [15.65], best model: 1\n",
      "Epoch: 4, train_loss: 0.64410589, valid_loss: 0.63954112, time: [15.33], best model: 1\n",
      "Epoch: 5, train_loss: 0.64061395, valid_loss: 0.6408358, time: [15.16], best model: 0\n",
      "Epoch: 6, train_loss: 0.64596413, valid_loss: 0.64947962, time: [15.29], best model: 0\n",
      "Epoch: 7, train_loss: 0.64628589, valid_loss: 0.6451254, time: [15.32], best model: 0\n",
      "Epoch: 8, train_loss: 0.64150386, valid_loss: 0.64480603, time: [15.28], best model: 0\n",
      "Epoch: 9, train_loss: 0.6473643, valid_loss: 0.65167513, time: [15.15], best model: 0\n",
      "Epoch: 10, train_loss: 0.64720719, valid_loss: 0.65211135, time: [15.4], best model: 0\n",
      "Epoch: 11, train_loss: 0.64480585, valid_loss: 0.64677247, time: [15.37], best model: 0\n",
      "Epoch: 12, train_loss: 0.64136734, valid_loss: 0.64782024, time: [15.59], best model: 0\n",
      "Epoch: 13, train_loss: 0.64462318, valid_loss: 0.65133636, time: [15.07], best model: 0\n",
      "Early Stopped at Epoch: 14\n",
      "On sample 30 / 60 (hyperparams = {'cell_size': 145, 'hidden_size': 140, 'learning_rate': 0.06633114272482353, 'num_epochs': 118, 'patience': 10, 'batch_size': 256, 'early_stop_frac': 0.14424206123971434, 'seed': 9667})\n",
      "Model Structure:  GRUD(\n",
      "  (zl): Linear(in_features=348, out_features=140, bias=True)\n",
      "  (rl): Linear(in_features=348, out_features=140, bias=True)\n",
      "  (hl): Linear(in_features=348, out_features=140, bias=True)\n",
      "  (gamma_x_l): FilterLinear(in_features=104, out_features=104, bias=True)\n",
      "  (gamma_h_l): Linear(in_features=104, out_features=140, bias=True)\n",
      "  (fc): Linear(in_features=140, out_features=2, bias=True)\n",
      "  (bn): BatchNorm1d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (drop): Dropout(p=0.5, inplace=False)\n",
      ")\n",
      "Start Training ... \n",
      "Output type dermined by the model\n",
      "Epoch: 0, train_loss: 0.6983101, valid_loss: 0.6885816, time: [5.67], best model: 1\n",
      "Epoch: 1, train_loss: 0.6553154, valid_loss: 0.65420035, time: [5.58], best model: 1\n",
      "Epoch: 2, train_loss: 0.64542157, valid_loss: 0.65074158, time: [5.6], best model: 1\n",
      "Epoch: 3, train_loss: 0.64458677, valid_loss: 0.65574421, time: [5.6], best model: 0\n",
      "Epoch: 4, train_loss: 0.64019714, valid_loss: 0.65173272, time: [5.58], best model: 0\n",
      "Epoch: 5, train_loss: 0.64577314, valid_loss: 0.65180779, time: [5.7], best model: 0\n",
      "Epoch: 6, train_loss: 0.64575747, valid_loss: 0.648039, time: [5.7], best model: 1\n",
      "Epoch: 7, train_loss: 0.63974667, valid_loss: 0.65051058, time: [6.2], best model: 0\n",
      "Epoch: 8, train_loss: 0.63862487, valid_loss: 0.64802633, time: [5.61], best model: 1\n",
      "Epoch: 9, train_loss: 0.64044019, valid_loss: 0.65214137, time: [5.71], best model: 0\n",
      "Epoch: 10, train_loss: 0.63404356, valid_loss: 0.64774595, time: [5.78], best model: 1\n",
      "Epoch: 11, train_loss: 0.63830444, valid_loss: 0.6485375, time: [5.79], best model: 0\n",
      "Epoch: 12, train_loss: 0.63023438, valid_loss: 0.64971106, time: [5.78], best model: 0\n",
      "Epoch: 13, train_loss: 0.63055059, valid_loss: 0.64587239, time: [5.74], best model: 1\n",
      "Epoch: 14, train_loss: 0.6296948, valid_loss: 0.64909349, time: [5.63], best model: 0\n",
      "Epoch: 15, train_loss: 0.62435893, valid_loss: 0.65333884, time: [5.73], best model: 0\n",
      "Epoch: 16, train_loss: 0.62585878, valid_loss: 0.64802878, time: [5.69], best model: 0\n",
      "Epoch: 17, train_loss: 0.62008497, valid_loss: 0.65604775, time: [5.7], best model: 0\n",
      "Epoch: 18, train_loss: 0.62066882, valid_loss: 0.65577766, time: [5.65], best model: 0\n",
      "Epoch: 19, train_loss: 0.62233802, valid_loss: 0.64932837, time: [5.65], best model: 0\n",
      "Epoch: 20, train_loss: 0.61500597, valid_loss: 0.65371718, time: [5.62], best model: 0\n",
      "Epoch: 21, train_loss: 0.62023585, valid_loss: 0.65643535, time: [5.66], best model: 0\n",
      "Epoch: 22, train_loss: 0.61791011, valid_loss: 0.65898459, time: [5.67], best model: 0\n",
      "Early Stopped at Epoch: 23\n",
      "On sample 31 / 60 (hyperparams = {'cell_size': 171, 'hidden_size': 175, 'learning_rate': 0.018146656289167673, 'num_epochs': 120, 'patience': 9, 'batch_size': 256, 'early_stop_frac': 0.08712711716678964, 'seed': 4843})\n",
      "Model Structure:  GRUD(\n",
      "  (zl): Linear(in_features=383, out_features=175, bias=True)\n",
      "  (rl): Linear(in_features=383, out_features=175, bias=True)\n",
      "  (hl): Linear(in_features=383, out_features=175, bias=True)\n",
      "  (gamma_x_l): FilterLinear(in_features=104, out_features=104, bias=True)\n",
      "  (gamma_h_l): Linear(in_features=104, out_features=175, bias=True)\n",
      "  (fc): Linear(in_features=175, out_features=2, bias=True)\n",
      "  (bn): BatchNorm1d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (drop): Dropout(p=0.5, inplace=False)\n",
      ")\n",
      "Start Training ... \n",
      "Output type dermined by the model\n",
      "Epoch: 0, train_loss: 0.71431357, valid_loss: 0.69113198, time: [5.91], best model: 1\n",
      "Epoch: 1, train_loss: 0.63238829, valid_loss: 0.62847894, time: [6.03], best model: 1\n",
      "Epoch: 2, train_loss: 0.62368949, valid_loss: 0.62292726, time: [5.9], best model: 1\n",
      "Epoch: 3, train_loss: 0.62094879, valid_loss: 0.62695823, time: [5.93], best model: 0\n",
      "Epoch: 4, train_loss: 0.61878657, valid_loss: 0.62649252, time: [5.94], best model: 0\n",
      "Epoch: 5, train_loss: 0.61286247, valid_loss: 0.63256067, time: [5.96], best model: 0\n",
      "Epoch: 6, train_loss: 0.61070898, valid_loss: 0.62690231, time: [5.93], best model: 0\n",
      "Epoch: 7, train_loss: 0.61488194, valid_loss: 0.63378538, time: [5.92], best model: 0\n",
      "Epoch: 8, train_loss: 0.61191171, valid_loss: 0.63395794, time: [6.04], best model: 0\n",
      "Epoch: 9, train_loss: 0.60006998, valid_loss: 0.63307216, time: [5.92], best model: 0\n",
      "Epoch: 10, train_loss: 0.58903251, valid_loss: 0.64433508, time: [5.93], best model: 0\n",
      "Early Stopped at Epoch: 11\n",
      "On sample 32 / 60 (hyperparams = {'cell_size': 81, 'hidden_size': 115, 'learning_rate': 0.08901458933690015, 'num_epochs': 76, 'patience': 10, 'batch_size': 64, 'early_stop_frac': 0.12290008018214771, 'seed': 137})\n",
      "Model Structure:  GRUD(\n",
      "  (zl): Linear(in_features=323, out_features=115, bias=True)\n",
      "  (rl): Linear(in_features=323, out_features=115, bias=True)\n",
      "  (hl): Linear(in_features=323, out_features=115, bias=True)\n",
      "  (gamma_x_l): FilterLinear(in_features=104, out_features=104, bias=True)\n",
      "  (gamma_h_l): Linear(in_features=104, out_features=115, bias=True)\n",
      "  (fc): Linear(in_features=115, out_features=2, bias=True)\n",
      "  (bn): BatchNorm1d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (drop): Dropout(p=0.5, inplace=False)\n",
      ")\n",
      "Start Training ... \n",
      "Output type dermined by the model\n",
      "Epoch: 0, train_loss: 0.68035429, valid_loss: 0.67882221, time: [14.45], best model: 1\n",
      "Epoch: 1, train_loss: 0.664121, valid_loss: 0.67129523, time: [14.42], best model: 1\n",
      "Epoch: 2, train_loss: 0.65714954, valid_loss: 0.66047882, time: [14.32], best model: 1\n",
      "Epoch: 3, train_loss: 0.66503846, valid_loss: 0.67114578, time: [14.37], best model: 0\n",
      "Epoch: 4, train_loss: 0.65964525, valid_loss: 0.66602902, time: [14.3], best model: 0\n",
      "Epoch: 5, train_loss: 0.66047928, valid_loss: 0.66611684, time: [14.53], best model: 0\n",
      "Epoch: 6, train_loss: 0.65769532, valid_loss: 0.66557385, time: [14.51], best model: 0\n",
      "Epoch: 7, train_loss: 0.65081587, valid_loss: 0.66390312, time: [14.38], best model: 0\n",
      "Epoch: 8, train_loss: 0.65253232, valid_loss: 0.66210951, time: [14.35], best model: 0\n",
      "Epoch: 9, train_loss: 0.65768533, valid_loss: 0.66933971, time: [14.26], best model: 0\n",
      "Epoch: 10, train_loss: 0.65390774, valid_loss: 0.66466872, time: [14.37], best model: 0\n",
      "Epoch: 11, train_loss: 0.6564469, valid_loss: 0.66443464, time: [14.37], best model: 0\n",
      "Early Stopped at Epoch: 12\n",
      "On sample 33 / 60 (hyperparams = {'cell_size': 130, 'hidden_size': 147, 'learning_rate': 0.023740242630502596, 'num_epochs': 64, 'patience': 9, 'batch_size': 64, 'early_stop_frac': 0.06261601086290215, 'seed': 2755})\n",
      "Model Structure:  GRUD(\n",
      "  (zl): Linear(in_features=355, out_features=147, bias=True)\n",
      "  (rl): Linear(in_features=355, out_features=147, bias=True)\n",
      "  (hl): Linear(in_features=355, out_features=147, bias=True)\n",
      "  (gamma_x_l): FilterLinear(in_features=104, out_features=104, bias=True)\n",
      "  (gamma_h_l): Linear(in_features=104, out_features=147, bias=True)\n",
      "  (fc): Linear(in_features=147, out_features=2, bias=True)\n",
      "  (bn): BatchNorm1d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (drop): Dropout(p=0.5, inplace=False)\n",
      ")\n",
      "Start Training ... \n",
      "Output type dermined by the model\n",
      "Epoch: 0, train_loss: 0.66237756, valid_loss: 0.66667125, time: [15.55], best model: 1\n",
      "Epoch: 1, train_loss: 0.64309487, valid_loss: 0.64679491, time: [15.51], best model: 1\n",
      "Epoch: 2, train_loss: 0.64123286, valid_loss: 0.64314083, time: [15.46], best model: 1\n",
      "Epoch: 3, train_loss: 0.63658136, valid_loss: 0.63898577, time: [15.5], best model: 1\n",
      "Epoch: 4, train_loss: 0.63969857, valid_loss: 0.64505734, time: [15.38], best model: 0\n",
      "Epoch: 5, train_loss: 0.63816809, valid_loss: 0.64412188, time: [15.5], best model: 0\n",
      "Epoch: 6, train_loss: 0.63063797, valid_loss: 0.64125921, time: [15.52], best model: 0\n",
      "Epoch: 7, train_loss: 0.63836657, valid_loss: 0.64437692, time: [15.38], best model: 0\n",
      "Epoch: 8, train_loss: 0.64120751, valid_loss: 0.63963405, time: [15.54], best model: 0\n",
      "Epoch: 9, train_loss: 0.63394769, valid_loss: 0.6392608, time: [15.38], best model: 0\n",
      "Epoch: 10, train_loss: 0.63696787, valid_loss: 0.64494486, time: [15.37], best model: 0\n",
      "Epoch: 11, train_loss: 0.63673258, valid_loss: 0.65233547, time: [15.38], best model: 0\n",
      "Early Stopped at Epoch: 12\n",
      "On sample 34 / 60 (hyperparams = {'cell_size': 102, 'hidden_size': 194, 'learning_rate': 0.0761755038883449, 'num_epochs': 107, 'patience': 11, 'batch_size': 512, 'early_stop_frac': 0.07512829217072094, 'seed': 6198})\n",
      "Model Structure:  GRUD(\n",
      "  (zl): Linear(in_features=402, out_features=194, bias=True)\n",
      "  (rl): Linear(in_features=402, out_features=194, bias=True)\n",
      "  (hl): Linear(in_features=402, out_features=194, bias=True)\n",
      "  (gamma_x_l): FilterLinear(in_features=104, out_features=104, bias=True)\n",
      "  (gamma_h_l): Linear(in_features=104, out_features=194, bias=True)\n",
      "  (fc): Linear(in_features=194, out_features=2, bias=True)\n",
      "  (bn): BatchNorm1d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (drop): Dropout(p=0.5, inplace=False)\n",
      ")\n",
      "Start Training ... \n",
      "Output type dermined by the model\n",
      "Epoch: 0, train_loss: 0.71529999, valid_loss: 0.69333083, time: [4.17], best model: 1\n",
      "Epoch: 1, train_loss: 0.65281944, valid_loss: 0.65066935, time: [4.08], best model: 1\n",
      "Epoch: 2, train_loss: 0.64927998, valid_loss: 0.6432017, time: [4.16], best model: 1\n",
      "Epoch: 3, train_loss: 0.64355119, valid_loss: 0.64559644, time: [4.12], best model: 0\n",
      "Epoch: 4, train_loss: 0.64526857, valid_loss: 0.64291954, time: [4.06], best model: 1\n",
      "Epoch: 5, train_loss: 0.6484937, valid_loss: 0.65319106, time: [4.12], best model: 0\n",
      "Epoch: 6, train_loss: 0.64287046, valid_loss: 0.64501762, time: [4.1], best model: 0\n",
      "Epoch: 7, train_loss: 0.6450744, valid_loss: 0.64467182, time: [4.08], best model: 0\n",
      "Epoch: 8, train_loss: 0.64496549, valid_loss: 0.65057373, time: [4.], best model: 0\n",
      "Epoch: 9, train_loss: 0.64859072, valid_loss: 0.64683094, time: [4.12], best model: 0\n",
      "Epoch: 10, train_loss: 0.6429945, valid_loss: 0.64436989, time: [4.07], best model: 0\n",
      "Epoch: 11, train_loss: 0.63995018, valid_loss: 0.63931491, time: [4.], best model: 1\n",
      "Epoch: 12, train_loss: 0.6400924, valid_loss: 0.63788102, time: [4.09], best model: 1\n",
      "Epoch: 13, train_loss: 0.63598099, valid_loss: 0.63971558, time: [4.11], best model: 0\n",
      "Epoch: 14, train_loss: 0.64001745, valid_loss: 0.64545549, time: [4.11], best model: 0\n",
      "Epoch: 15, train_loss: 0.63893954, valid_loss: 0.64363696, time: [4.11], best model: 0\n",
      "Epoch: 16, train_loss: 0.63769697, valid_loss: 0.64014734, time: [4.05], best model: 0\n",
      "Epoch: 17, train_loss: 0.63814526, valid_loss: 0.64132843, time: [4.14], best model: 0\n",
      "Epoch: 18, train_loss: 0.63889071, valid_loss: 0.64048214, time: [4.05], best model: 0\n",
      "Epoch: 19, train_loss: 0.63650443, valid_loss: 0.64160709, time: [4.05], best model: 0\n",
      "Epoch: 20, train_loss: 0.63639565, valid_loss: 0.64513925, time: [4.06], best model: 0\n",
      "Epoch: 21, train_loss: 0.64005095, valid_loss: 0.64078134, time: [4.06], best model: 0\n",
      "Epoch: 22, train_loss: 0.63680045, valid_loss: 0.63930372, time: [4.1], best model: 0\n",
      "Early Stopped at Epoch: 23\n",
      "On sample 35 / 60 (hyperparams = {'cell_size': 100, 'hidden_size': 114, 'learning_rate': 0.06730205132311011, 'num_epochs': 136, 'patience': 10, 'batch_size': 512, 'early_stop_frac': 0.13812352971212316, 'seed': 4055})\n",
      "Model Structure:  GRUD(\n",
      "  (zl): Linear(in_features=322, out_features=114, bias=True)\n",
      "  (rl): Linear(in_features=322, out_features=114, bias=True)\n",
      "  (hl): Linear(in_features=322, out_features=114, bias=True)\n",
      "  (gamma_x_l): FilterLinear(in_features=104, out_features=104, bias=True)\n",
      "  (gamma_h_l): Linear(in_features=104, out_features=114, bias=True)\n",
      "  (fc): Linear(in_features=114, out_features=2, bias=True)\n",
      "  (bn): BatchNorm1d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (drop): Dropout(p=0.5, inplace=False)\n",
      ")\n",
      "Start Training ... \n",
      "Output type dermined by the model\n",
      "Epoch: 0, train_loss: 0.711905, valid_loss: 0.69327443, time: [3.98], best model: 1\n",
      "Epoch: 1, train_loss: 0.64412389, valid_loss: 0.6501646, time: [3.79], best model: 1\n",
      "Epoch: 2, train_loss: 0.63629723, valid_loss: 0.64844111, time: [3.83], best model: 1\n",
      "Epoch: 3, train_loss: 0.62998601, valid_loss: 0.6453166, time: [3.97], best model: 1\n",
      "Epoch: 4, train_loss: 0.637271, valid_loss: 0.64333037, time: [3.84], best model: 1\n",
      "Epoch: 5, train_loss: 0.63417659, valid_loss: 0.64940943, time: [3.76], best model: 0\n",
      "Epoch: 6, train_loss: 0.64366075, valid_loss: 0.64955139, time: [3.74], best model: 0\n",
      "Epoch: 7, train_loss: 0.64053174, valid_loss: 0.65177482, time: [3.74], best model: 0\n",
      "Epoch: 8, train_loss: 0.6372992, valid_loss: 0.6551327, time: [3.77], best model: 0\n",
      "Epoch: 9, train_loss: 0.63905709, valid_loss: 0.65008736, time: [3.93], best model: 0\n",
      "Epoch: 10, train_loss: 0.63544614, valid_loss: 0.65413284, time: [4.19], best model: 0\n",
      "Epoch: 11, train_loss: 0.63407878, valid_loss: 0.65363973, time: [4.09], best model: 0\n",
      "Epoch: 12, train_loss: 0.63113792, valid_loss: 0.6440303, time: [3.83], best model: 0\n",
      "Epoch: 13, train_loss: 0.63209166, valid_loss: 0.65671076, time: [4.05], best model: 0\n",
      "Early Stopped at Epoch: 14\n",
      "On sample 36 / 60 (hyperparams = {'cell_size': 182, 'hidden_size': 105, 'learning_rate': 0.08188855115046297, 'num_epochs': 121, 'patience': 10, 'batch_size': 512, 'early_stop_frac': 0.14032961504890157, 'seed': 2087})\n",
      "Model Structure:  GRUD(\n",
      "  (zl): Linear(in_features=313, out_features=105, bias=True)\n",
      "  (rl): Linear(in_features=313, out_features=105, bias=True)\n",
      "  (hl): Linear(in_features=313, out_features=105, bias=True)\n",
      "  (gamma_x_l): FilterLinear(in_features=104, out_features=104, bias=True)\n",
      "  (gamma_h_l): Linear(in_features=104, out_features=105, bias=True)\n",
      "  (fc): Linear(in_features=105, out_features=2, bias=True)\n",
      "  (bn): BatchNorm1d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (drop): Dropout(p=0.5, inplace=False)\n",
      ")\n",
      "Start Training ... \n",
      "Output type dermined by the model\n",
      "Epoch: 0, train_loss: 0.72731502, valid_loss: 0.71267516, time: [3.76], best model: 1\n",
      "Epoch: 1, train_loss: 0.66026361, valid_loss: 0.660701, time: [3.67], best model: 1\n",
      "Epoch: 2, train_loss: 0.65154634, valid_loss: 0.65250369, time: [3.65], best model: 1\n",
      "Epoch: 3, train_loss: 0.6502439, valid_loss: 0.65096147, time: [3.87], best model: 1\n",
      "Epoch: 4, train_loss: 0.64494378, valid_loss: 0.65218381, time: [3.67], best model: 0\n",
      "Epoch: 5, train_loss: 0.64310435, valid_loss: 0.65242209, time: [3.68], best model: 0\n",
      "Epoch: 6, train_loss: 0.64016833, valid_loss: 0.65011297, time: [3.73], best model: 1\n",
      "Epoch: 7, train_loss: 0.63963679, valid_loss: 0.6493142, time: [3.74], best model: 1\n",
      "Epoch: 8, train_loss: 0.6406201, valid_loss: 0.65110445, time: [3.76], best model: 0\n",
      "Epoch: 9, train_loss: 0.63658074, valid_loss: 0.64982469, time: [3.83], best model: 0\n",
      "Epoch: 10, train_loss: 0.63309138, valid_loss: 0.64801611, time: [3.77], best model: 1\n",
      "Epoch: 11, train_loss: 0.63243587, valid_loss: 0.6500751, time: [3.83], best model: 0\n",
      "Epoch: 12, train_loss: 0.62843772, valid_loss: 0.65393094, time: [3.71], best model: 0\n",
      "Epoch: 13, train_loss: 0.63069759, valid_loss: 0.65173599, time: [3.78], best model: 0\n",
      "Epoch: 14, train_loss: 0.62585919, valid_loss: 0.65129055, time: [3.7], best model: 0\n",
      "Epoch: 15, train_loss: 0.62870107, valid_loss: 0.65253523, time: [3.79], best model: 0\n",
      "Epoch: 16, train_loss: 0.62534073, valid_loss: 0.64912578, time: [3.68], best model: 0\n",
      "Epoch: 17, train_loss: 0.62558344, valid_loss: 0.65206644, time: [3.73], best model: 0\n",
      "Epoch: 18, train_loss: 0.62405109, valid_loss: 0.65690906, time: [3.75], best model: 0\n",
      "Epoch: 19, train_loss: 0.61932836, valid_loss: 0.65496438, time: [3.67], best model: 0\n",
      "Early Stopped at Epoch: 20\n",
      "On sample 37 / 60 (hyperparams = {'cell_size': 113, 'hidden_size': 173, 'learning_rate': 0.00512475622652616, 'num_epochs': 83, 'patience': 10, 'batch_size': 512, 'early_stop_frac': 0.0787635258215888, 'seed': 5126})\n",
      "Model Structure:  GRUD(\n",
      "  (zl): Linear(in_features=381, out_features=173, bias=True)\n",
      "  (rl): Linear(in_features=381, out_features=173, bias=True)\n",
      "  (hl): Linear(in_features=381, out_features=173, bias=True)\n",
      "  (gamma_x_l): FilterLinear(in_features=104, out_features=104, bias=True)\n",
      "  (gamma_h_l): Linear(in_features=104, out_features=173, bias=True)\n",
      "  (fc): Linear(in_features=173, out_features=2, bias=True)\n",
      "  (bn): BatchNorm1d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (drop): Dropout(p=0.5, inplace=False)\n",
      ")\n",
      "Start Training ... \n",
      "Output type dermined by the model\n",
      "Epoch: 0, train_loss: 0.80051308, valid_loss: 0.75995483, time: [4.09], best model: 1\n",
      "Epoch: 1, train_loss: 0.70261065, valid_loss: 0.7053098, time: [4.08], best model: 1\n",
      "Epoch: 2, train_loss: 0.67402611, valid_loss: 0.67492453, time: [4.12], best model: 1\n",
      "Epoch: 3, train_loss: 0.63826752, valid_loss: 0.66036873, time: [4.09], best model: 1\n",
      "Epoch: 4, train_loss: 0.62189687, valid_loss: 0.64746539, time: [4.11], best model: 1\n",
      "Epoch: 5, train_loss: 0.60984637, valid_loss: 0.63695316, time: [4.11], best model: 1\n",
      "Epoch: 6, train_loss: 0.59813957, valid_loss: 0.63734366, time: [4.06], best model: 0\n",
      "Epoch: 7, train_loss: 0.58588422, valid_loss: 0.64932461, time: [4.03], best model: 0\n",
      "Epoch: 8, train_loss: 0.57518139, valid_loss: 0.64661338, time: [4.05], best model: 0\n",
      "Epoch: 9, train_loss: 0.5594663, valid_loss: 0.66804562, time: [4.07], best model: 0\n",
      "Epoch: 10, train_loss: 0.54145451, valid_loss: 0.67556883, time: [4.03], best model: 0\n",
      "Epoch: 11, train_loss: 0.52597933, valid_loss: 0.68968366, time: [4.1], best model: 0\n",
      "Epoch: 12, train_loss: 0.50703897, valid_loss: 0.69984964, time: [4.08], best model: 0\n",
      "Epoch: 13, train_loss: 0.49034227, valid_loss: 0.71571693, time: [4.09], best model: 0\n",
      "Epoch: 14, train_loss: 0.46494468, valid_loss: 0.76014506, time: [4.09], best model: 0\n",
      "Early Stopped at Epoch: 15\n",
      "On sample 38 / 60 (hyperparams = {'cell_size': 99, 'hidden_size': 111, 'learning_rate': 0.02495740287443452, 'num_epochs': 79, 'patience': 10, 'batch_size': 512, 'early_stop_frac': 0.14671131315122965, 'seed': 417})\n",
      "Model Structure:  GRUD(\n",
      "  (zl): Linear(in_features=319, out_features=111, bias=True)\n",
      "  (rl): Linear(in_features=319, out_features=111, bias=True)\n",
      "  (hl): Linear(in_features=319, out_features=111, bias=True)\n",
      "  (gamma_x_l): FilterLinear(in_features=104, out_features=104, bias=True)\n",
      "  (gamma_h_l): Linear(in_features=104, out_features=111, bias=True)\n",
      "  (fc): Linear(in_features=111, out_features=2, bias=True)\n",
      "  (bn): BatchNorm1d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (drop): Dropout(p=0.5, inplace=False)\n",
      ")\n",
      "Start Training ... \n",
      "Output type dermined by the model\n",
      "Epoch: 0, train_loss: 0.74414727, valid_loss: 0.73016859, time: [3.68], best model: 1\n",
      "Epoch: 1, train_loss: 0.63223895, valid_loss: 0.63788209, time: [3.71], best model: 1\n",
      "Epoch: 2, train_loss: 0.62022753, valid_loss: 0.63369984, time: [3.62], best model: 1\n",
      "Epoch: 3, train_loss: 0.61800936, valid_loss: 0.63537654, time: [3.6], best model: 0\n",
      "Epoch: 4, train_loss: 0.61166806, valid_loss: 0.63953061, time: [3.79], best model: 0\n",
      "Epoch: 5, train_loss: 0.60164282, valid_loss: 0.63949896, time: [3.62], best model: 0\n",
      "Epoch: 6, train_loss: 0.59797223, valid_loss: 0.64576283, time: [3.58], best model: 0\n",
      "Epoch: 7, train_loss: 0.59094673, valid_loss: 0.65121149, time: [3.61], best model: 0\n",
      "Epoch: 8, train_loss: 0.58330472, valid_loss: 0.66957707, time: [3.66], best model: 0\n",
      "Epoch: 9, train_loss: 0.57375184, valid_loss: 0.67687324, time: [3.79], best model: 0\n",
      "Epoch: 10, train_loss: 0.57076617, valid_loss: 0.67259527, time: [3.71], best model: 0\n",
      "Epoch: 11, train_loss: 0.55334342, valid_loss: 0.69177091, time: [3.69], best model: 0\n",
      "Early Stopped at Epoch: 12\n",
      "On sample 39 / 60 (hyperparams = {'cell_size': 89, 'hidden_size': 138, 'learning_rate': 0.07246274991204592, 'num_epochs': 91, 'patience': 9, 'batch_size': 64, 'early_stop_frac': 0.1168099335625191, 'seed': 7563})\n",
      "Model Structure:  GRUD(\n",
      "  (zl): Linear(in_features=346, out_features=138, bias=True)\n",
      "  (rl): Linear(in_features=346, out_features=138, bias=True)\n",
      "  (hl): Linear(in_features=346, out_features=138, bias=True)\n",
      "  (gamma_x_l): FilterLinear(in_features=104, out_features=104, bias=True)\n",
      "  (gamma_h_l): Linear(in_features=104, out_features=138, bias=True)\n",
      "  (fc): Linear(in_features=138, out_features=2, bias=True)\n",
      "  (bn): BatchNorm1d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (drop): Dropout(p=0.5, inplace=False)\n",
      ")\n",
      "Start Training ... \n",
      "Output type dermined by the model\n",
      "Epoch: 0, train_loss: 0.67639339, valid_loss: 0.67799463, time: [14.48], best model: 1\n",
      "Epoch: 1, train_loss: 0.67020162, valid_loss: 0.67221083, time: [14.61], best model: 1\n",
      "Epoch: 2, train_loss: 0.6688025, valid_loss: 0.67145667, time: [14.66], best model: 1\n",
      "Epoch: 3, train_loss: 0.66730542, valid_loss: 0.66707852, time: [14.4], best model: 1\n",
      "Epoch: 4, train_loss: 0.66569057, valid_loss: 0.66918252, time: [14.46], best model: 0\n",
      "Epoch: 5, train_loss: 0.66346827, valid_loss: 0.66636109, time: [14.48], best model: 1\n",
      "Epoch: 6, train_loss: 0.66609932, valid_loss: 0.66729578, time: [14.67], best model: 0\n",
      "Epoch: 7, train_loss: 0.66236871, valid_loss: 0.66642959, time: [14.44], best model: 0\n",
      "Epoch: 8, train_loss: 0.6590956, valid_loss: 0.66644327, time: [14.51], best model: 0\n",
      "Epoch: 9, train_loss: 0.65771669, valid_loss: 0.65785779, time: [14.36], best model: 1\n",
      "Epoch: 10, train_loss: 0.66125891, valid_loss: 0.66488958, time: [14.47], best model: 0\n",
      "Epoch: 11, train_loss: 0.65792008, valid_loss: 0.65891494, time: [14.49], best model: 0\n",
      "Epoch: 12, train_loss: 0.65487202, valid_loss: 0.65965231, time: [14.54], best model: 0\n",
      "Epoch: 13, train_loss: 0.65706024, valid_loss: 0.65988648, time: [14.37], best model: 0\n",
      "Epoch: 14, train_loss: 0.65961136, valid_loss: 0.66348584, time: [14.51], best model: 0\n",
      "Epoch: 15, train_loss: 0.6564018, valid_loss: 0.66306368, time: [14.49], best model: 0\n",
      "Epoch: 16, train_loss: 0.65788705, valid_loss: 0.65726798, time: [14.44], best model: 1\n",
      "Epoch: 17, train_loss: 0.65022331, valid_loss: 0.65142538, time: [14.42], best model: 1\n",
      "Epoch: 18, train_loss: 0.65051012, valid_loss: 0.65590493, time: [14.44], best model: 0\n",
      "Epoch: 19, train_loss: 0.65166153, valid_loss: 0.65723878, time: [14.45], best model: 0\n",
      "Epoch: 20, train_loss: 0.6561165, valid_loss: 0.65752328, time: [14.53], best model: 0\n",
      "Epoch: 21, train_loss: 0.65869504, valid_loss: 0.65991521, time: [14.54], best model: 0\n",
      "Epoch: 22, train_loss: 0.65725867, valid_loss: 0.6559289, time: [14.48], best model: 0\n",
      "Epoch: 23, train_loss: 0.65150115, valid_loss: 0.6572588, time: [14.41], best model: 0\n",
      "Epoch: 24, train_loss: 0.64938916, valid_loss: 0.65528744, time: [14.4], best model: 0\n",
      "Epoch: 25, train_loss: 0.65169443, valid_loss: 0.65588755, time: [14.47], best model: 0\n",
      "Early Stopped at Epoch: 26\n",
      "On sample 40 / 60 (hyperparams = {'cell_size': 186, 'hidden_size': 143, 'learning_rate': 0.010756250900112284, 'num_epochs': 141, 'patience': 8, 'batch_size': 64, 'early_stop_frac': 0.10030067735343266, 'seed': 3370})\n",
      "Model Structure:  GRUD(\n",
      "  (zl): Linear(in_features=351, out_features=143, bias=True)\n",
      "  (rl): Linear(in_features=351, out_features=143, bias=True)\n",
      "  (hl): Linear(in_features=351, out_features=143, bias=True)\n",
      "  (gamma_x_l): FilterLinear(in_features=104, out_features=104, bias=True)\n",
      "  (gamma_h_l): Linear(in_features=104, out_features=143, bias=True)\n",
      "  (fc): Linear(in_features=143, out_features=2, bias=True)\n",
      "  (bn): BatchNorm1d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (drop): Dropout(p=0.5, inplace=False)\n",
      ")\n",
      "Start Training ... \n",
      "Output type dermined by the model\n",
      "Epoch: 0, train_loss: 0.68086801, valid_loss: 0.67082442, time: [15.08], best model: 1\n",
      "Epoch: 1, train_loss: 0.63439792, valid_loss: 0.6331593, time: [15.28], best model: 1\n",
      "Epoch: 2, train_loss: 0.63655136, valid_loss: 0.63469634, time: [14.96], best model: 0\n",
      "Epoch: 3, train_loss: 0.62768438, valid_loss: 0.62975405, time: [14.88], best model: 1\n",
      "Epoch: 4, train_loss: 0.6278206, valid_loss: 0.63415053, time: [14.77], best model: 0\n",
      "Epoch: 5, train_loss: 0.63058017, valid_loss: 0.63515982, time: [14.93], best model: 0\n",
      "Epoch: 6, train_loss: 0.62288, valid_loss: 0.63131155, time: [14.92], best model: 0\n",
      "Epoch: 7, train_loss: 0.6174717, valid_loss: 0.63663492, time: [14.9], best model: 0\n",
      "Epoch: 8, train_loss: 0.61663578, valid_loss: 0.63412326, time: [14.87], best model: 0\n",
      "Epoch: 9, train_loss: 0.60914553, valid_loss: 0.63614664, time: [14.94], best model: 0\n",
      "Epoch: 10, train_loss: 0.60414864, valid_loss: 0.64172175, time: [15.1], best model: 0\n",
      "Early Stopped at Epoch: 11\n",
      "On sample 41 / 60 (hyperparams = {'cell_size': 65, 'hidden_size': 175, 'learning_rate': 0.005058948319431931, 'num_epochs': 149, 'patience': 11, 'batch_size': 512, 'early_stop_frac': 0.08780024086485555, 'seed': 3185})\n",
      "Model Structure:  GRUD(\n",
      "  (zl): Linear(in_features=383, out_features=175, bias=True)\n",
      "  (rl): Linear(in_features=383, out_features=175, bias=True)\n",
      "  (hl): Linear(in_features=383, out_features=175, bias=True)\n",
      "  (gamma_x_l): FilterLinear(in_features=104, out_features=104, bias=True)\n",
      "  (gamma_h_l): Linear(in_features=104, out_features=175, bias=True)\n",
      "  (fc): Linear(in_features=175, out_features=2, bias=True)\n",
      "  (bn): BatchNorm1d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (drop): Dropout(p=0.5, inplace=False)\n",
      ")\n",
      "Start Training ... \n",
      "Output type dermined by the model\n",
      "Epoch: 0, train_loss: 0.78191474, valid_loss: 0.77669354, time: [4.], best model: 1\n",
      "Epoch: 1, train_loss: 0.69386791, valid_loss: 0.69234223, time: [3.93], best model: 1\n",
      "Epoch: 2, train_loss: 0.6608377, valid_loss: 0.66366689, time: [3.89], best model: 1\n",
      "Epoch: 3, train_loss: 0.6557116, valid_loss: 0.66244434, time: [3.98], best model: 1\n",
      "Epoch: 4, train_loss: 0.63777443, valid_loss: 0.64201677, time: [3.92], best model: 1\n",
      "Epoch: 5, train_loss: 0.62322597, valid_loss: 0.6380879, time: [3.91], best model: 1\n",
      "Epoch: 6, train_loss: 0.6131555, valid_loss: 0.61738415, time: [4.05], best model: 1\n",
      "Epoch: 7, train_loss: 0.60460788, valid_loss: 0.62167845, time: [4.03], best model: 0\n",
      "Epoch: 8, train_loss: 0.59309604, valid_loss: 0.61866537, time: [3.93], best model: 0\n",
      "Epoch: 9, train_loss: 0.58749028, valid_loss: 0.62897182, time: [3.9], best model: 0\n",
      "Epoch: 10, train_loss: 0.57379953, valid_loss: 0.62209846, time: [3.88], best model: 0\n",
      "Epoch: 11, train_loss: 0.56188202, valid_loss: 0.63861821, time: [3.95], best model: 0\n",
      "Epoch: 12, train_loss: 0.54778836, valid_loss: 0.65159252, time: [3.88], best model: 0\n",
      "Epoch: 13, train_loss: 0.5295301, valid_loss: 0.6538324, time: [3.99], best model: 0\n",
      "Epoch: 14, train_loss: 0.50607592, valid_loss: 0.69032426, time: [3.99], best model: 0\n",
      "Epoch: 15, train_loss: 0.48927304, valid_loss: 0.69522864, time: [4.05], best model: 0\n",
      "Epoch: 16, train_loss: 0.46464851, valid_loss: 0.71937311, time: [3.97], best model: 0\n",
      "Early Stopped at Epoch: 17\n",
      "On sample 42 / 60 (hyperparams = {'cell_size': 186, 'hidden_size': 160, 'learning_rate': 0.03771349336995607, 'num_epochs': 133, 'patience': 10, 'batch_size': 128, 'early_stop_frac': 0.08373682942964583, 'seed': 6040})\n",
      "Model Structure:  GRUD(\n",
      "  (zl): Linear(in_features=368, out_features=160, bias=True)\n",
      "  (rl): Linear(in_features=368, out_features=160, bias=True)\n",
      "  (hl): Linear(in_features=368, out_features=160, bias=True)\n",
      "  (gamma_x_l): FilterLinear(in_features=104, out_features=104, bias=True)\n",
      "  (gamma_h_l): Linear(in_features=104, out_features=160, bias=True)\n",
      "  (fc): Linear(in_features=160, out_features=2, bias=True)\n",
      "  (bn): BatchNorm1d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (drop): Dropout(p=0.5, inplace=False)\n",
      ")\n",
      "Start Training ... \n",
      "Output type dermined by the model\n",
      "Epoch: 0, train_loss: 0.66787547, valid_loss: 0.66986738, time: [8.66], best model: 1\n",
      "Epoch: 1, train_loss: 0.6504273, valid_loss: 0.6480368, time: [8.67], best model: 1\n",
      "Epoch: 2, train_loss: 0.65348983, valid_loss: 0.65400106, time: [8.63], best model: 0\n",
      "Epoch: 3, train_loss: 0.64607591, valid_loss: 0.64375491, time: [8.59], best model: 1\n",
      "Epoch: 4, train_loss: 0.64304916, valid_loss: 0.65002422, time: [8.59], best model: 0\n",
      "Epoch: 5, train_loss: 0.643095, valid_loss: 0.6543917, time: [8.59], best model: 0\n",
      "Epoch: 6, train_loss: 0.64267346, valid_loss: 0.65162691, time: [8.54], best model: 0\n",
      "Epoch: 7, train_loss: 0.6366538, valid_loss: 0.6527551, time: [8.58], best model: 0\n",
      "Epoch: 8, train_loss: 0.64238604, valid_loss: 0.65414724, time: [8.62], best model: 0\n",
      "Epoch: 9, train_loss: 0.63824463, valid_loss: 0.64677057, time: [8.61], best model: 0\n",
      "Epoch: 10, train_loss: 0.63735013, valid_loss: 0.65618704, time: [8.73], best model: 0\n",
      "Epoch: 11, train_loss: 0.63693686, valid_loss: 0.65572537, time: [8.6], best model: 0\n",
      "Epoch: 12, train_loss: 0.63138683, valid_loss: 0.65221803, time: [8.58], best model: 0\n",
      "Early Stopped at Epoch: 13\n",
      "On sample 43 / 60 (hyperparams = {'cell_size': 195, 'hidden_size': 97, 'learning_rate': 0.060978199147176386, 'num_epochs': 119, 'patience': 11, 'batch_size': 256, 'early_stop_frac': 0.1452010705083001, 'seed': 4311})\n",
      "Model Structure:  GRUD(\n",
      "  (zl): Linear(in_features=305, out_features=97, bias=True)\n",
      "  (rl): Linear(in_features=305, out_features=97, bias=True)\n",
      "  (hl): Linear(in_features=305, out_features=97, bias=True)\n",
      "  (gamma_x_l): FilterLinear(in_features=104, out_features=104, bias=True)\n",
      "  (gamma_h_l): Linear(in_features=104, out_features=97, bias=True)\n",
      "  (fc): Linear(in_features=97, out_features=2, bias=True)\n",
      "  (bn): BatchNorm1d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (drop): Dropout(p=0.5, inplace=False)\n",
      ")\n",
      "Start Training ... \n",
      "Output type dermined by the model\n",
      "Epoch: 0, train_loss: 0.69217606, valid_loss: 0.68187804, time: [4.84], best model: 1\n",
      "Epoch: 1, train_loss: 0.64151563, valid_loss: 0.65072882, time: [4.78], best model: 1\n",
      "Epoch: 2, train_loss: 0.63883785, valid_loss: 0.64679357, time: [4.8], best model: 1\n",
      "Epoch: 3, train_loss: 0.63292944, valid_loss: 0.64903786, time: [4.71], best model: 0\n",
      "Epoch: 4, train_loss: 0.63474204, valid_loss: 0.6460504, time: [4.74], best model: 1\n",
      "Epoch: 5, train_loss: 0.63867264, valid_loss: 0.64627283, time: [4.83], best model: 0\n",
      "Epoch: 6, train_loss: 0.63076498, valid_loss: 0.64973145, time: [4.84], best model: 0\n",
      "Epoch: 7, train_loss: 0.62855266, valid_loss: 0.64940997, time: [4.83], best model: 0\n",
      "Epoch: 8, train_loss: 0.63520265, valid_loss: 0.65688782, time: [4.82], best model: 0\n",
      "Epoch: 9, train_loss: 0.63551525, valid_loss: 0.65597853, time: [4.78], best model: 0\n",
      "Epoch: 10, train_loss: 0.63746761, valid_loss: 0.65051221, time: [4.82], best model: 0\n",
      "Epoch: 11, train_loss: 0.62952694, valid_loss: 0.65286782, time: [4.77], best model: 0\n",
      "Epoch: 12, train_loss: 0.63511415, valid_loss: 0.65803417, time: [4.73], best model: 0\n",
      "Epoch: 13, train_loss: 0.64502855, valid_loss: 0.66435588, time: [4.76], best model: 0\n",
      "Epoch: 14, train_loss: 0.64432498, valid_loss: 0.65438656, time: [4.74], best model: 0\n",
      "Early Stopped at Epoch: 15\n",
      "On sample 44 / 60 (hyperparams = {'cell_size': 167, 'hidden_size': 184, 'learning_rate': 0.007222272738416023, 'num_epochs': 60, 'patience': 10, 'batch_size': 256, 'early_stop_frac': 0.1193333828589223, 'seed': 928})\n",
      "Model Structure:  GRUD(\n",
      "  (zl): Linear(in_features=392, out_features=184, bias=True)\n",
      "  (rl): Linear(in_features=392, out_features=184, bias=True)\n",
      "  (hl): Linear(in_features=392, out_features=184, bias=True)\n",
      "  (gamma_x_l): FilterLinear(in_features=104, out_features=104, bias=True)\n",
      "  (gamma_h_l): Linear(in_features=104, out_features=184, bias=True)\n",
      "  (fc): Linear(in_features=184, out_features=2, bias=True)\n",
      "  (bn): BatchNorm1d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (drop): Dropout(p=0.5, inplace=False)\n",
      ")\n",
      "Start Training ... \n",
      "Output type dermined by the model\n",
      "Epoch: 0, train_loss: 0.7340974, valid_loss: 0.72927602, time: [5.86], best model: 1\n",
      "Epoch: 1, train_loss: 0.65736289, valid_loss: 0.68855861, time: [5.87], best model: 1\n",
      "Epoch: 2, train_loss: 0.63112573, valid_loss: 0.65310207, time: [5.79], best model: 1\n",
      "Epoch: 3, train_loss: 0.62126889, valid_loss: 0.64111977, time: [5.88], best model: 1\n",
      "Epoch: 4, train_loss: 0.6126357, valid_loss: 0.64109093, time: [5.92], best model: 1\n",
      "Epoch: 5, train_loss: 0.60931222, valid_loss: 0.64957542, time: [5.82], best model: 0\n",
      "Epoch: 6, train_loss: 0.60577647, valid_loss: 0.6450627, time: [5.85], best model: 0\n",
      "Epoch: 7, train_loss: 0.59884215, valid_loss: 0.64387914, time: [5.81], best model: 0\n",
      "Epoch: 8, train_loss: 0.58918508, valid_loss: 0.65646081, time: [5.84], best model: 0\n",
      "Epoch: 9, train_loss: 0.58334277, valid_loss: 0.65777621, time: [5.82], best model: 0\n",
      "Epoch: 10, train_loss: 0.57440406, valid_loss: 0.66148892, time: [5.84], best model: 0\n",
      "Epoch: 11, train_loss: 0.56288428, valid_loss: 0.68179582, time: [5.87], best model: 0\n",
      "Epoch: 12, train_loss: 0.55725559, valid_loss: 0.69510985, time: [5.86], best model: 0\n",
      "Epoch: 13, train_loss: 0.54584911, valid_loss: 0.70734037, time: [5.77], best model: 0\n",
      "Early Stopped at Epoch: 14\n",
      "On sample 45 / 60 (hyperparams = {'cell_size': 123, 'hidden_size': 81, 'learning_rate': 0.008566366620637754, 'num_epochs': 68, 'patience': 9, 'batch_size': 256, 'early_stop_frac': 0.10341017000733373, 'seed': 6310})\n",
      "Model Structure:  GRUD(\n",
      "  (zl): Linear(in_features=289, out_features=81, bias=True)\n",
      "  (rl): Linear(in_features=289, out_features=81, bias=True)\n",
      "  (hl): Linear(in_features=289, out_features=81, bias=True)\n",
      "  (gamma_x_l): FilterLinear(in_features=104, out_features=104, bias=True)\n",
      "  (gamma_h_l): Linear(in_features=104, out_features=81, bias=True)\n",
      "  (fc): Linear(in_features=81, out_features=2, bias=True)\n",
      "  (bn): BatchNorm1d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (drop): Dropout(p=0.5, inplace=False)\n",
      ")\n",
      "Start Training ... \n",
      "Output type dermined by the model\n",
      "Epoch: 0, train_loss: 0.74493994, valid_loss: 0.73447852, time: [5.07], best model: 1\n",
      "Epoch: 1, train_loss: 0.64798638, valid_loss: 0.64779091, time: [5.01], best model: 1\n",
      "Epoch: 2, train_loss: 0.62742056, valid_loss: 0.63310314, time: [5.03], best model: 1\n",
      "Epoch: 3, train_loss: 0.62077535, valid_loss: 0.6215308, time: [5.03], best model: 1\n",
      "Epoch: 4, train_loss: 0.61366857, valid_loss: 0.62653134, time: [4.98], best model: 0\n",
      "Epoch: 5, train_loss: 0.60528775, valid_loss: 0.62275235, time: [4.99], best model: 0\n",
      "Epoch: 6, train_loss: 0.60053668, valid_loss: 0.63287143, time: [5.02], best model: 0\n",
      "Epoch: 7, train_loss: 0.5906332, valid_loss: 0.63481311, time: [5.04], best model: 0\n",
      "Epoch: 8, train_loss: 0.58709473, valid_loss: 0.64025576, time: [4.99], best model: 0\n",
      "Epoch: 9, train_loss: 0.57129656, valid_loss: 0.65219886, time: [4.97], best model: 0\n",
      "Epoch: 10, train_loss: 0.55966982, valid_loss: 0.66655731, time: [5.01], best model: 0\n",
      "Epoch: 11, train_loss: 0.54911416, valid_loss: 0.68818092, time: [5.07], best model: 0\n",
      "Early Stopped at Epoch: 12\n",
      "On sample 46 / 60 (hyperparams = {'cell_size': 155, 'hidden_size': 123, 'learning_rate': 0.006350118605971565, 'num_epochs': 70, 'patience': 11, 'batch_size': 256, 'early_stop_frac': 0.054348969793627744, 'seed': 5768})\n",
      "Model Structure:  GRUD(\n",
      "  (zl): Linear(in_features=331, out_features=123, bias=True)\n",
      "  (rl): Linear(in_features=331, out_features=123, bias=True)\n",
      "  (hl): Linear(in_features=331, out_features=123, bias=True)\n",
      "  (gamma_x_l): FilterLinear(in_features=104, out_features=104, bias=True)\n",
      "  (gamma_h_l): Linear(in_features=104, out_features=123, bias=True)\n",
      "  (fc): Linear(in_features=123, out_features=2, bias=True)\n",
      "  (bn): BatchNorm1d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (drop): Dropout(p=0.5, inplace=False)\n",
      ")\n",
      "Start Training ... \n",
      "Output type dermined by the model\n",
      "Epoch: 0, train_loss: 0.74667565, valid_loss: 0.76382396, time: [5.52], best model: 1\n",
      "Epoch: 1, train_loss: 0.65249709, valid_loss: 0.65808212, time: [5.45], best model: 1\n",
      "Epoch: 2, train_loss: 0.62620563, valid_loss: 0.63665415, time: [5.42], best model: 1\n",
      "Epoch: 3, train_loss: 0.61620862, valid_loss: 0.63122402, time: [5.36], best model: 1\n",
      "Epoch: 4, train_loss: 0.61487861, valid_loss: 0.63132521, time: [5.37], best model: 0\n",
      "Epoch: 5, train_loss: 0.60540509, valid_loss: 0.63710153, time: [5.44], best model: 0\n",
      "Epoch: 6, train_loss: 0.59808056, valid_loss: 0.64153753, time: [5.41], best model: 0\n",
      "Epoch: 7, train_loss: 0.58258576, valid_loss: 0.6519761, time: [5.43], best model: 0\n",
      "Epoch: 8, train_loss: 0.56907979, valid_loss: 0.66791903, time: [5.43], best model: 0\n",
      "Epoch: 9, train_loss: 0.5535676, valid_loss: 0.67797095, time: [5.42], best model: 0\n",
      "Epoch: 10, train_loss: 0.5345085, valid_loss: 0.68738256, time: [5.46], best model: 0\n",
      "Epoch: 11, train_loss: 0.51361128, valid_loss: 0.72240204, time: [5.42], best model: 0\n",
      "Epoch: 12, train_loss: 0.49421773, valid_loss: 0.74287702, time: [5.44], best model: 0\n",
      "Epoch: 13, train_loss: 0.46820494, valid_loss: 0.77932827, time: [5.42], best model: 0\n",
      "Early Stopped at Epoch: 14\n",
      "On sample 47 / 60 (hyperparams = {'cell_size': 160, 'hidden_size': 86, 'learning_rate': 0.041515075846750384, 'num_epochs': 68, 'patience': 9, 'batch_size': 256, 'early_stop_frac': 0.07475508756225406, 'seed': 7741})\n",
      "Model Structure:  GRUD(\n",
      "  (zl): Linear(in_features=294, out_features=86, bias=True)\n",
      "  (rl): Linear(in_features=294, out_features=86, bias=True)\n",
      "  (hl): Linear(in_features=294, out_features=86, bias=True)\n",
      "  (gamma_x_l): FilterLinear(in_features=104, out_features=104, bias=True)\n",
      "  (gamma_h_l): Linear(in_features=104, out_features=86, bias=True)\n",
      "  (fc): Linear(in_features=86, out_features=2, bias=True)\n",
      "  (bn): BatchNorm1d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (drop): Dropout(p=0.5, inplace=False)\n",
      ")\n",
      "Start Training ... \n",
      "Output type dermined by the model\n",
      "Epoch: 0, train_loss: 0.67914244, valid_loss: 0.68295441, time: [5.17], best model: 1\n",
      "Epoch: 1, train_loss: 0.63529256, valid_loss: 0.65345491, time: [5.2], best model: 1\n",
      "Epoch: 2, train_loss: 0.63039335, valid_loss: 0.6452233, time: [5.14], best model: 1\n",
      "Epoch: 3, train_loss: 0.63314126, valid_loss: 0.64980189, time: [5.15], best model: 0\n",
      "Epoch: 4, train_loss: 0.62970009, valid_loss: 0.64802799, time: [5.17], best model: 0\n",
      "Epoch: 5, train_loss: 0.6337567, valid_loss: 0.64697056, time: [5.16], best model: 0\n",
      "Epoch: 6, train_loss: 0.62747396, valid_loss: 0.64617036, time: [5.15], best model: 0\n",
      "Epoch: 7, train_loss: 0.62847214, valid_loss: 0.65071176, time: [5.26], best model: 0\n",
      "Epoch: 8, train_loss: 0.62536093, valid_loss: 0.65218716, time: [5.15], best model: 0\n",
      "Epoch: 9, train_loss: 0.62987321, valid_loss: 0.64876175, time: [5.41], best model: 0\n",
      "Epoch: 10, train_loss: 0.63364944, valid_loss: 0.65534528, time: [5.16], best model: 0\n",
      "Early Stopped at Epoch: 11\n",
      "On sample 48 / 60 (hyperparams = {'cell_size': 133, 'hidden_size': 157, 'learning_rate': 0.06884270460160578, 'num_epochs': 106, 'patience': 8, 'batch_size': 512, 'early_stop_frac': 0.14431707226672083, 'seed': 4586})\n",
      "Model Structure:  GRUD(\n",
      "  (zl): Linear(in_features=365, out_features=157, bias=True)\n",
      "  (rl): Linear(in_features=365, out_features=157, bias=True)\n",
      "  (hl): Linear(in_features=365, out_features=157, bias=True)\n",
      "  (gamma_x_l): FilterLinear(in_features=104, out_features=104, bias=True)\n",
      "  (gamma_h_l): Linear(in_features=104, out_features=157, bias=True)\n",
      "  (fc): Linear(in_features=157, out_features=2, bias=True)\n",
      "  (bn): BatchNorm1d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (drop): Dropout(p=0.5, inplace=False)\n",
      ")\n",
      "Start Training ... \n",
      "Output type dermined by the model\n",
      "Epoch: 0, train_loss: 0.72313499, valid_loss: 0.70575217, time: [3.9], best model: 1\n",
      "Epoch: 1, train_loss: 0.6596989, valid_loss: 0.6539214, time: [3.89], best model: 1\n",
      "Epoch: 2, train_loss: 0.64386627, valid_loss: 0.64275462, time: [3.85], best model: 1\n",
      "Epoch: 3, train_loss: 0.63995831, valid_loss: 0.6388325, time: [3.84], best model: 1\n",
      "Epoch: 4, train_loss: 0.63841043, valid_loss: 0.64222533, time: [3.84], best model: 0\n",
      "Epoch: 5, train_loss: 0.63739892, valid_loss: 0.63820342, time: [3.85], best model: 1\n",
      "Epoch: 6, train_loss: 0.64617859, valid_loss: 0.64361981, time: [3.9], best model: 0\n",
      "Epoch: 7, train_loss: 0.63729634, valid_loss: 0.64226484, time: [3.85], best model: 0\n",
      "Epoch: 8, train_loss: 0.63645969, valid_loss: 0.64117241, time: [3.85], best model: 0\n",
      "Epoch: 9, train_loss: 0.63515963, valid_loss: 0.64486919, time: [4.01], best model: 0\n",
      "Epoch: 10, train_loss: 0.64955698, valid_loss: 0.64426504, time: [3.91], best model: 0\n",
      "Epoch: 11, train_loss: 0.64253807, valid_loss: 0.63882542, time: [3.85], best model: 0\n",
      "Epoch: 12, train_loss: 0.63766166, valid_loss: 0.64110592, time: [3.86], best model: 0\n",
      "Early Stopped at Epoch: 13\n",
      "On sample 49 / 60 (hyperparams = {'cell_size': 146, 'hidden_size': 116, 'learning_rate': 0.02180271118161696, 'num_epochs': 95, 'patience': 10, 'batch_size': 128, 'early_stop_frac': 0.10568601662432534, 'seed': 7836})\n",
      "Model Structure:  GRUD(\n",
      "  (zl): Linear(in_features=324, out_features=116, bias=True)\n",
      "  (rl): Linear(in_features=324, out_features=116, bias=True)\n",
      "  (hl): Linear(in_features=324, out_features=116, bias=True)\n",
      "  (gamma_x_l): FilterLinear(in_features=104, out_features=104, bias=True)\n",
      "  (gamma_h_l): Linear(in_features=104, out_features=116, bias=True)\n",
      "  (fc): Linear(in_features=116, out_features=2, bias=True)\n",
      "  (bn): BatchNorm1d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (drop): Dropout(p=0.5, inplace=False)\n",
      ")\n",
      "Start Training ... \n",
      "Output type dermined by the model\n",
      "Epoch: 0, train_loss: 0.67396565, valid_loss: 0.66839626, time: [8.48], best model: 1\n",
      "Epoch: 1, train_loss: 0.63495153, valid_loss: 0.63619434, time: [8.68], best model: 1\n",
      "Epoch: 2, train_loss: 0.62729827, valid_loss: 0.63823067, time: [8.72], best model: 0\n",
      "Epoch: 3, train_loss: 0.62574703, valid_loss: 0.6432546, time: [8.53], best model: 0\n",
      "Epoch: 4, train_loss: 0.62472397, valid_loss: 0.6443293, time: [8.55], best model: 0\n",
      "Epoch: 5, train_loss: 0.62611487, valid_loss: 0.63794369, time: [8.53], best model: 0\n",
      "Epoch: 6, train_loss: 0.63270347, valid_loss: 0.63798516, time: [8.67], best model: 0\n",
      "Epoch: 7, train_loss: 0.6360025, valid_loss: 0.64400821, time: [8.54], best model: 0\n",
      "Epoch: 8, train_loss: 0.63790163, valid_loss: 0.65150843, time: [8.47], best model: 0\n",
      "Epoch: 9, train_loss: 0.63386242, valid_loss: 0.64123326, time: [8.5], best model: 0\n",
      "Epoch: 10, train_loss: 0.63421422, valid_loss: 0.64959684, time: [8.6], best model: 0\n",
      "Early Stopped at Epoch: 11\n",
      "On sample 50 / 60 (hyperparams = {'cell_size': 93, 'hidden_size': 162, 'learning_rate': 0.08962664517041591, 'num_epochs': 138, 'patience': 8, 'batch_size': 256, 'early_stop_frac': 0.08575182323552322, 'seed': 2695})\n",
      "Model Structure:  GRUD(\n",
      "  (zl): Linear(in_features=370, out_features=162, bias=True)\n",
      "  (rl): Linear(in_features=370, out_features=162, bias=True)\n",
      "  (hl): Linear(in_features=370, out_features=162, bias=True)\n",
      "  (gamma_x_l): FilterLinear(in_features=104, out_features=104, bias=True)\n",
      "  (gamma_h_l): Linear(in_features=104, out_features=162, bias=True)\n",
      "  (fc): Linear(in_features=162, out_features=2, bias=True)\n",
      "  (bn): BatchNorm1d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (drop): Dropout(p=0.5, inplace=False)\n",
      ")\n",
      "Start Training ... \n",
      "Output type dermined by the model\n",
      "Epoch: 0, train_loss: 0.68327765, valid_loss: 0.67453856, time: [6.28], best model: 1\n",
      "Epoch: 1, train_loss: 0.65365491, valid_loss: 0.65583413, time: [6.5], best model: 1\n",
      "Epoch: 2, train_loss: 0.6518554, valid_loss: 0.65397172, time: [6.19], best model: 1\n",
      "Epoch: 3, train_loss: 0.64830638, valid_loss: 0.65239644, time: [6.26], best model: 1\n",
      "Epoch: 4, train_loss: 0.65107197, valid_loss: 0.65368607, time: [6.12], best model: 0\n",
      "Epoch: 5, train_loss: 0.64649679, valid_loss: 0.6548127, time: [6.12], best model: 0\n",
      "Epoch: 6, train_loss: 0.65305438, valid_loss: 0.66489359, time: [6.2], best model: 0\n",
      "Epoch: 7, train_loss: 0.65324085, valid_loss: 0.65793429, time: [5.96], best model: 0\n",
      "Epoch: 8, train_loss: 0.66125708, valid_loss: 0.66193674, time: [5.95], best model: 0\n",
      "Epoch: 9, train_loss: 0.65796467, valid_loss: 0.66175325, time: [5.96], best model: 0\n",
      "Epoch: 10, train_loss: 0.6563808, valid_loss: 0.66162814, time: [6.1], best model: 0\n",
      "Early Stopped at Epoch: 11\n",
      "On sample 51 / 60 (hyperparams = {'cell_size': 82, 'hidden_size': 73, 'learning_rate': 0.04523890954448474, 'num_epochs': 139, 'patience': 10, 'batch_size': 64, 'early_stop_frac': 0.05094503741378993, 'seed': 7921})\n",
      "Model Structure:  GRUD(\n",
      "  (zl): Linear(in_features=281, out_features=73, bias=True)\n",
      "  (rl): Linear(in_features=281, out_features=73, bias=True)\n",
      "  (hl): Linear(in_features=281, out_features=73, bias=True)\n",
      "  (gamma_x_l): FilterLinear(in_features=104, out_features=104, bias=True)\n",
      "  (gamma_h_l): Linear(in_features=104, out_features=73, bias=True)\n",
      "  (fc): Linear(in_features=73, out_features=2, bias=True)\n",
      "  (bn): BatchNorm1d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (drop): Dropout(p=0.5, inplace=False)\n",
      ")\n",
      "Start Training ... \n",
      "Output type dermined by the model\n",
      "Epoch: 0, train_loss: 0.67162828, valid_loss: 0.67033306, time: [14.47], best model: 1\n",
      "Epoch: 1, train_loss: 0.65904906, valid_loss: 0.67314382, time: [14.73], best model: 0\n",
      "Epoch: 2, train_loss: 0.65513395, valid_loss: 0.67075932, time: [14.36], best model: 0\n",
      "Epoch: 3, train_loss: 0.65175543, valid_loss: 0.66422081, time: [14.58], best model: 1\n",
      "Epoch: 4, train_loss: 0.64569978, valid_loss: 0.66976596, time: [14.32], best model: 0\n",
      "Epoch: 5, train_loss: 0.64747558, valid_loss: 0.6645685, time: [14.28], best model: 0\n",
      "Epoch: 6, train_loss: 0.64873129, valid_loss: 0.66549393, time: [14.36], best model: 0\n",
      "Epoch: 7, train_loss: 0.64427966, valid_loss: 0.66429181, time: [14.37], best model: 0\n",
      "Epoch: 8, train_loss: 0.6432724, valid_loss: 0.66626684, time: [14.31], best model: 0\n",
      "Epoch: 9, train_loss: 0.64410696, valid_loss: 0.66432362, time: [14.35], best model: 0\n",
      "Epoch: 10, train_loss: 0.64015493, valid_loss: 0.6657449, time: [14.36], best model: 0\n",
      "Epoch: 11, train_loss: 0.64348122, valid_loss: 0.66546336, time: [14.35], best model: 0\n",
      "Epoch: 12, train_loss: 0.63930185, valid_loss: 0.67038973, time: [14.38], best model: 0\n",
      "Early Stopped at Epoch: 13\n",
      "On sample 52 / 60 (hyperparams = {'cell_size': 76, 'hidden_size': 172, 'learning_rate': 0.06396414637099647, 'num_epochs': 114, 'patience': 11, 'batch_size': 256, 'early_stop_frac': 0.0753548267224923, 'seed': 1139})\n",
      "Model Structure:  GRUD(\n",
      "  (zl): Linear(in_features=380, out_features=172, bias=True)\n",
      "  (rl): Linear(in_features=380, out_features=172, bias=True)\n",
      "  (hl): Linear(in_features=380, out_features=172, bias=True)\n",
      "  (gamma_x_l): FilterLinear(in_features=104, out_features=104, bias=True)\n",
      "  (gamma_h_l): Linear(in_features=104, out_features=172, bias=True)\n",
      "  (fc): Linear(in_features=172, out_features=2, bias=True)\n",
      "  (bn): BatchNorm1d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (drop): Dropout(p=0.5, inplace=False)\n",
      ")\n",
      "Start Training ... \n",
      "Output type dermined by the model\n",
      "Epoch: 0, train_loss: 0.67714214, valid_loss: 0.68489825, time: [6.07], best model: 1\n",
      "Epoch: 1, train_loss: 0.65225512, valid_loss: 0.65662111, time: [5.98], best model: 1\n",
      "Epoch: 2, train_loss: 0.65891291, valid_loss: 0.65796324, time: [6.01], best model: 0\n",
      "Epoch: 3, train_loss: 0.65449657, valid_loss: 0.65979557, time: [6.04], best model: 0\n",
      "Epoch: 4, train_loss: 0.64761887, valid_loss: 0.65921307, time: [6.1], best model: 0\n",
      "Epoch: 5, train_loss: 0.6495676, valid_loss: 0.65508569, time: [6.13], best model: 1\n",
      "Epoch: 6, train_loss: 0.64997164, valid_loss: 0.64911652, time: [6.2], best model: 1\n",
      "Epoch: 7, train_loss: 0.64349492, valid_loss: 0.65027091, time: [6.25], best model: 0\n",
      "Epoch: 8, train_loss: 0.64212195, valid_loss: 0.64569709, time: [6.12], best model: 1\n",
      "Epoch: 9, train_loss: 0.64136384, valid_loss: 0.64783599, time: [6.09], best model: 0\n",
      "Epoch: 10, train_loss: 0.64423656, valid_loss: 0.64969851, time: [6.13], best model: 0\n",
      "Epoch: 11, train_loss: 0.64129969, valid_loss: 0.65134494, time: [6.07], best model: 0\n",
      "Epoch: 12, train_loss: 0.6493096, valid_loss: 0.65389608, time: [6.08], best model: 0\n",
      "Epoch: 13, train_loss: 0.64643027, valid_loss: 0.64827442, time: [6.05], best model: 0\n",
      "Epoch: 14, train_loss: 0.64673723, valid_loss: 0.64993401, time: [6.07], best model: 0\n",
      "Epoch: 15, train_loss: 0.64477914, valid_loss: 0.6512469, time: [6.04], best model: 0\n",
      "Epoch: 16, train_loss: 0.6443751, valid_loss: 0.64959424, time: [6.02], best model: 0\n",
      "Epoch: 17, train_loss: 0.64729144, valid_loss: 0.65132236, time: [6.11], best model: 0\n",
      "Epoch: 18, train_loss: 0.6452418, valid_loss: 0.64712957, time: [6.24], best model: 0\n",
      "Early Stopped at Epoch: 19\n",
      "On sample 53 / 60 (hyperparams = {'cell_size': 186, 'hidden_size': 151, 'learning_rate': 0.031042674293498843, 'num_epochs': 109, 'patience': 11, 'batch_size': 64, 'early_stop_frac': 0.07542266901505368, 'seed': 3079})\n",
      "Model Structure:  GRUD(\n",
      "  (zl): Linear(in_features=359, out_features=151, bias=True)\n",
      "  (rl): Linear(in_features=359, out_features=151, bias=True)\n",
      "  (hl): Linear(in_features=359, out_features=151, bias=True)\n",
      "  (gamma_x_l): FilterLinear(in_features=104, out_features=104, bias=True)\n",
      "  (gamma_h_l): Linear(in_features=104, out_features=151, bias=True)\n",
      "  (fc): Linear(in_features=151, out_features=2, bias=True)\n",
      "  (bn): BatchNorm1d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (drop): Dropout(p=0.5, inplace=False)\n",
      ")\n",
      "Start Training ... \n",
      "Output type dermined by the model\n",
      "Epoch: 0, train_loss: 0.68130109, valid_loss: 0.68240495, time: [15.24], best model: 1\n",
      "Epoch: 1, train_loss: 0.65087229, valid_loss: 0.6562918, time: [15.21], best model: 1\n",
      "Epoch: 2, train_loss: 0.65063495, valid_loss: 0.65948972, time: [15.12], best model: 0\n",
      "Epoch: 3, train_loss: 0.64679825, valid_loss: 0.65210106, time: [15.03], best model: 1\n",
      "Epoch: 4, train_loss: 0.64820086, valid_loss: 0.66055588, time: [15.02], best model: 0\n",
      "Epoch: 5, train_loss: 0.64630789, valid_loss: 0.66406124, time: [14.98], best model: 0\n",
      "Epoch: 6, train_loss: 0.64211065, valid_loss: 0.65532413, time: [15.09], best model: 0\n",
      "Epoch: 7, train_loss: 0.63861664, valid_loss: 0.65671306, time: [15.05], best model: 0\n",
      "Epoch: 8, train_loss: 0.63781757, valid_loss: 0.65682504, time: [15.22], best model: 0\n",
      "Epoch: 9, train_loss: 0.63991231, valid_loss: 0.65198271, time: [15.16], best model: 1\n",
      "Epoch: 10, train_loss: 0.63750842, valid_loss: 0.65191468, time: [15.23], best model: 1\n",
      "Epoch: 11, train_loss: 0.63990538, valid_loss: 0.65033356, time: [15.35], best model: 1\n",
      "Epoch: 12, train_loss: 0.63719619, valid_loss: 0.65272074, time: [15.23], best model: 0\n",
      "Epoch: 13, train_loss: 0.63980506, valid_loss: 0.64837268, time: [15.15], best model: 1\n",
      "Epoch: 14, train_loss: 0.63365816, valid_loss: 0.64774663, time: [15.17], best model: 1\n",
      "Epoch: 15, train_loss: 0.64169267, valid_loss: 0.65651293, time: [15.42], best model: 0\n",
      "Epoch: 16, train_loss: 0.64311237, valid_loss: 0.65281766, time: [15.34], best model: 0\n",
      "Epoch: 17, train_loss: 0.64427923, valid_loss: 0.65164557, time: [15.4], best model: 0\n",
      "Epoch: 18, train_loss: 0.64595391, valid_loss: 0.64896607, time: [15.19], best model: 0\n",
      "Epoch: 19, train_loss: 0.64365866, valid_loss: 0.65245308, time: [15.21], best model: 0\n",
      "Epoch: 20, train_loss: 0.64436857, valid_loss: 0.65227906, time: [15.41], best model: 0\n",
      "Epoch: 21, train_loss: 0.64344516, valid_loss: 0.6562773, time: [15.33], best model: 0\n",
      "Epoch: 22, train_loss: 0.63985431, valid_loss: 0.65425463, time: [15.37], best model: 0\n",
      "Epoch: 23, train_loss: 0.63717456, valid_loss: 0.65608777, time: [15.33], best model: 0\n",
      "Epoch: 24, train_loss: 0.63699908, valid_loss: 0.65359951, time: [15.42], best model: 0\n",
      "Early Stopped at Epoch: 25\n",
      "On sample 54 / 60 (hyperparams = {'cell_size': 126, 'hidden_size': 153, 'learning_rate': 0.06352545734642763, 'num_epochs': 66, 'patience': 9, 'batch_size': 512, 'early_stop_frac': 0.06706855260340261, 'seed': 5773})\n",
      "Model Structure:  GRUD(\n",
      "  (zl): Linear(in_features=361, out_features=153, bias=True)\n",
      "  (rl): Linear(in_features=361, out_features=153, bias=True)\n",
      "  (hl): Linear(in_features=361, out_features=153, bias=True)\n",
      "  (gamma_x_l): FilterLinear(in_features=104, out_features=104, bias=True)\n",
      "  (gamma_h_l): Linear(in_features=104, out_features=153, bias=True)\n",
      "  (fc): Linear(in_features=153, out_features=2, bias=True)\n",
      "  (bn): BatchNorm1d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (drop): Dropout(p=0.5, inplace=False)\n",
      ")\n",
      "Start Training ... \n",
      "Output type dermined by the model\n",
      "Epoch: 0, train_loss: 0.7213267, valid_loss: 0.70835247, time: [4.19], best model: 1\n",
      "Epoch: 1, train_loss: 0.65491435, valid_loss: 0.66076444, time: [4.12], best model: 1\n",
      "Epoch: 2, train_loss: 0.64447543, valid_loss: 0.6506609, time: [4.14], best model: 1\n",
      "Epoch: 3, train_loss: 0.64232966, valid_loss: 0.65748278, time: [4.13], best model: 0\n",
      "Epoch: 4, train_loss: 0.64248867, valid_loss: 0.65452271, time: [4.08], best model: 0\n",
      "Epoch: 5, train_loss: 0.64940408, valid_loss: 0.65627588, time: [4.05], best model: 0\n",
      "Epoch: 6, train_loss: 0.64889806, valid_loss: 0.65635624, time: [4.03], best model: 0\n",
      "Epoch: 7, train_loss: 0.6427386, valid_loss: 0.65238406, time: [4.12], best model: 0\n",
      "Epoch: 8, train_loss: 0.64081491, valid_loss: 0.64949983, time: [4.14], best model: 1\n",
      "Epoch: 9, train_loss: 0.64184672, valid_loss: 0.65250816, time: [4.06], best model: 0\n",
      "Epoch: 10, train_loss: 0.64279302, valid_loss: 0.65137978, time: [4.32], best model: 0\n",
      "Epoch: 11, train_loss: 0.64308046, valid_loss: 0.65459086, time: [4.36], best model: 0\n",
      "Epoch: 12, train_loss: 0.6394289, valid_loss: 0.65627263, time: [4.13], best model: 0\n",
      "Epoch: 13, train_loss: 0.63548838, valid_loss: 0.65135975, time: [4.1], best model: 0\n",
      "Epoch: 14, train_loss: 0.6310627, valid_loss: 0.65263767, time: [4.28], best model: 0\n",
      "Epoch: 15, train_loss: 0.63534438, valid_loss: 0.64701246, time: [4.57], best model: 1\n",
      "Epoch: 16, train_loss: 0.64150651, valid_loss: 0.65468566, time: [5.05], best model: 0\n",
      "Epoch: 17, train_loss: 0.64693673, valid_loss: 0.65414906, time: [4.68], best model: 0\n",
      "Epoch: 18, train_loss: 0.64345907, valid_loss: 0.65329056, time: [4.45], best model: 0\n",
      "Epoch: 19, train_loss: 0.64156761, valid_loss: 0.65705547, time: [4.36], best model: 0\n",
      "Epoch: 20, train_loss: 0.64064433, valid_loss: 0.65435861, time: [4.21], best model: 0\n",
      "Epoch: 21, train_loss: 0.63888747, valid_loss: 0.65376034, time: [4.29], best model: 0\n",
      "Epoch: 22, train_loss: 0.63834915, valid_loss: 0.65518328, time: [4.18], best model: 0\n",
      "Epoch: 23, train_loss: 0.63733934, valid_loss: 0.65456607, time: [4.13], best model: 0\n",
      "Early Stopped at Epoch: 24\n",
      "On sample 55 / 60 (hyperparams = {'cell_size': 188, 'hidden_size': 176, 'learning_rate': 0.09736599623823228, 'num_epochs': 109, 'patience': 9, 'batch_size': 512, 'early_stop_frac': 0.08449799596771912, 'seed': 5471})\n",
      "Model Structure:  GRUD(\n",
      "  (zl): Linear(in_features=384, out_features=176, bias=True)\n",
      "  (rl): Linear(in_features=384, out_features=176, bias=True)\n",
      "  (hl): Linear(in_features=384, out_features=176, bias=True)\n",
      "  (gamma_x_l): FilterLinear(in_features=104, out_features=104, bias=True)\n",
      "  (gamma_h_l): Linear(in_features=104, out_features=176, bias=True)\n",
      "  (fc): Linear(in_features=176, out_features=2, bias=True)\n",
      "  (bn): BatchNorm1d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (drop): Dropout(p=0.5, inplace=False)\n",
      ")\n",
      "Start Training ... \n",
      "Output type dermined by the model\n",
      "Epoch: 0, train_loss: 0.70378935, valid_loss: 0.68749868, time: [4.37], best model: 1\n",
      "Epoch: 1, train_loss: 0.65047935, valid_loss: 0.64629653, time: [4.12], best model: 1\n",
      "Epoch: 2, train_loss: 0.6523471, valid_loss: 0.65494445, time: [4.01], best model: 0\n",
      "Epoch: 3, train_loss: 0.64529439, valid_loss: 0.65124597, time: [4.15], best model: 0\n",
      "Epoch: 4, train_loss: 0.65301902, valid_loss: 0.65338825, time: [4.17], best model: 0\n",
      "Epoch: 5, train_loss: 0.65442848, valid_loss: 0.65513525, time: [4.11], best model: 0\n",
      "Epoch: 6, train_loss: 0.65001277, valid_loss: 0.65254251, time: [4.15], best model: 0\n",
      "Epoch: 7, train_loss: 0.64796494, valid_loss: 0.64788378, time: [4.12], best model: 0\n",
      "Epoch: 8, train_loss: 0.64661763, valid_loss: 0.64614059, time: [3.95], best model: 1\n",
      "Epoch: 9, train_loss: 0.64483649, valid_loss: 0.64585903, time: [4.29], best model: 1\n",
      "Epoch: 10, train_loss: 0.6425555, valid_loss: 0.64335744, time: [4.49], best model: 1\n",
      "Epoch: 11, train_loss: 0.64623925, valid_loss: 0.64773527, time: [3.91], best model: 0\n",
      "Epoch: 12, train_loss: 0.64595578, valid_loss: 0.64934744, time: [3.95], best model: 0\n",
      "Epoch: 13, train_loss: 0.64033758, valid_loss: 0.65027362, time: [4.15], best model: 0\n",
      "Epoch: 14, train_loss: 0.64399094, valid_loss: 0.64537108, time: [4.31], best model: 0\n",
      "Epoch: 15, train_loss: 0.64270184, valid_loss: 0.64624083, time: [3.99], best model: 0\n",
      "Epoch: 16, train_loss: 0.64276268, valid_loss: 0.64698995, time: [3.9], best model: 0\n",
      "Epoch: 17, train_loss: 0.64447357, valid_loss: 0.64493436, time: [4.02], best model: 0\n",
      "Epoch: 18, train_loss: 0.64398522, valid_loss: 0.64864882, time: [4.06], best model: 0\n",
      "Early Stopped at Epoch: 19\n",
      "On sample 56 / 60 (hyperparams = {'cell_size': 90, 'hidden_size': 66, 'learning_rate': 0.04680147165240897, 'num_epochs': 89, 'patience': 11, 'batch_size': 512, 'early_stop_frac': 0.07026490513477239, 'seed': 2678})\n",
      "Model Structure:  GRUD(\n",
      "  (zl): Linear(in_features=274, out_features=66, bias=True)\n",
      "  (rl): Linear(in_features=274, out_features=66, bias=True)\n",
      "  (hl): Linear(in_features=274, out_features=66, bias=True)\n",
      "  (gamma_x_l): FilterLinear(in_features=104, out_features=104, bias=True)\n",
      "  (gamma_h_l): Linear(in_features=104, out_features=66, bias=True)\n",
      "  (fc): Linear(in_features=66, out_features=2, bias=True)\n",
      "  (bn): BatchNorm1d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (drop): Dropout(p=0.5, inplace=False)\n",
      ")\n",
      "Start Training ... \n",
      "Output type dermined by the model\n",
      "Epoch: 0, train_loss: 0.71019071, valid_loss: 0.69235878, time: [4.22], best model: 1\n",
      "Epoch: 1, train_loss: 0.63927358, valid_loss: 0.64160862, time: [4.24], best model: 1\n",
      "Epoch: 2, train_loss: 0.63359337, valid_loss: 0.63997008, time: [4.38], best model: 1\n",
      "Epoch: 3, train_loss: 0.62817675, valid_loss: 0.63421625, time: [4.01], best model: 1\n",
      "Epoch: 4, train_loss: 0.6224774, valid_loss: 0.64049765, time: [4.13], best model: 0\n",
      "Epoch: 5, train_loss: 0.62685846, valid_loss: 0.64142812, time: [4.], best model: 0\n",
      "Epoch: 6, train_loss: 0.61861916, valid_loss: 0.64289462, time: [3.97], best model: 0\n",
      "Epoch: 7, train_loss: 0.62135455, valid_loss: 0.64061063, time: [3.89], best model: 0\n",
      "Epoch: 8, train_loss: 0.61531232, valid_loss: 0.64121914, time: [4.14], best model: 0\n",
      "Epoch: 9, train_loss: 0.61194363, valid_loss: 0.63797455, time: [4.03], best model: 0\n",
      "Epoch: 10, train_loss: 0.60750287, valid_loss: 0.64035994, time: [3.98], best model: 0\n",
      "Epoch: 11, train_loss: 0.60992215, valid_loss: 0.64429754, time: [3.98], best model: 0\n",
      "Epoch: 12, train_loss: 0.60709413, valid_loss: 0.64081154, time: [4.01], best model: 0\n",
      "Epoch: 13, train_loss: 0.60774892, valid_loss: 0.64254449, time: [4.03], best model: 0\n",
      "Early Stopped at Epoch: 14\n",
      "On sample 57 / 60 (hyperparams = {'cell_size': 84, 'hidden_size': 124, 'learning_rate': 0.022704983825331426, 'num_epochs': 94, 'patience': 8, 'batch_size': 64, 'early_stop_frac': 0.056290154018084106, 'seed': 3051})\n",
      "Model Structure:  GRUD(\n",
      "  (zl): Linear(in_features=332, out_features=124, bias=True)\n",
      "  (rl): Linear(in_features=332, out_features=124, bias=True)\n",
      "  (hl): Linear(in_features=332, out_features=124, bias=True)\n",
      "  (gamma_x_l): FilterLinear(in_features=104, out_features=104, bias=True)\n",
      "  (gamma_h_l): Linear(in_features=104, out_features=124, bias=True)\n",
      "  (fc): Linear(in_features=124, out_features=2, bias=True)\n",
      "  (bn): BatchNorm1d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (drop): Dropout(p=0.5, inplace=False)\n",
      ")\n",
      "Start Training ... \n",
      "Output type dermined by the model\n",
      "Epoch: 0, train_loss: 0.6745034, valid_loss: 0.66685294, time: [15.67], best model: 1\n",
      "Epoch: 1, train_loss: 0.65245711, valid_loss: 0.64668101, time: [15.5], best model: 1\n",
      "Epoch: 2, train_loss: 0.65016094, valid_loss: 0.64581194, time: [15.44], best model: 1\n",
      "Epoch: 3, train_loss: 0.64161917, valid_loss: 0.64120002, time: [15.41], best model: 1\n",
      "Epoch: 4, train_loss: 0.64422638, valid_loss: 0.64172481, time: [15.42], best model: 0\n",
      "Epoch: 5, train_loss: 0.6517342, valid_loss: 0.64600721, time: [15.5], best model: 0\n",
      "Epoch: 6, train_loss: 0.64317878, valid_loss: 0.64402147, time: [15.47], best model: 0\n",
      "Epoch: 7, train_loss: 0.64173945, valid_loss: 0.64567035, time: [15.53], best model: 0\n",
      "Epoch: 8, train_loss: 0.63990784, valid_loss: 0.64255459, time: [15.5], best model: 0\n",
      "Epoch: 9, train_loss: 0.6456751, valid_loss: 0.65539637, time: [15.4], best model: 0\n",
      "Epoch: 10, train_loss: 0.64043047, valid_loss: 0.6471056, time: [15.48], best model: 0\n",
      "Early Stopped at Epoch: 11\n",
      "On sample 58 / 60 (hyperparams = {'cell_size': 110, 'hidden_size': 128, 'learning_rate': 0.04453672919053865, 'num_epochs': 114, 'patience': 11, 'batch_size': 64, 'early_stop_frac': 0.059796039588625866, 'seed': 6894})\n",
      "Model Structure:  GRUD(\n",
      "  (zl): Linear(in_features=336, out_features=128, bias=True)\n",
      "  (rl): Linear(in_features=336, out_features=128, bias=True)\n",
      "  (hl): Linear(in_features=336, out_features=128, bias=True)\n",
      "  (gamma_x_l): FilterLinear(in_features=104, out_features=104, bias=True)\n",
      "  (gamma_h_l): Linear(in_features=104, out_features=128, bias=True)\n",
      "  (fc): Linear(in_features=128, out_features=2, bias=True)\n",
      "  (bn): BatchNorm1d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (drop): Dropout(p=0.5, inplace=False)\n",
      ")\n",
      "Start Training ... \n",
      "Output type dermined by the model\n",
      "Epoch: 0, train_loss: 0.67679199, valid_loss: 0.6687521, time: [15.78], best model: 1\n",
      "Epoch: 1, train_loss: 0.65918688, valid_loss: 0.65450119, time: [15.73], best model: 1\n",
      "Epoch: 2, train_loss: 0.66126357, valid_loss: 0.65216648, time: [15.75], best model: 1\n",
      "Epoch: 3, train_loss: 0.65644067, valid_loss: 0.64492599, time: [15.99], best model: 1\n",
      "Epoch: 4, train_loss: 0.65745023, valid_loss: 0.65049409, time: [15.77], best model: 0\n",
      "Epoch: 5, train_loss: 0.65218682, valid_loss: 0.64949023, time: [15.66], best model: 0\n",
      "Epoch: 6, train_loss: 0.65091532, valid_loss: 0.64556537, time: [16.26], best model: 0\n",
      "Epoch: 7, train_loss: 0.65276566, valid_loss: 0.65006603, time: [16.17], best model: 0\n",
      "Epoch: 8, train_loss: 0.65208875, valid_loss: 0.6420213, time: [15.56], best model: 1\n",
      "Epoch: 9, train_loss: 0.64988771, valid_loss: 0.64091721, time: [15.97], best model: 1\n",
      "Epoch: 10, train_loss: 0.64936934, valid_loss: 0.6395415, time: [15.65], best model: 1\n",
      "Epoch: 11, train_loss: 0.65004749, valid_loss: 0.64831506, time: [15.77], best model: 0\n",
      "Epoch: 12, train_loss: 0.64813158, valid_loss: 0.64336178, time: [15.75], best model: 0\n",
      "Epoch: 13, train_loss: 0.65005245, valid_loss: 0.64989502, time: [15.9], best model: 0\n",
      "Epoch: 14, train_loss: 0.64960294, valid_loss: 0.64996065, time: [15.66], best model: 0\n",
      "Epoch: 15, train_loss: 0.64621946, valid_loss: 0.64411225, time: [15.67], best model: 0\n",
      "Epoch: 16, train_loss: 0.6499751, valid_loss: 0.64710924, time: [15.79], best model: 0\n",
      "Epoch: 17, train_loss: 0.6453672, valid_loss: 0.64273226, time: [15.81], best model: 0\n",
      "Epoch: 18, train_loss: 0.64858599, valid_loss: 0.64032094, time: [15.67], best model: 0\n",
      "Epoch: 19, train_loss: 0.64470921, valid_loss: 0.64363749, time: [15.48], best model: 0\n",
      "Epoch: 20, train_loss: 0.64500719, valid_loss: 0.64161626, time: [15.67], best model: 0\n",
      "Early Stopped at Epoch: 21\n",
      "On sample 59 / 60 (hyperparams = {'cell_size': 187, 'hidden_size': 145, 'learning_rate': 0.046457426476375775, 'num_epochs': 119, 'patience': 9, 'batch_size': 512, 'early_stop_frac': 0.09967275023141152, 'seed': 4770})\n",
      "Model Structure:  GRUD(\n",
      "  (zl): Linear(in_features=353, out_features=145, bias=True)\n",
      "  (rl): Linear(in_features=353, out_features=145, bias=True)\n",
      "  (hl): Linear(in_features=353, out_features=145, bias=True)\n",
      "  (gamma_x_l): FilterLinear(in_features=104, out_features=104, bias=True)\n",
      "  (gamma_h_l): Linear(in_features=104, out_features=145, bias=True)\n",
      "  (fc): Linear(in_features=145, out_features=2, bias=True)\n",
      "  (bn): BatchNorm1d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (drop): Dropout(p=0.5, inplace=False)\n",
      ")\n",
      "Start Training ... \n",
      "Output type dermined by the model\n",
      "Epoch: 0, train_loss: 0.70841954, valid_loss: 0.70121686, time: [4.26], best model: 1\n",
      "Epoch: 1, train_loss: 0.64298301, valid_loss: 0.64703113, time: [4.45], best model: 1\n",
      "Epoch: 2, train_loss: 0.63418158, valid_loss: 0.64995351, time: [3.95], best model: 0\n",
      "Epoch: 3, train_loss: 0.63102459, valid_loss: 0.64793357, time: [4.04], best model: 0\n",
      "Epoch: 4, train_loss: 0.63798036, valid_loss: 0.65333518, time: [3.94], best model: 0\n",
      "Epoch: 5, train_loss: 0.64477855, valid_loss: 0.65823259, time: [4.06], best model: 0\n",
      "Epoch: 6, train_loss: 0.64132368, valid_loss: 0.65395158, time: [4.09], best model: 0\n",
      "Epoch: 7, train_loss: 0.63759916, valid_loss: 0.65340187, time: [3.95], best model: 0\n",
      "Epoch: 8, train_loss: 0.63645606, valid_loss: 0.65128162, time: [3.93], best model: 0\n",
      "Epoch: 9, train_loss: 0.62994293, valid_loss: 0.64774382, time: [4.08], best model: 0\n",
      "Early Stopped at Epoch: 10\n",
      "On sample 60 / 60 (hyperparams = {'cell_size': 120, 'hidden_size': 170, 'learning_rate': 0.05276174866719614, 'num_epochs': 73, 'patience': 9, 'batch_size': 64, 'early_stop_frac': 0.05696605904124455, 'seed': 3234})\n",
      "Model Structure:  GRUD(\n",
      "  (zl): Linear(in_features=378, out_features=170, bias=True)\n",
      "  (rl): Linear(in_features=378, out_features=170, bias=True)\n",
      "  (hl): Linear(in_features=378, out_features=170, bias=True)\n",
      "  (gamma_x_l): FilterLinear(in_features=104, out_features=104, bias=True)\n",
      "  (gamma_h_l): Linear(in_features=104, out_features=170, bias=True)\n",
      "  (fc): Linear(in_features=170, out_features=2, bias=True)\n",
      "  (bn): BatchNorm1d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (drop): Dropout(p=0.5, inplace=False)\n",
      ")\n",
      "Start Training ... \n",
      "Output type dermined by the model\n",
      "Epoch: 0, train_loss: 0.66895499, valid_loss: 0.67496856, time: [15.94], best model: 1\n",
      "Epoch: 1, train_loss: 0.66254909, valid_loss: 0.66511393, time: [15.55], best model: 1\n",
      "Epoch: 2, train_loss: 0.66197242, valid_loss: 0.66858803, time: [15.74], best model: 0\n",
      "Epoch: 3, train_loss: 0.65368789, valid_loss: 0.66337933, time: [15.61], best model: 1\n",
      "Epoch: 4, train_loss: 0.6570246, valid_loss: 0.66587017, time: [15.64], best model: 0\n",
      "Epoch: 5, train_loss: 0.65350267, valid_loss: 0.66334397, time: [15.51], best model: 1\n",
      "Epoch: 6, train_loss: 0.65471184, valid_loss: 0.6588626, time: [15.51], best model: 1\n",
      "Epoch: 7, train_loss: 0.65101369, valid_loss: 0.66116823, time: [15.4], best model: 0\n",
      "Epoch: 8, train_loss: 0.65049471, valid_loss: 0.65461446, time: [15.51], best model: 1\n",
      "Epoch: 9, train_loss: 0.64896473, valid_loss: 0.65757944, time: [15.41], best model: 0\n",
      "Epoch: 10, train_loss: 0.64783248, valid_loss: 0.65340027, time: [15.74], best model: 1\n",
      "Epoch: 11, train_loss: 0.65221709, valid_loss: 0.65884449, time: [15.62], best model: 0\n",
      "Epoch: 12, train_loss: 0.64573471, valid_loss: 0.65425693, time: [15.44], best model: 0\n",
      "Epoch: 13, train_loss: 0.65053186, valid_loss: 0.65791507, time: [15.48], best model: 0\n",
      "Epoch: 14, train_loss: 0.6472132, valid_loss: 0.65892078, time: [15.42], best model: 0\n",
      "Epoch: 15, train_loss: 0.64986674, valid_loss: 0.65904192, time: [15.7], best model: 0\n",
      "Epoch: 16, train_loss: 0.6492286, valid_loss: 0.65898269, time: [15.44], best model: 0\n",
      "Epoch: 17, train_loss: 0.64886351, valid_loss: 0.65987651, time: [15.56], best model: 0\n",
      "Epoch: 18, train_loss: 0.64584723, valid_loss: 0.65672557, time: [15.55], best model: 0\n",
      "Epoch: 19, train_loss: 0.6462452, valid_loss: 0.64954631, time: [15.72], best model: 1\n",
      "Epoch: 20, train_loss: 0.6424496, valid_loss: 0.65453891, time: [15.58], best model: 0\n",
      "Epoch: 21, train_loss: 0.64188069, valid_loss: 0.65411327, time: [15.53], best model: 0\n",
      "Epoch: 22, train_loss: 0.64149277, valid_loss: 0.65535141, time: [15.56], best model: 0\n",
      "Epoch: 23, train_loss: 0.64498963, valid_loss: 0.65289015, time: [15.61], best model: 0\n",
      "Epoch: 24, train_loss: 0.64183472, valid_loss: 0.64512082, time: [15.58], best model: 1\n",
      "Epoch: 25, train_loss: 0.64448969, valid_loss: 0.64950388, time: [15.58], best model: 0\n",
      "Epoch: 26, train_loss: 0.64252881, valid_loss: 0.65695569, time: [15.56], best model: 0\n",
      "Epoch: 27, train_loss: 0.64450538, valid_loss: 0.65145074, time: [15.62], best model: 0\n",
      "Epoch: 28, train_loss: 0.63884158, valid_loss: 0.65040167, time: [15.62], best model: 0\n",
      "Epoch: 29, train_loss: 0.64397567, valid_loss: 0.65409435, time: [15.64], best model: 0\n",
      "Epoch: 30, train_loss: 0.64487054, valid_loss: 0.66176016, time: [15.62], best model: 0\n",
      "Epoch: 31, train_loss: 0.64246176, valid_loss: 0.65529943, time: [15.59], best model: 0\n",
      "Epoch: 32, train_loss: 0.64528284, valid_loss: 0.65301762, time: [15.67], best model: 0\n",
      "Early Stopped at Epoch: 33\n",
      "Model Structure:  GRUD(\n",
      "  (zl): Linear(in_features=299, out_features=91, bias=True)\n",
      "  (rl): Linear(in_features=299, out_features=91, bias=True)\n",
      "  (hl): Linear(in_features=299, out_features=91, bias=True)\n",
      "  (gamma_x_l): FilterLinear(in_features=104, out_features=104, bias=True)\n",
      "  (gamma_h_l): Linear(in_features=104, out_features=91, bias=True)\n",
      "  (fc): Linear(in_features=91, out_features=2, bias=True)\n",
      "  (bn): BatchNorm1d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (drop): Dropout(p=0.5, inplace=False)\n",
      ")\n",
      "Start Training ... \n",
      "Output type dermined by the model\n",
      "Epoch: 0, train_loss: 0.68352309, valid_loss: 0.67779023, time: [9.56], best model: 1\n",
      "Epoch: 1, train_loss: 0.62822581, valid_loss: 0.63285566, time: [9.47], best model: 1\n",
      "Epoch: 2, train_loss: 0.62470183, valid_loss: 0.6327957, time: [9.46], best model: 1\n",
      "Epoch: 3, train_loss: 0.62007819, valid_loss: 0.63186964, time: [9.45], best model: 1\n",
      "Epoch: 4, train_loss: 0.61738011, valid_loss: 0.63072301, time: [9.4], best model: 1\n",
      "Epoch: 5, train_loss: 0.61284336, valid_loss: 0.63399916, time: [9.38], best model: 0\n",
      "Epoch: 6, train_loss: 0.60556116, valid_loss: 0.63826046, time: [9.5], best model: 0\n",
      "Epoch: 7, train_loss: 0.59974317, valid_loss: 0.6386934, time: [9.42], best model: 0\n",
      "Epoch: 8, train_loss: 0.5982871, valid_loss: 0.63792926, time: [9.49], best model: 0\n",
      "Epoch: 9, train_loss: 0.59136126, valid_loss: 0.6500604, time: [9.36], best model: 0\n",
      "Epoch: 10, train_loss: 0.58336093, valid_loss: 0.64799055, time: [9.58], best model: 0\n",
      "Epoch: 11, train_loss: 0.57630351, valid_loss: 0.65411531, time: [9.58], best model: 0\n",
      "Epoch: 12, train_loss: 0.57041464, valid_loss: 0.67882339, time: [9.67], best model: 0\n",
      "Epoch: 13, train_loss: 0.56627575, valid_loss: 0.67816322, time: [9.49], best model: 0\n",
      "Epoch: 14, train_loss: 0.56562788, valid_loss: 0.67755992, time: [9.38], best model: 0\n",
      "Early Stopped at Epoch: 15\n",
      "Final results for model GRU-D on target los_3 with representation data\n",
      "0.7047917839565588 0.6605992872768005 0.6737753378378378 0.5850120870265915\n",
      "Running model GRU-D on target los_7 with representation data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-32-7d35c2d9607d>:22: RuntimeWarning: Mean of empty slice\n",
      "  X_mean = np.nanmean(tensor, axis=0, keepdims=True).transpose([0, 2, 1])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On sample 1 / 60 (hyperparams = {'cell_size': 65, 'hidden_size': 151, 'learning_rate': 0.0933915477165132, 'num_epochs': 145, 'patience': 10, 'batch_size': 64, 'early_stop_frac': 0.13332124901226045, 'seed': 4241})\n",
      "Model Structure:  GRUD(\n",
      "  (zl): Linear(in_features=359, out_features=151, bias=True)\n",
      "  (rl): Linear(in_features=359, out_features=151, bias=True)\n",
      "  (hl): Linear(in_features=359, out_features=151, bias=True)\n",
      "  (gamma_x_l): FilterLinear(in_features=104, out_features=104, bias=True)\n",
      "  (gamma_h_l): Linear(in_features=104, out_features=151, bias=True)\n",
      "  (fc): Linear(in_features=151, out_features=2, bias=True)\n",
      "  (bn): BatchNorm1d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (drop): Dropout(p=0.5, inplace=False)\n",
      ")\n",
      "Start Training ... \n",
      "Output type dermined by the model\n",
      "Epoch: 0, train_loss: 0.41508362, valid_loss: 0.39038025, time: [14.61], best model: 1\n",
      "Epoch: 1, train_loss: 0.39376257, valid_loss: 0.39115956, time: [14.65], best model: 0\n",
      "Epoch: 2, train_loss: 0.39644393, valid_loss: 0.38877761, time: [14.5], best model: 1\n",
      "Epoch: 3, train_loss: 0.38517187, valid_loss: 0.38163423, time: [14.53], best model: 1\n",
      "Epoch: 4, train_loss: 0.39669125, valid_loss: 0.38491953, time: [14.55], best model: 0\n",
      "Epoch: 5, train_loss: 0.38677259, valid_loss: 0.38067205, time: [14.71], best model: 1\n",
      "Epoch: 6, train_loss: 0.39139861, valid_loss: 0.38544272, time: [14.58], best model: 0\n",
      "Epoch: 7, train_loss: 0.38014258, valid_loss: 0.38253636, time: [14.56], best model: 0\n",
      "Epoch: 8, train_loss: 0.38362885, valid_loss: 0.3788918, time: [14.42], best model: 1\n",
      "Epoch: 9, train_loss: 0.39727827, valid_loss: 0.38070139, time: [14.63], best model: 0\n",
      "Epoch: 10, train_loss: 0.38989835, valid_loss: 0.38200078, time: [14.59], best model: 0\n",
      "Epoch: 11, train_loss: 0.39171195, valid_loss: 0.37810223, time: [14.27], best model: 1\n",
      "Epoch: 12, train_loss: 0.38385276, valid_loss: 0.37766465, time: [14.27], best model: 1\n",
      "Epoch: 13, train_loss: 0.38072576, valid_loss: 0.38436522, time: [14.29], best model: 0\n",
      "Epoch: 14, train_loss: 0.38574894, valid_loss: 0.38161911, time: [14.39], best model: 0\n",
      "Epoch: 15, train_loss: 0.38657166, valid_loss: 0.3803874, time: [14.31], best model: 0\n",
      "Epoch: 16, train_loss: 0.38694807, valid_loss: 0.37819236, time: [14.49], best model: 0\n",
      "Epoch: 17, train_loss: 0.38672179, valid_loss: 0.37657149, time: [14.27], best model: 1\n",
      "Epoch: 18, train_loss: 0.38456328, valid_loss: 0.37435474, time: [14.31], best model: 1\n",
      "Epoch: 19, train_loss: 0.38368225, valid_loss: 0.37440578, time: [14.35], best model: 0\n",
      "Epoch: 20, train_loss: 0.38525178, valid_loss: 0.3806099, time: [14.45], best model: 0\n",
      "Epoch: 21, train_loss: 0.38342707, valid_loss: 0.37819655, time: [14.37], best model: 0\n",
      "Epoch: 22, train_loss: 0.38386255, valid_loss: 0.38422441, time: [14.44], best model: 0\n",
      "Epoch: 23, train_loss: 0.37931814, valid_loss: 0.38410646, time: [14.29], best model: 0\n",
      "Epoch: 24, train_loss: 0.3895318, valid_loss: 0.39096184, time: [14.15], best model: 0\n",
      "Epoch: 25, train_loss: 0.38203214, valid_loss: 0.37995009, time: [14.14], best model: 0\n",
      "Epoch: 26, train_loss: 0.38563953, valid_loss: 0.38153029, time: [14.22], best model: 0\n",
      "Epoch: 27, train_loss: 0.38274576, valid_loss: 0.37655819, time: [14.4], best model: 0\n",
      "Early Stopped at Epoch: 28\n",
      "New Best Score: 67.11 @ hyperparams = {'cell_size': 65, 'hidden_size': 151, 'learning_rate': 0.0933915477165132, 'num_epochs': 145, 'patience': 10, 'batch_size': 64, 'early_stop_frac': 0.13332124901226045, 'seed': 4241}\n",
      "On sample 2 / 60 (hyperparams = {'cell_size': 122, 'hidden_size': 84, 'learning_rate': 0.04397354613068208, 'num_epochs': 61, 'patience': 8, 'batch_size': 512, 'early_stop_frac': 0.08237505822561465, 'seed': 2709})\n",
      "Model Structure:  GRUD(\n",
      "  (zl): Linear(in_features=292, out_features=84, bias=True)\n",
      "  (rl): Linear(in_features=292, out_features=84, bias=True)\n",
      "  (hl): Linear(in_features=292, out_features=84, bias=True)\n",
      "  (gamma_x_l): FilterLinear(in_features=104, out_features=104, bias=True)\n",
      "  (gamma_h_l): Linear(in_features=104, out_features=84, bias=True)\n",
      "  (fc): Linear(in_features=84, out_features=2, bias=True)\n",
      "  (bn): BatchNorm1d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (drop): Dropout(p=0.5, inplace=False)\n",
      ")\n",
      "Start Training ... \n",
      "Output type dermined by the model\n",
      "Epoch: 0, train_loss: 0.51010005, valid_loss: 0.50466337, time: [3.88], best model: 1\n",
      "Epoch: 1, train_loss: 0.39244204, valid_loss: 0.40862013, time: [3.99], best model: 1\n",
      "Epoch: 2, train_loss: 0.38417966, valid_loss: 0.4054745, time: [3.93], best model: 1\n",
      "Epoch: 3, train_loss: 0.37576507, valid_loss: 0.39992428, time: [3.89], best model: 1\n",
      "Epoch: 4, train_loss: 0.36861083, valid_loss: 0.38850918, time: [3.84], best model: 1\n",
      "Epoch: 5, train_loss: 0.3660031, valid_loss: 0.38129743, time: [3.97], best model: 1\n",
      "Epoch: 6, train_loss: 0.36065489, valid_loss: 0.39129674, time: [3.83], best model: 0\n",
      "Epoch: 7, train_loss: 0.35915991, valid_loss: 0.39648809, time: [3.87], best model: 0\n",
      "Epoch: 8, train_loss: 0.35333754, valid_loss: 0.39525452, time: [3.9], best model: 0\n",
      "Epoch: 9, train_loss: 0.35223885, valid_loss: 0.40088402, time: [3.88], best model: 0\n",
      "Epoch: 10, train_loss: 0.35031888, valid_loss: 0.39322548, time: [3.89], best model: 0\n",
      "Epoch: 11, train_loss: 0.34727936, valid_loss: 0.39500847, time: [3.93], best model: 0\n",
      "Epoch: 12, train_loss: 0.34822919, valid_loss: 0.40641403, time: [3.87], best model: 0\n",
      "Early Stopped at Epoch: 13\n",
      "New Best Score: 70.44 @ hyperparams = {'cell_size': 122, 'hidden_size': 84, 'learning_rate': 0.04397354613068208, 'num_epochs': 61, 'patience': 8, 'batch_size': 512, 'early_stop_frac': 0.08237505822561465, 'seed': 2709}\n",
      "On sample 3 / 60 (hyperparams = {'cell_size': 72, 'hidden_size': 121, 'learning_rate': 0.05601915156671309, 'num_epochs': 111, 'patience': 11, 'batch_size': 512, 'early_stop_frac': 0.14888620933197066, 'seed': 7882})\n",
      "Model Structure:  GRUD(\n",
      "  (zl): Linear(in_features=329, out_features=121, bias=True)\n",
      "  (rl): Linear(in_features=329, out_features=121, bias=True)\n",
      "  (hl): Linear(in_features=329, out_features=121, bias=True)\n",
      "  (gamma_x_l): FilterLinear(in_features=104, out_features=104, bias=True)\n",
      "  (gamma_h_l): Linear(in_features=104, out_features=121, bias=True)\n",
      "  (fc): Linear(in_features=121, out_features=2, bias=True)\n",
      "  (bn): BatchNorm1d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (drop): Dropout(p=0.5, inplace=False)\n",
      ")\n",
      "Start Training ... \n",
      "Output type dermined by the model\n",
      "Epoch: 0, train_loss: 0.49939791, valid_loss: 0.46803075, time: [3.56], best model: 1\n",
      "Epoch: 1, train_loss: 0.38358989, valid_loss: 0.38574657, time: [3.55], best model: 1\n",
      "Epoch: 2, train_loss: 0.36440376, valid_loss: 0.38441866, time: [3.64], best model: 1\n",
      "Epoch: 3, train_loss: 0.3682109, valid_loss: 0.38419713, time: [3.55], best model: 1\n",
      "Epoch: 4, train_loss: 0.36666019, valid_loss: 0.38095951, time: [3.6], best model: 1\n",
      "Epoch: 5, train_loss: 0.36962343, valid_loss: 0.39667762, time: [3.5], best model: 0\n",
      "Epoch: 6, train_loss: 0.36131831, valid_loss: 0.40071099, time: [3.58], best model: 0\n",
      "Epoch: 7, train_loss: 0.36537336, valid_loss: 0.3902353, time: [3.55], best model: 0\n",
      "Epoch: 8, train_loss: 0.36073639, valid_loss: 0.38431182, time: [3.62], best model: 0\n",
      "Epoch: 9, train_loss: 0.35781613, valid_loss: 0.38848118, time: [3.64], best model: 0\n",
      "Epoch: 10, train_loss: 0.35757683, valid_loss: 0.3898036, time: [3.61], best model: 0\n",
      "Epoch: 11, train_loss: 0.35549302, valid_loss: 0.38857891, time: [3.57], best model: 0\n",
      "Epoch: 12, train_loss: 0.35252278, valid_loss: 0.39112338, time: [3.65], best model: 0\n",
      "Epoch: 13, train_loss: 0.34569959, valid_loss: 0.39977957, time: [3.61], best model: 0\n",
      "Epoch: 14, train_loss: 0.34964674, valid_loss: 0.38857605, time: [3.56], best model: 0\n",
      "Early Stopped at Epoch: 15\n",
      "On sample 4 / 60 (hyperparams = {'cell_size': 93, 'hidden_size': 194, 'learning_rate': 0.06284421578050496, 'num_epochs': 105, 'patience': 11, 'batch_size': 256, 'early_stop_frac': 0.14949502599677933, 'seed': 3185})\n",
      "Model Structure:  GRUD(\n",
      "  (zl): Linear(in_features=402, out_features=194, bias=True)\n",
      "  (rl): Linear(in_features=402, out_features=194, bias=True)\n",
      "  (hl): Linear(in_features=402, out_features=194, bias=True)\n",
      "  (gamma_x_l): FilterLinear(in_features=104, out_features=104, bias=True)\n",
      "  (gamma_h_l): Linear(in_features=104, out_features=194, bias=True)\n",
      "  (fc): Linear(in_features=194, out_features=2, bias=True)\n",
      "  (bn): BatchNorm1d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (drop): Dropout(p=0.5, inplace=False)\n",
      ")\n",
      "Start Training ... \n",
      "Output type dermined by the model\n",
      "Epoch: 0, train_loss: 0.44791829, valid_loss: 0.43558124, time: [5.42], best model: 1\n",
      "Epoch: 1, train_loss: 0.39328114, valid_loss: 0.39298488, time: [5.47], best model: 1\n",
      "Epoch: 2, train_loss: 0.38549201, valid_loss: 0.40034887, time: [5.42], best model: 0\n",
      "Epoch: 3, train_loss: 0.3843956, valid_loss: 0.39726497, time: [5.43], best model: 0\n",
      "Epoch: 4, train_loss: 0.386392, valid_loss: 0.39005893, time: [5.5], best model: 1\n",
      "Epoch: 5, train_loss: 0.37886477, valid_loss: 0.39082791, time: [5.45], best model: 0\n",
      "Epoch: 6, train_loss: 0.36850877, valid_loss: 0.37822501, time: [5.4], best model: 1\n",
      "Epoch: 7, train_loss: 0.37327721, valid_loss: 0.38509046, time: [5.52], best model: 0\n",
      "Epoch: 8, train_loss: 0.37334342, valid_loss: 0.38462996, time: [5.62], best model: 0\n",
      "Epoch: 9, train_loss: 0.37448633, valid_loss: 0.3806134, time: [5.82], best model: 0\n",
      "Epoch: 10, train_loss: 0.37001228, valid_loss: 0.39334145, time: [5.65], best model: 0\n",
      "Epoch: 11, train_loss: 0.37264744, valid_loss: 0.38573442, time: [5.63], best model: 0\n",
      "Epoch: 12, train_loss: 0.36809692, valid_loss: 0.39282362, time: [5.48], best model: 0\n",
      "Epoch: 13, train_loss: 0.36824372, valid_loss: 0.38742797, time: [5.58], best model: 0\n",
      "Epoch: 14, train_loss: 0.36754678, valid_loss: 0.39546107, time: [6.01], best model: 0\n",
      "Epoch: 15, train_loss: 0.36001199, valid_loss: 0.38970812, time: [5.72], best model: 0\n",
      "Epoch: 16, train_loss: 0.36128322, valid_loss: 0.39201567, time: [5.44], best model: 0\n",
      "Early Stopped at Epoch: 17\n",
      "On sample 5 / 60 (hyperparams = {'cell_size': 125, 'hidden_size': 133, 'learning_rate': 0.0846249828434158, 'num_epochs': 88, 'patience': 9, 'batch_size': 128, 'early_stop_frac': 0.1326150819439797, 'seed': 6044})\n",
      "Model Structure:  GRUD(\n",
      "  (zl): Linear(in_features=341, out_features=133, bias=True)\n",
      "  (rl): Linear(in_features=341, out_features=133, bias=True)\n",
      "  (hl): Linear(in_features=341, out_features=133, bias=True)\n",
      "  (gamma_x_l): FilterLinear(in_features=104, out_features=104, bias=True)\n",
      "  (gamma_h_l): Linear(in_features=104, out_features=133, bias=True)\n",
      "  (fc): Linear(in_features=133, out_features=2, bias=True)\n",
      "  (bn): BatchNorm1d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (drop): Dropout(p=0.5, inplace=False)\n",
      ")\n",
      "Start Training ... \n",
      "Output type dermined by the model\n",
      "Epoch: 0, train_loss: 0.41901594, valid_loss: 0.41844211, time: [8.22], best model: 1\n",
      "Epoch: 1, train_loss: 0.39155633, valid_loss: 0.39286784, time: [8.17], best model: 1\n",
      "Epoch: 2, train_loss: 0.3900557, valid_loss: 0.39227197, time: [8.18], best model: 1\n",
      "Epoch: 3, train_loss: 0.38717324, valid_loss: 0.38931761, time: [8.26], best model: 1\n",
      "Epoch: 4, train_loss: 0.38226031, valid_loss: 0.38734639, time: [8.32], best model: 1\n",
      "Epoch: 5, train_loss: 0.3859282, valid_loss: 0.38409532, time: [8.25], best model: 1\n",
      "Epoch: 6, train_loss: 0.38341961, valid_loss: 0.38594345, time: [8.24], best model: 0\n",
      "Epoch: 7, train_loss: 0.37722039, valid_loss: 0.39230252, time: [8.18], best model: 0\n",
      "Epoch: 8, train_loss: 0.38337086, valid_loss: 0.38958862, time: [8.15], best model: 0\n",
      "Epoch: 9, train_loss: 0.38270019, valid_loss: 0.38738099, time: [8.21], best model: 0\n",
      "Epoch: 10, train_loss: 0.38238093, valid_loss: 0.38982347, time: [8.19], best model: 0\n",
      "Epoch: 11, train_loss: 0.38109724, valid_loss: 0.37915265, time: [8.15], best model: 1\n",
      "Epoch: 12, train_loss: 0.37455425, valid_loss: 0.38915023, time: [8.21], best model: 0\n",
      "Epoch: 13, train_loss: 0.38412415, valid_loss: 0.38984768, time: [8.26], best model: 0\n",
      "Epoch: 14, train_loss: 0.38059859, valid_loss: 0.38316484, time: [8.19], best model: 0\n",
      "Epoch: 15, train_loss: 0.3715845, valid_loss: 0.38037504, time: [8.14], best model: 0\n",
      "Epoch: 16, train_loss: 0.36896059, valid_loss: 0.36931556, time: [8.13], best model: 1\n",
      "Epoch: 17, train_loss: 0.37467268, valid_loss: 0.38103711, time: [8.09], best model: 0\n",
      "Epoch: 18, train_loss: 0.37191249, valid_loss: 0.38767729, time: [8.18], best model: 0\n",
      "Epoch: 19, train_loss: 0.36921429, valid_loss: 0.38245264, time: [8.17], best model: 0\n",
      "Epoch: 20, train_loss: 0.3753995, valid_loss: 0.37776322, time: [8.09], best model: 0\n",
      "Epoch: 21, train_loss: 0.37055041, valid_loss: 0.38048456, time: [8.12], best model: 0\n",
      "Epoch: 22, train_loss: 0.37608402, valid_loss: 0.38561411, time: [8.12], best model: 0\n",
      "Epoch: 23, train_loss: 0.37446631, valid_loss: 0.38439796, time: [8.11], best model: 0\n",
      "Epoch: 24, train_loss: 0.3660595, valid_loss: 0.37882091, time: [8.18], best model: 0\n",
      "Early Stopped at Epoch: 25\n",
      "New Best Score: 70.91 @ hyperparams = {'cell_size': 125, 'hidden_size': 133, 'learning_rate': 0.0846249828434158, 'num_epochs': 88, 'patience': 9, 'batch_size': 128, 'early_stop_frac': 0.1326150819439797, 'seed': 6044}\n",
      "On sample 6 / 60 (hyperparams = {'cell_size': 154, 'hidden_size': 146, 'learning_rate': 0.06435631845621308, 'num_epochs': 83, 'patience': 10, 'batch_size': 64, 'early_stop_frac': 0.11941525454251833, 'seed': 7121})\n",
      "Model Structure:  GRUD(\n",
      "  (zl): Linear(in_features=354, out_features=146, bias=True)\n",
      "  (rl): Linear(in_features=354, out_features=146, bias=True)\n",
      "  (hl): Linear(in_features=354, out_features=146, bias=True)\n",
      "  (gamma_x_l): FilterLinear(in_features=104, out_features=104, bias=True)\n",
      "  (gamma_h_l): Linear(in_features=104, out_features=146, bias=True)\n",
      "  (fc): Linear(in_features=146, out_features=2, bias=True)\n",
      "  (bn): BatchNorm1d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (drop): Dropout(p=0.5, inplace=False)\n",
      ")\n",
      "Start Training ... \n",
      "Output type dermined by the model\n",
      "Epoch: 0, train_loss: 0.39888979, valid_loss: 0.3940774, time: [14.48], best model: 1\n",
      "Epoch: 1, train_loss: 0.38861525, valid_loss: 0.39175325, time: [14.5], best model: 1\n",
      "Epoch: 2, train_loss: 0.38189638, valid_loss: 0.38537561, time: [14.56], best model: 1\n",
      "Epoch: 3, train_loss: 0.39396044, valid_loss: 0.3833246, time: [14.63], best model: 1\n",
      "Epoch: 4, train_loss: 0.38259576, valid_loss: 0.3851046, time: [14.54], best model: 0\n",
      "Epoch: 5, train_loss: 0.38536652, valid_loss: 0.37937556, time: [14.63], best model: 1\n",
      "Epoch: 6, train_loss: 0.39045536, valid_loss: 0.38363979, time: [14.46], best model: 0\n",
      "Epoch: 7, train_loss: 0.3905627, valid_loss: 0.38334629, time: [14.37], best model: 0\n",
      "Epoch: 8, train_loss: 0.38645746, valid_loss: 0.38892315, time: [14.49], best model: 0\n",
      "Epoch: 9, train_loss: 0.38728064, valid_loss: 0.38488239, time: [14.5], best model: 0\n",
      "Epoch: 10, train_loss: 0.37979839, valid_loss: 0.37870663, time: [14.66], best model: 1\n",
      "Epoch: 11, train_loss: 0.38453137, valid_loss: 0.38100503, time: [14.6], best model: 0\n",
      "Epoch: 12, train_loss: 0.38310079, valid_loss: 0.38025582, time: [14.49], best model: 0\n",
      "Epoch: 13, train_loss: 0.38339582, valid_loss: 0.38217219, time: [14.56], best model: 0\n",
      "Epoch: 14, train_loss: 0.38670926, valid_loss: 0.38417259, time: [14.83], best model: 0\n",
      "Epoch: 15, train_loss: 0.37943835, valid_loss: 0.37736153, time: [14.76], best model: 1\n",
      "Epoch: 16, train_loss: 0.38616413, valid_loss: 0.38316166, time: [14.43], best model: 0\n",
      "Epoch: 17, train_loss: 0.3829209, valid_loss: 0.38439504, time: [14.53], best model: 0\n",
      "Epoch: 18, train_loss: 0.38556028, valid_loss: 0.38487157, time: [14.56], best model: 0\n",
      "Epoch: 19, train_loss: 0.38466684, valid_loss: 0.38006582, time: [14.53], best model: 0\n",
      "Epoch: 20, train_loss: 0.37875933, valid_loss: 0.38263112, time: [14.56], best model: 0\n",
      "Epoch: 21, train_loss: 0.38254932, valid_loss: 0.38578531, time: [14.63], best model: 0\n",
      "Epoch: 22, train_loss: 0.37871273, valid_loss: 0.38020474, time: [14.92], best model: 0\n",
      "Epoch: 23, train_loss: 0.37988653, valid_loss: 0.37694851, time: [14.71], best model: 1\n",
      "Epoch: 24, train_loss: 0.38050146, valid_loss: 0.38287227, time: [14.6], best model: 0\n",
      "Epoch: 25, train_loss: 0.37614885, valid_loss: 0.37644182, time: [14.55], best model: 1\n",
      "Epoch: 26, train_loss: 0.38025984, valid_loss: 0.37628426, time: [14.57], best model: 1\n",
      "Epoch: 27, train_loss: 0.38064718, valid_loss: 0.38259198, time: [14.51], best model: 0\n",
      "Epoch: 28, train_loss: 0.38113194, valid_loss: 0.38296383, time: [14.67], best model: 0\n",
      "Epoch: 29, train_loss: 0.37829417, valid_loss: 0.38396796, time: [14.4], best model: 0\n",
      "Epoch: 30, train_loss: 0.38046281, valid_loss: 0.385044, time: [14.58], best model: 0\n",
      "Epoch: 31, train_loss: 0.38147016, valid_loss: 0.38286604, time: [14.43], best model: 0\n",
      "Epoch: 32, train_loss: 0.3811334, valid_loss: 0.37744439, time: [14.41], best model: 0\n",
      "Epoch: 33, train_loss: 0.37936823, valid_loss: 0.37839266, time: [14.65], best model: 0\n",
      "Epoch: 34, train_loss: 0.37649377, valid_loss: 0.37949089, time: [14.4], best model: 0\n",
      "Epoch: 35, train_loss: 0.38543403, valid_loss: 0.37990444, time: [14.46], best model: 0\n",
      "Early Stopped at Epoch: 36\n",
      "On sample 7 / 60 (hyperparams = {'cell_size': 57, 'hidden_size': 126, 'learning_rate': 0.019671216158442605, 'num_epochs': 96, 'patience': 8, 'batch_size': 256, 'early_stop_frac': 0.12336697980969767, 'seed': 6892})\n",
      "Model Structure:  GRUD(\n",
      "  (zl): Linear(in_features=334, out_features=126, bias=True)\n",
      "  (rl): Linear(in_features=334, out_features=126, bias=True)\n",
      "  (hl): Linear(in_features=334, out_features=126, bias=True)\n",
      "  (gamma_x_l): FilterLinear(in_features=104, out_features=104, bias=True)\n",
      "  (gamma_h_l): Linear(in_features=104, out_features=126, bias=True)\n",
      "  (fc): Linear(in_features=126, out_features=2, bias=True)\n",
      "  (bn): BatchNorm1d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (drop): Dropout(p=0.5, inplace=False)\n",
      ")\n",
      "Start Training ... \n",
      "Output type dermined by the model\n",
      "Epoch: 0, train_loss: 0.52771127, valid_loss: 0.52487397, time: [5.11], best model: 1\n",
      "Epoch: 1, train_loss: 0.39336496, valid_loss: 0.38916002, time: [5.08], best model: 1\n",
      "Epoch: 2, train_loss: 0.38863871, valid_loss: 0.39538096, time: [5.05], best model: 0\n",
      "Epoch: 3, train_loss: 0.38494575, valid_loss: 0.380287, time: [5.15], best model: 1\n",
      "Epoch: 4, train_loss: 0.37679107, valid_loss: 0.37364903, time: [5.09], best model: 1\n",
      "Epoch: 5, train_loss: 0.36674162, valid_loss: 0.37410104, time: [5.06], best model: 0\n",
      "Epoch: 6, train_loss: 0.36929629, valid_loss: 0.37758386, time: [5.06], best model: 0\n",
      "Epoch: 7, train_loss: 0.36286444, valid_loss: 0.37432791, time: [5.16], best model: 0\n",
      "Epoch: 8, train_loss: 0.36352472, valid_loss: 0.37808656, time: [5.1], best model: 0\n",
      "Epoch: 9, train_loss: 0.35879684, valid_loss: 0.3849753, time: [5.16], best model: 0\n",
      "Epoch: 10, train_loss: 0.37727634, valid_loss: 0.38112322, time: [5.1], best model: 0\n",
      "Epoch: 11, train_loss: 0.37879288, valid_loss: 0.37666823, time: [5.07], best model: 0\n",
      "Epoch: 12, train_loss: 0.37118795, valid_loss: 0.37123098, time: [5.11], best model: 1\n",
      "Epoch: 13, train_loss: 0.37435194, valid_loss: 0.37906376, time: [5.1], best model: 0\n",
      "Epoch: 14, train_loss: 0.36094448, valid_loss: 0.3784097, time: [5.11], best model: 0\n",
      "Epoch: 15, train_loss: 0.36377455, valid_loss: 0.37542313, time: [5.11], best model: 0\n",
      "Epoch: 16, train_loss: 0.35666315, valid_loss: 0.38049992, time: [5.21], best model: 0\n",
      "Epoch: 17, train_loss: 0.34591437, valid_loss: 0.38003664, time: [5.11], best model: 0\n",
      "Epoch: 18, train_loss: 0.35132207, valid_loss: 0.38331477, time: [5.07], best model: 0\n",
      "Epoch: 19, train_loss: 0.35186557, valid_loss: 0.38328676, time: [5.12], best model: 0\n",
      "Early Stopped at Epoch: 20\n",
      "New Best Score: 70.94 @ hyperparams = {'cell_size': 57, 'hidden_size': 126, 'learning_rate': 0.019671216158442605, 'num_epochs': 96, 'patience': 8, 'batch_size': 256, 'early_stop_frac': 0.12336697980969767, 'seed': 6892}\n",
      "On sample 8 / 60 (hyperparams = {'cell_size': 145, 'hidden_size': 190, 'learning_rate': 0.061125735265354586, 'num_epochs': 141, 'patience': 8, 'batch_size': 128, 'early_stop_frac': 0.13752688098046628, 'seed': 971})\n",
      "Model Structure:  GRUD(\n",
      "  (zl): Linear(in_features=398, out_features=190, bias=True)\n",
      "  (rl): Linear(in_features=398, out_features=190, bias=True)\n",
      "  (hl): Linear(in_features=398, out_features=190, bias=True)\n",
      "  (gamma_x_l): FilterLinear(in_features=104, out_features=104, bias=True)\n",
      "  (gamma_h_l): Linear(in_features=104, out_features=190, bias=True)\n",
      "  (fc): Linear(in_features=190, out_features=2, bias=True)\n",
      "  (bn): BatchNorm1d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (drop): Dropout(p=0.5, inplace=False)\n",
      ")\n",
      "Start Training ... \n",
      "Output type dermined by the model\n",
      "Epoch: 0, train_loss: 0.4236345, valid_loss: 0.43990721, time: [8.35], best model: 1\n",
      "Epoch: 1, train_loss: 0.39210449, valid_loss: 0.41262048, time: [8.21], best model: 1\n",
      "Epoch: 2, train_loss: 0.3893952, valid_loss: 0.40626448, time: [8.21], best model: 1\n",
      "Epoch: 3, train_loss: 0.38014361, valid_loss: 0.39445325, time: [8.28], best model: 1\n",
      "Epoch: 4, train_loss: 0.39125477, valid_loss: 0.40739536, time: [8.27], best model: 0\n",
      "Epoch: 5, train_loss: 0.38533572, valid_loss: 0.41163298, time: [8.18], best model: 0\n",
      "Epoch: 6, train_loss: 0.38997739, valid_loss: 0.40941851, time: [8.16], best model: 0\n",
      "Epoch: 7, train_loss: 0.39097766, valid_loss: 0.408241, time: [8.15], best model: 0\n",
      "Epoch: 8, train_loss: 0.38187848, valid_loss: 0.40710589, time: [8.22], best model: 0\n",
      "Epoch: 9, train_loss: 0.37541778, valid_loss: 0.40753709, time: [8.21], best model: 0\n",
      "Epoch: 10, train_loss: 0.37899389, valid_loss: 0.40511373, time: [8.21], best model: 0\n",
      "Early Stopped at Epoch: 11\n",
      "On sample 9 / 60 (hyperparams = {'cell_size': 125, 'hidden_size': 162, 'learning_rate': 0.05092661669948592, 'num_epochs': 142, 'patience': 10, 'batch_size': 256, 'early_stop_frac': 0.14515101483457324, 'seed': 589})\n",
      "Model Structure:  GRUD(\n",
      "  (zl): Linear(in_features=370, out_features=162, bias=True)\n",
      "  (rl): Linear(in_features=370, out_features=162, bias=True)\n",
      "  (hl): Linear(in_features=370, out_features=162, bias=True)\n",
      "  (gamma_x_l): FilterLinear(in_features=104, out_features=104, bias=True)\n",
      "  (gamma_h_l): Linear(in_features=104, out_features=162, bias=True)\n",
      "  (fc): Linear(in_features=162, out_features=2, bias=True)\n",
      "  (bn): BatchNorm1d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (drop): Dropout(p=0.5, inplace=False)\n",
      ")\n",
      "Start Training ... \n",
      "Output type dermined by the model\n",
      "Epoch: 0, train_loss: 0.45821096, valid_loss: 0.44457071, time: [5.54], best model: 1\n",
      "Epoch: 1, train_loss: 0.39256838, valid_loss: 0.39434121, time: [5.57], best model: 1\n",
      "Epoch: 2, train_loss: 0.3873281, valid_loss: 0.39201123, time: [5.45], best model: 1\n",
      "Epoch: 3, train_loss: 0.38358401, valid_loss: 0.39189425, time: [5.49], best model: 1\n",
      "Epoch: 4, train_loss: 0.37800893, valid_loss: 0.37991409, time: [5.57], best model: 1\n",
      "Epoch: 5, train_loss: 0.37785225, valid_loss: 0.38503196, time: [5.54], best model: 0\n",
      "Epoch: 6, train_loss: 0.37561209, valid_loss: 0.38468864, time: [5.55], best model: 0\n",
      "Epoch: 7, train_loss: 0.3737399, valid_loss: 0.38474974, time: [5.59], best model: 0\n",
      "Epoch: 8, train_loss: 0.36300996, valid_loss: 0.37843885, time: [5.49], best model: 1\n",
      "Epoch: 9, train_loss: 0.36732507, valid_loss: 0.37484436, time: [5.39], best model: 1\n",
      "Epoch: 10, train_loss: 0.36532763, valid_loss: 0.38926038, time: [5.47], best model: 0\n",
      "Epoch: 11, train_loss: 0.3684837, valid_loss: 0.3893253, time: [5.54], best model: 0\n",
      "Epoch: 12, train_loss: 0.3576973, valid_loss: 0.38656367, time: [5.55], best model: 0\n",
      "Epoch: 13, train_loss: 0.35941249, valid_loss: 0.38973715, time: [5.49], best model: 0\n",
      "Epoch: 14, train_loss: 0.36912557, valid_loss: 0.38615307, time: [5.46], best model: 0\n",
      "Epoch: 15, train_loss: 0.3642153, valid_loss: 0.39428357, time: [5.41], best model: 0\n",
      "Epoch: 16, train_loss: 0.35534169, valid_loss: 0.38373722, time: [5.84], best model: 0\n",
      "Epoch: 17, train_loss: 0.35414196, valid_loss: 0.39249018, time: [6.08], best model: 0\n",
      "Epoch: 18, train_loss: 0.35236785, valid_loss: 0.38411661, time: [5.51], best model: 0\n",
      "Early Stopped at Epoch: 19\n",
      "On sample 10 / 60 (hyperparams = {'cell_size': 97, 'hidden_size': 152, 'learning_rate': 0.056790778009037673, 'num_epochs': 98, 'patience': 11, 'batch_size': 256, 'early_stop_frac': 0.1352262926597551, 'seed': 2159})\n",
      "Model Structure:  GRUD(\n",
      "  (zl): Linear(in_features=360, out_features=152, bias=True)\n",
      "  (rl): Linear(in_features=360, out_features=152, bias=True)\n",
      "  (hl): Linear(in_features=360, out_features=152, bias=True)\n",
      "  (gamma_x_l): FilterLinear(in_features=104, out_features=104, bias=True)\n",
      "  (gamma_h_l): Linear(in_features=104, out_features=152, bias=True)\n",
      "  (fc): Linear(in_features=152, out_features=2, bias=True)\n",
      "  (bn): BatchNorm1d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (drop): Dropout(p=0.5, inplace=False)\n",
      ")\n",
      "Start Training ... \n",
      "Output type dermined by the model\n",
      "Epoch: 0, train_loss: 0.46039503, valid_loss: 0.44007965, time: [5.62], best model: 1\n",
      "Epoch: 1, train_loss: 0.39356896, valid_loss: 0.38934905, time: [5.65], best model: 1\n",
      "Epoch: 2, train_loss: 0.38488173, valid_loss: 0.389284, time: [5.58], best model: 1\n",
      "Epoch: 3, train_loss: 0.38191339, valid_loss: 0.38674607, time: [5.54], best model: 1\n",
      "Epoch: 4, train_loss: 0.37908176, valid_loss: 0.38274309, time: [5.52], best model: 1\n",
      "Epoch: 5, train_loss: 0.38094796, valid_loss: 0.38682294, time: [5.54], best model: 0\n",
      "Epoch: 6, train_loss: 0.37641498, valid_loss: 0.37398403, time: [5.58], best model: 1\n",
      "Epoch: 7, train_loss: 0.37342616, valid_loss: 0.38126462, time: [5.61], best model: 0\n",
      "Epoch: 8, train_loss: 0.38054167, valid_loss: 0.37845734, time: [5.67], best model: 0\n",
      "Epoch: 9, train_loss: 0.37349112, valid_loss: 0.38200658, time: [5.69], best model: 0\n",
      "Epoch: 10, train_loss: 0.37960151, valid_loss: 0.37851007, time: [5.57], best model: 0\n",
      "Epoch: 11, train_loss: 0.37227273, valid_loss: 0.38463184, time: [5.65], best model: 0\n",
      "Epoch: 12, train_loss: 0.36953752, valid_loss: 0.37285505, time: [5.83], best model: 1\n",
      "Epoch: 13, train_loss: 0.36908109, valid_loss: 0.38770127, time: [6.], best model: 0\n",
      "Epoch: 14, train_loss: 0.3726009, valid_loss: 0.37816739, time: [6.09], best model: 0\n",
      "Epoch: 15, train_loss: 0.3736714, valid_loss: 0.38257796, time: [6.38], best model: 0\n",
      "Epoch: 16, train_loss: 0.37438062, valid_loss: 0.38903727, time: [6.3], best model: 0\n",
      "Epoch: 17, train_loss: 0.37000339, valid_loss: 0.38620887, time: [5.89], best model: 0\n",
      "Epoch: 18, train_loss: 0.36900626, valid_loss: 0.3827829, time: [5.81], best model: 0\n",
      "Epoch: 19, train_loss: 0.36821243, valid_loss: 0.3798151, time: [5.61], best model: 0\n",
      "Epoch: 20, train_loss: 0.36167083, valid_loss: 0.38495656, time: [5.68], best model: 0\n",
      "Epoch: 21, train_loss: 0.36981865, valid_loss: 0.38160597, time: [5.66], best model: 0\n",
      "Epoch: 22, train_loss: 0.37034198, valid_loss: 0.3774253, time: [5.83], best model: 0\n",
      "Early Stopped at Epoch: 23\n",
      "New Best Score: 71.08 @ hyperparams = {'cell_size': 97, 'hidden_size': 152, 'learning_rate': 0.056790778009037673, 'num_epochs': 98, 'patience': 11, 'batch_size': 256, 'early_stop_frac': 0.1352262926597551, 'seed': 2159}\n",
      "On sample 11 / 60 (hyperparams = {'cell_size': 113, 'hidden_size': 108, 'learning_rate': 0.07195206197905482, 'num_epochs': 134, 'patience': 11, 'batch_size': 256, 'early_stop_frac': 0.11409386397788643, 'seed': 8469})\n",
      "Model Structure:  GRUD(\n",
      "  (zl): Linear(in_features=316, out_features=108, bias=True)\n",
      "  (rl): Linear(in_features=316, out_features=108, bias=True)\n",
      "  (hl): Linear(in_features=316, out_features=108, bias=True)\n",
      "  (gamma_x_l): FilterLinear(in_features=104, out_features=104, bias=True)\n",
      "  (gamma_h_l): Linear(in_features=104, out_features=108, bias=True)\n",
      "  (fc): Linear(in_features=108, out_features=2, bias=True)\n",
      "  (bn): BatchNorm1d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (drop): Dropout(p=0.5, inplace=False)\n",
      ")\n",
      "Start Training ... \n",
      "Output type dermined by the model\n",
      "Epoch: 0, train_loss: 0.4408569, valid_loss: 0.42877681, time: [5.39], best model: 1\n",
      "Epoch: 1, train_loss: 0.38559207, valid_loss: 0.39960388, time: [5.07], best model: 1\n",
      "Epoch: 2, train_loss: 0.3853131, valid_loss: 0.39488385, time: [5.15], best model: 1\n",
      "Epoch: 3, train_loss: 0.38753056, valid_loss: 0.39448475, time: [5.09], best model: 1\n",
      "Epoch: 4, train_loss: 0.38160538, valid_loss: 0.38961029, time: [4.99], best model: 1\n",
      "Epoch: 5, train_loss: 0.37653068, valid_loss: 0.379903, time: [5.03], best model: 1\n",
      "Epoch: 6, train_loss: 0.38070869, valid_loss: 0.38875955, time: [5.01], best model: 0\n",
      "Epoch: 7, train_loss: 0.37449054, valid_loss: 0.38191762, time: [4.96], best model: 0\n",
      "Epoch: 8, train_loss: 0.37271457, valid_loss: 0.37965758, time: [4.98], best model: 1\n",
      "Epoch: 9, train_loss: 0.37083925, valid_loss: 0.3886164, time: [4.97], best model: 0\n",
      "Epoch: 10, train_loss: 0.36953097, valid_loss: 0.38127222, time: [4.96], best model: 0\n",
      "Epoch: 11, train_loss: 0.3678504, valid_loss: 0.38618009, time: [5.04], best model: 0\n",
      "Epoch: 12, train_loss: 0.36842715, valid_loss: 0.38386835, time: [4.98], best model: 0\n",
      "Epoch: 13, train_loss: 0.37206485, valid_loss: 0.38858216, time: [4.96], best model: 0\n",
      "Epoch: 14, train_loss: 0.37924714, valid_loss: 0.38731697, time: [5.01], best model: 0\n",
      "Epoch: 15, train_loss: 0.37207781, valid_loss: 0.38943146, time: [4.94], best model: 0\n",
      "Epoch: 16, train_loss: 0.3679535, valid_loss: 0.3857049, time: [5.06], best model: 0\n",
      "Epoch: 17, train_loss: 0.37156391, valid_loss: 0.38657057, time: [4.94], best model: 0\n",
      "Epoch: 18, train_loss: 0.36027823, valid_loss: 0.39068978, time: [4.96], best model: 0\n",
      "Early Stopped at Epoch: 19\n",
      "On sample 12 / 60 (hyperparams = {'cell_size': 81, 'hidden_size': 117, 'learning_rate': 0.026581116390413072, 'num_epochs': 86, 'patience': 10, 'batch_size': 512, 'early_stop_frac': 0.05734983847144366, 'seed': 6248})\n",
      "Model Structure:  GRUD(\n",
      "  (zl): Linear(in_features=325, out_features=117, bias=True)\n",
      "  (rl): Linear(in_features=325, out_features=117, bias=True)\n",
      "  (hl): Linear(in_features=325, out_features=117, bias=True)\n",
      "  (gamma_x_l): FilterLinear(in_features=104, out_features=104, bias=True)\n",
      "  (gamma_h_l): Linear(in_features=104, out_features=117, bias=True)\n",
      "  (fc): Linear(in_features=117, out_features=2, bias=True)\n",
      "  (bn): BatchNorm1d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (drop): Dropout(p=0.5, inplace=False)\n",
      ")\n",
      "Start Training ... \n",
      "Output type dermined by the model\n",
      "Epoch: 0, train_loss: 0.58032576, valid_loss: 0.55704161, time: [4.5], best model: 1\n",
      "Epoch: 1, train_loss: 0.39575475, valid_loss: 0.38043423, time: [4.65], best model: 1\n",
      "Epoch: 2, train_loss: 0.37314959, valid_loss: 0.37068542, time: [4.3], best model: 1\n",
      "Epoch: 3, train_loss: 0.36926349, valid_loss: 0.37120584, time: [4.12], best model: 0\n",
      "Epoch: 4, train_loss: 0.36943792, valid_loss: 0.36154559, time: [4.12], best model: 1\n",
      "Epoch: 5, train_loss: 0.35678202, valid_loss: 0.36778383, time: [4.03], best model: 0\n",
      "Epoch: 6, train_loss: 0.36184756, valid_loss: 0.36886476, time: [4.01], best model: 0\n",
      "Epoch: 7, train_loss: 0.35871032, valid_loss: 0.36299419, time: [4.06], best model: 0\n",
      "Epoch: 8, train_loss: 0.35803219, valid_loss: 0.36798642, time: [4.03], best model: 0\n",
      "Epoch: 9, train_loss: 0.36020931, valid_loss: 0.37083925, time: [4.05], best model: 0\n",
      "Epoch: 10, train_loss: 0.35581719, valid_loss: 0.36656837, time: [4.14], best model: 0\n",
      "Epoch: 11, train_loss: 0.35905031, valid_loss: 0.37264566, time: [4.02], best model: 0\n",
      "Epoch: 12, train_loss: 0.34626576, valid_loss: 0.37529008, time: [4.], best model: 0\n",
      "Epoch: 13, train_loss: 0.3420488, valid_loss: 0.37961861, time: [4.05], best model: 0\n",
      "Early Stopped at Epoch: 14\n",
      "On sample 13 / 60 (hyperparams = {'cell_size': 198, 'hidden_size': 81, 'learning_rate': 0.020662714558648022, 'num_epochs': 122, 'patience': 8, 'batch_size': 128, 'early_stop_frac': 0.11233847142958386, 'seed': 3991})\n",
      "Model Structure:  GRUD(\n",
      "  (zl): Linear(in_features=289, out_features=81, bias=True)\n",
      "  (rl): Linear(in_features=289, out_features=81, bias=True)\n",
      "  (hl): Linear(in_features=289, out_features=81, bias=True)\n",
      "  (gamma_x_l): FilterLinear(in_features=104, out_features=104, bias=True)\n",
      "  (gamma_h_l): Linear(in_features=104, out_features=81, bias=True)\n",
      "  (fc): Linear(in_features=81, out_features=2, bias=True)\n",
      "  (bn): BatchNorm1d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (drop): Dropout(p=0.5, inplace=False)\n",
      ")\n",
      "Start Training ... \n",
      "Output type dermined by the model\n",
      "Epoch: 0, train_loss: 0.45558689, valid_loss: 0.44180544, time: [8.28], best model: 1\n",
      "Epoch: 1, train_loss: 0.37394386, valid_loss: 0.36338171, time: [8.26], best model: 1\n",
      "Epoch: 2, train_loss: 0.36996611, valid_loss: 0.36562979, time: [8.27], best model: 0\n",
      "Epoch: 3, train_loss: 0.36680639, valid_loss: 0.35660934, time: [8.27], best model: 1\n",
      "Epoch: 4, train_loss: 0.37034975, valid_loss: 0.35821139, time: [8.26], best model: 0\n",
      "Epoch: 5, train_loss: 0.36390048, valid_loss: 0.36320068, time: [8.25], best model: 0\n",
      "Epoch: 6, train_loss: 0.36066516, valid_loss: 0.35495426, time: [8.28], best model: 1\n",
      "Epoch: 7, train_loss: 0.36486915, valid_loss: 0.3622276, time: [8.24], best model: 0\n",
      "Epoch: 8, train_loss: 0.36347475, valid_loss: 0.36460761, time: [8.3], best model: 0\n",
      "Epoch: 9, train_loss: 0.36963469, valid_loss: 0.35810073, time: [8.29], best model: 0\n",
      "Epoch: 10, train_loss: 0.36122914, valid_loss: 0.35620558, time: [8.32], best model: 0\n",
      "Epoch: 11, train_loss: 0.3606421, valid_loss: 0.36707835, time: [8.25], best model: 0\n",
      "Epoch: 12, train_loss: 0.35313587, valid_loss: 0.37369942, time: [8.28], best model: 0\n",
      "Epoch: 13, train_loss: 0.35772314, valid_loss: 0.36636047, time: [8.22], best model: 0\n",
      "Early Stopped at Epoch: 14\n",
      "New Best Score: 72.77 @ hyperparams = {'cell_size': 198, 'hidden_size': 81, 'learning_rate': 0.020662714558648022, 'num_epochs': 122, 'patience': 8, 'batch_size': 128, 'early_stop_frac': 0.11233847142958386, 'seed': 3991}\n",
      "On sample 14 / 60 (hyperparams = {'cell_size': 174, 'hidden_size': 120, 'learning_rate': 0.013058314779616107, 'num_epochs': 93, 'patience': 10, 'batch_size': 256, 'early_stop_frac': 0.08532138917855187, 'seed': 2438})\n",
      "Model Structure:  GRUD(\n",
      "  (zl): Linear(in_features=328, out_features=120, bias=True)\n",
      "  (rl): Linear(in_features=328, out_features=120, bias=True)\n",
      "  (hl): Linear(in_features=328, out_features=120, bias=True)\n",
      "  (gamma_x_l): FilterLinear(in_features=104, out_features=104, bias=True)\n",
      "  (gamma_h_l): Linear(in_features=104, out_features=120, bias=True)\n",
      "  (fc): Linear(in_features=120, out_features=2, bias=True)\n",
      "  (bn): BatchNorm1d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (drop): Dropout(p=0.5, inplace=False)\n",
      ")\n",
      "Start Training ... \n",
      "Output type dermined by the model\n",
      "Epoch: 0, train_loss: 0.57589263, valid_loss: 0.56096184, time: [5.39], best model: 1\n",
      "Epoch: 1, train_loss: 0.40323455, valid_loss: 0.39307504, time: [5.34], best model: 1\n",
      "Epoch: 2, train_loss: 0.375283, valid_loss: 0.35725933, time: [5.25], best model: 1\n",
      "Epoch: 3, train_loss: 0.37103634, valid_loss: 0.36144838, time: [5.25], best model: 0\n",
      "Epoch: 4, train_loss: 0.36829732, valid_loss: 0.35581825, time: [5.29], best model: 1\n",
      "Epoch: 5, train_loss: 0.35986412, valid_loss: 0.35156783, time: [5.44], best model: 1\n",
      "Epoch: 6, train_loss: 0.35426337, valid_loss: 0.35532085, time: [5.48], best model: 0\n",
      "Epoch: 7, train_loss: 0.35669986, valid_loss: 0.36381586, time: [5.32], best model: 0\n",
      "Epoch: 8, train_loss: 0.34906507, valid_loss: 0.36482478, time: [5.25], best model: 0\n",
      "Epoch: 9, train_loss: 0.34844702, valid_loss: 0.35809594, time: [5.24], best model: 0\n",
      "Epoch: 10, train_loss: 0.34436672, valid_loss: 0.36841735, time: [5.27], best model: 0\n",
      "Epoch: 11, train_loss: 0.3416674, valid_loss: 0.3732069, time: [5.34], best model: 0\n",
      "Epoch: 12, train_loss: 0.33171851, valid_loss: 0.36487169, time: [5.37], best model: 0\n",
      "Epoch: 13, train_loss: 0.33094681, valid_loss: 0.36884402, time: [5.27], best model: 0\n",
      "Epoch: 14, train_loss: 0.32191173, valid_loss: 0.39280306, time: [5.24], best model: 0\n",
      "Early Stopped at Epoch: 15\n",
      "On sample 15 / 60 (hyperparams = {'cell_size': 166, 'hidden_size': 188, 'learning_rate': 0.029405925253605372, 'num_epochs': 62, 'patience': 10, 'batch_size': 64, 'early_stop_frac': 0.06647786232242964, 'seed': 9245})\n",
      "Model Structure:  GRUD(\n",
      "  (zl): Linear(in_features=396, out_features=188, bias=True)\n",
      "  (rl): Linear(in_features=396, out_features=188, bias=True)\n",
      "  (hl): Linear(in_features=396, out_features=188, bias=True)\n",
      "  (gamma_x_l): FilterLinear(in_features=104, out_features=104, bias=True)\n",
      "  (gamma_h_l): Linear(in_features=104, out_features=188, bias=True)\n",
      "  (fc): Linear(in_features=188, out_features=2, bias=True)\n",
      "  (bn): BatchNorm1d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (drop): Dropout(p=0.5, inplace=False)\n",
      ")\n",
      "Start Training ... \n",
      "Output type dermined by the model\n",
      "Epoch: 0, train_loss: 0.40934816, valid_loss: 0.40409182, time: [15.66], best model: 1\n",
      "Epoch: 1, train_loss: 0.38051408, valid_loss: 0.37436298, time: [15.46], best model: 1\n",
      "Epoch: 2, train_loss: 0.37846115, valid_loss: 0.37288022, time: [15.44], best model: 1\n",
      "Epoch: 3, train_loss: 0.38642946, valid_loss: 0.36947263, time: [15.57], best model: 1\n",
      "Epoch: 4, train_loss: 0.3839571, valid_loss: 0.37621167, time: [15.46], best model: 0\n",
      "Epoch: 5, train_loss: 0.37522085, valid_loss: 0.37168581, time: [15.55], best model: 0\n",
      "Epoch: 6, train_loss: 0.37376538, valid_loss: 0.37407272, time: [15.41], best model: 0\n",
      "Epoch: 7, train_loss: 0.37265315, valid_loss: 0.37691351, time: [15.35], best model: 0\n",
      "Epoch: 8, train_loss: 0.36474628, valid_loss: 0.37134715, time: [15.55], best model: 0\n",
      "Epoch: 9, train_loss: 0.373535, valid_loss: 0.37376523, time: [15.41], best model: 0\n",
      "Epoch: 10, train_loss: 0.37978876, valid_loss: 0.37300085, time: [15.48], best model: 0\n",
      "Epoch: 11, train_loss: 0.37273685, valid_loss: 0.37032068, time: [15.3], best model: 0\n",
      "Epoch: 12, train_loss: 0.3762289, valid_loss: 0.37130972, time: [15.38], best model: 0\n",
      "Epoch: 13, train_loss: 0.37474582, valid_loss: 0.36791648, time: [15.47], best model: 1\n",
      "Epoch: 14, train_loss: 0.3732423, valid_loss: 0.37683412, time: [15.43], best model: 0\n",
      "Epoch: 15, train_loss: 0.37712604, valid_loss: 0.36852915, time: [15.4], best model: 0\n",
      "Epoch: 16, train_loss: 0.37262122, valid_loss: 0.36594191, time: [15.43], best model: 1\n",
      "Epoch: 17, train_loss: 0.37707685, valid_loss: 0.37297812, time: [15.45], best model: 0\n",
      "Epoch: 18, train_loss: 0.37444277, valid_loss: 0.37181982, time: [15.69], best model: 0\n",
      "Epoch: 19, train_loss: 0.37399039, valid_loss: 0.37215711, time: [15.78], best model: 0\n",
      "Epoch: 20, train_loss: 0.37295379, valid_loss: 0.36858837, time: [15.76], best model: 0\n",
      "Epoch: 21, train_loss: 0.37428834, valid_loss: 0.37130969, time: [15.71], best model: 0\n",
      "Epoch: 22, train_loss: 0.37028822, valid_loss: 0.36375459, time: [15.65], best model: 1\n",
      "Epoch: 23, train_loss: 0.36983937, valid_loss: 0.36421066, time: [15.67], best model: 0\n",
      "Epoch: 24, train_loss: 0.36848706, valid_loss: 0.36676272, time: [15.64], best model: 0\n",
      "Epoch: 25, train_loss: 0.37856202, valid_loss: 0.36361303, time: [15.66], best model: 1\n",
      "Epoch: 26, train_loss: 0.36885881, valid_loss: 0.37541524, time: [15.73], best model: 0\n",
      "Epoch: 27, train_loss: 0.37312883, valid_loss: 0.37286787, time: [15.63], best model: 0\n",
      "Epoch: 28, train_loss: 0.36721314, valid_loss: 0.37020546, time: [15.71], best model: 0\n",
      "Epoch: 29, train_loss: 0.36824645, valid_loss: 0.38156831, time: [15.64], best model: 0\n",
      "Epoch: 30, train_loss: 0.36410485, valid_loss: 0.3777135, time: [15.68], best model: 0\n",
      "Epoch: 31, train_loss: 0.36441015, valid_loss: 0.37812643, time: [15.76], best model: 0\n",
      "Epoch: 32, train_loss: 0.37152972, valid_loss: 0.36951872, time: [15.65], best model: 0\n",
      "Epoch: 33, train_loss: 0.36499055, valid_loss: 0.36924365, time: [15.98], best model: 0\n",
      "Epoch: 34, train_loss: 0.37073642, valid_loss: 0.37445578, time: [15.85], best model: 0\n",
      "Early Stopped at Epoch: 35\n",
      "On sample 16 / 60 (hyperparams = {'cell_size': 87, 'hidden_size': 108, 'learning_rate': 0.0030250039399590907, 'num_epochs': 119, 'patience': 11, 'batch_size': 128, 'early_stop_frac': 0.13931661865670436, 'seed': 6518})\n",
      "Model Structure:  GRUD(\n",
      "  (zl): Linear(in_features=316, out_features=108, bias=True)\n",
      "  (rl): Linear(in_features=316, out_features=108, bias=True)\n",
      "  (hl): Linear(in_features=316, out_features=108, bias=True)\n",
      "  (gamma_x_l): FilterLinear(in_features=104, out_features=104, bias=True)\n",
      "  (gamma_h_l): Linear(in_features=104, out_features=108, bias=True)\n",
      "  (fc): Linear(in_features=108, out_features=2, bias=True)\n",
      "  (bn): BatchNorm1d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (drop): Dropout(p=0.5, inplace=False)\n",
      ")\n",
      "Start Training ... \n",
      "Output type dermined by the model\n",
      "Epoch: 0, train_loss: 0.70057174, valid_loss: 0.70828206, time: [7.89], best model: 1\n",
      "Epoch: 1, train_loss: 0.5100131, valid_loss: 0.51096875, time: [7.88], best model: 1\n",
      "Epoch: 2, train_loss: 0.42877088, valid_loss: 0.44167771, time: [7.92], best model: 1\n",
      "Epoch: 3, train_loss: 0.39100541, valid_loss: 0.39789254, time: [7.9], best model: 1\n",
      "Epoch: 4, train_loss: 0.37453083, valid_loss: 0.37871044, time: [7.88], best model: 1\n",
      "Epoch: 5, train_loss: 0.36455103, valid_loss: 0.37840343, time: [7.9], best model: 1\n",
      "Epoch: 6, train_loss: 0.36009659, valid_loss: 0.37274786, time: [7.98], best model: 1\n",
      "Epoch: 7, train_loss: 0.36013719, valid_loss: 0.36988051, time: [7.94], best model: 1\n",
      "Epoch: 8, train_loss: 0.35461109, valid_loss: 0.37224174, time: [7.89], best model: 0\n",
      "Epoch: 9, train_loss: 0.35066063, valid_loss: 0.3787818, time: [7.99], best model: 0\n",
      "Epoch: 10, train_loss: 0.34354172, valid_loss: 0.38111622, time: [8.02], best model: 0\n",
      "Epoch: 11, train_loss: 0.33662135, valid_loss: 0.38082055, time: [7.98], best model: 0\n",
      "Epoch: 12, train_loss: 0.33002486, valid_loss: 0.38295804, time: [7.96], best model: 0\n",
      "Epoch: 13, train_loss: 0.31675274, valid_loss: 0.40116555, time: [7.93], best model: 0\n",
      "Epoch: 14, train_loss: 0.30463726, valid_loss: 0.40462627, time: [7.86], best model: 0\n",
      "Epoch: 15, train_loss: 0.2965716, valid_loss: 0.41967137, time: [7.93], best model: 0\n",
      "Epoch: 16, train_loss: 0.28146962, valid_loss: 0.43238238, time: [7.83], best model: 0\n",
      "Epoch: 17, train_loss: 0.27140149, valid_loss: 0.45205556, time: [7.91], best model: 0\n",
      "Early Stopped at Epoch: 18\n",
      "On sample 17 / 60 (hyperparams = {'cell_size': 152, 'hidden_size': 135, 'learning_rate': 0.06493597228295822, 'num_epochs': 117, 'patience': 10, 'batch_size': 512, 'early_stop_frac': 0.13248904812066795, 'seed': 1450})\n",
      "Model Structure:  GRUD(\n",
      "  (zl): Linear(in_features=343, out_features=135, bias=True)\n",
      "  (rl): Linear(in_features=343, out_features=135, bias=True)\n",
      "  (hl): Linear(in_features=343, out_features=135, bias=True)\n",
      "  (gamma_x_l): FilterLinear(in_features=104, out_features=104, bias=True)\n",
      "  (gamma_h_l): Linear(in_features=104, out_features=135, bias=True)\n",
      "  (fc): Linear(in_features=135, out_features=2, bias=True)\n",
      "  (bn): BatchNorm1d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (drop): Dropout(p=0.5, inplace=False)\n",
      ")\n",
      "Start Training ... \n",
      "Output type dermined by the model\n",
      "Epoch: 0, train_loss: 0.47829625, valid_loss: 0.46792459, time: [3.83], best model: 1\n",
      "Epoch: 1, train_loss: 0.38777896, valid_loss: 0.40939658, time: [3.84], best model: 1\n",
      "Epoch: 2, train_loss: 0.3782787, valid_loss: 0.39447308, time: [3.8], best model: 1\n",
      "Epoch: 3, train_loss: 0.37276142, valid_loss: 0.38359942, time: [3.87], best model: 1\n",
      "Epoch: 4, train_loss: 0.37041293, valid_loss: 0.3912675, time: [3.78], best model: 0\n",
      "Epoch: 5, train_loss: 0.36201354, valid_loss: 0.37965039, time: [3.76], best model: 1\n",
      "Epoch: 6, train_loss: 0.36267904, valid_loss: 0.38534396, time: [3.86], best model: 0\n",
      "Epoch: 7, train_loss: 0.35819759, valid_loss: 0.38590002, time: [3.76], best model: 0\n",
      "Epoch: 8, train_loss: 0.3565387, valid_loss: 0.38543759, time: [3.72], best model: 0\n",
      "Epoch: 9, train_loss: 0.35996124, valid_loss: 0.39687916, time: [3.75], best model: 0\n",
      "Epoch: 10, train_loss: 0.34841507, valid_loss: 0.39545356, time: [3.85], best model: 0\n",
      "Epoch: 11, train_loss: 0.353269, valid_loss: 0.4046655, time: [3.75], best model: 0\n",
      "Epoch: 12, train_loss: 0.35678836, valid_loss: 0.3933269, time: [3.79], best model: 0\n",
      "Epoch: 13, train_loss: 0.35467359, valid_loss: 0.39531868, time: [3.77], best model: 0\n",
      "Epoch: 14, train_loss: 0.35187377, valid_loss: 0.40102761, time: [3.77], best model: 0\n",
      "Early Stopped at Epoch: 15\n",
      "On sample 18 / 60 (hyperparams = {'cell_size': 54, 'hidden_size': 124, 'learning_rate': 0.03151723052197425, 'num_epochs': 98, 'patience': 10, 'batch_size': 128, 'early_stop_frac': 0.10266384238528334, 'seed': 1271})\n",
      "Model Structure:  GRUD(\n",
      "  (zl): Linear(in_features=332, out_features=124, bias=True)\n",
      "  (rl): Linear(in_features=332, out_features=124, bias=True)\n",
      "  (hl): Linear(in_features=332, out_features=124, bias=True)\n",
      "  (gamma_x_l): FilterLinear(in_features=104, out_features=104, bias=True)\n",
      "  (gamma_h_l): Linear(in_features=104, out_features=124, bias=True)\n",
      "  (fc): Linear(in_features=124, out_features=2, bias=True)\n",
      "  (bn): BatchNorm1d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (drop): Dropout(p=0.5, inplace=False)\n",
      ")\n",
      "Start Training ... \n",
      "Output type dermined by the model\n",
      "Epoch: 0, train_loss: 0.43486669, valid_loss: 0.44401629, time: [8.45], best model: 1\n",
      "Epoch: 1, train_loss: 0.37025853, valid_loss: 0.39203572, time: [8.53], best model: 1\n",
      "Epoch: 2, train_loss: 0.37197263, valid_loss: 0.39319086, time: [8.45], best model: 0\n",
      "Epoch: 3, train_loss: 0.37452, valid_loss: 0.38835764, time: [8.39], best model: 1\n",
      "Epoch: 4, train_loss: 0.37308753, valid_loss: 0.39437328, time: [8.34], best model: 0\n",
      "Epoch: 5, train_loss: 0.37230373, valid_loss: 0.39426742, time: [8.38], best model: 0\n",
      "Epoch: 6, train_loss: 0.36569853, valid_loss: 0.40232885, time: [8.42], best model: 0\n",
      "Epoch: 7, train_loss: 0.36473452, valid_loss: 0.38672824, time: [8.46], best model: 1\n",
      "Epoch: 8, train_loss: 0.36329452, valid_loss: 0.38728486, time: [8.51], best model: 0\n",
      "Epoch: 9, train_loss: 0.37163296, valid_loss: 0.39134187, time: [9.54], best model: 0\n",
      "Epoch: 10, train_loss: 0.36832448, valid_loss: 0.38459553, time: [9.36], best model: 1\n",
      "Epoch: 11, train_loss: 0.37040397, valid_loss: 0.38445957, time: [8.94], best model: 1\n",
      "Epoch: 12, train_loss: 0.36127227, valid_loss: 0.39111833, time: [9.05], best model: 0\n",
      "Epoch: 13, train_loss: 0.36475398, valid_loss: 0.38707127, time: [8.61], best model: 0\n",
      "Epoch: 14, train_loss: 0.37050309, valid_loss: 0.3975806, time: [8.69], best model: 0\n",
      "Epoch: 15, train_loss: 0.36206498, valid_loss: 0.39558926, time: [9.23], best model: 0\n",
      "Epoch: 16, train_loss: 0.35573754, valid_loss: 0.38774849, time: [8.9], best model: 0\n",
      "Epoch: 17, train_loss: 0.36679821, valid_loss: 0.39430556, time: [8.8], best model: 0\n",
      "Epoch: 18, train_loss: 0.35909741, valid_loss: 0.40071412, time: [8.94], best model: 0\n",
      "Epoch: 19, train_loss: 0.35611249, valid_loss: 0.39876912, time: [8.84], best model: 0\n",
      "Epoch: 20, train_loss: 0.35782825, valid_loss: 0.39894776, time: [8.62], best model: 0\n",
      "Early Stopped at Epoch: 21\n",
      "On sample 19 / 60 (hyperparams = {'cell_size': 157, 'hidden_size': 82, 'learning_rate': 0.020728654470189775, 'num_epochs': 145, 'patience': 11, 'batch_size': 256, 'early_stop_frac': 0.09634492561535725, 'seed': 4848})\n",
      "Model Structure:  GRUD(\n",
      "  (zl): Linear(in_features=290, out_features=82, bias=True)\n",
      "  (rl): Linear(in_features=290, out_features=82, bias=True)\n",
      "  (hl): Linear(in_features=290, out_features=82, bias=True)\n",
      "  (gamma_x_l): FilterLinear(in_features=104, out_features=104, bias=True)\n",
      "  (gamma_h_l): Linear(in_features=104, out_features=82, bias=True)\n",
      "  (fc): Linear(in_features=82, out_features=2, bias=True)\n",
      "  (bn): BatchNorm1d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (drop): Dropout(p=0.5, inplace=False)\n",
      ")\n",
      "Start Training ... \n",
      "Output type dermined by the model\n",
      "Epoch: 0, train_loss: 0.52198585, valid_loss: 0.5056227, time: [5.17], best model: 1\n",
      "Epoch: 1, train_loss: 0.3858651, valid_loss: 0.38083584, time: [5.12], best model: 1\n",
      "Epoch: 2, train_loss: 0.37272023, valid_loss: 0.36929108, time: [5.16], best model: 1\n",
      "Epoch: 3, train_loss: 0.36595209, valid_loss: 0.36889222, time: [5.09], best model: 1\n",
      "Epoch: 4, train_loss: 0.36992594, valid_loss: 0.36596327, time: [5.12], best model: 1\n",
      "Epoch: 5, train_loss: 0.36112469, valid_loss: 0.37940494, time: [5.1], best model: 0\n",
      "Epoch: 6, train_loss: 0.36460705, valid_loss: 0.37563486, time: [5.09], best model: 0\n",
      "Epoch: 7, train_loss: 0.36570132, valid_loss: 0.37151356, time: [5.08], best model: 0\n",
      "Epoch: 8, train_loss: 0.36151863, valid_loss: 0.3680247, time: [5.13], best model: 0\n",
      "Epoch: 9, train_loss: 0.3624126, valid_loss: 0.36768965, time: [5.22], best model: 0\n",
      "Epoch: 10, train_loss: 0.36138997, valid_loss: 0.37348569, time: [5.15], best model: 0\n",
      "Epoch: 11, train_loss: 0.35558093, valid_loss: 0.37429528, time: [5.08], best model: 0\n",
      "Epoch: 12, train_loss: 0.35905069, valid_loss: 0.36276711, time: [5.04], best model: 1\n",
      "Epoch: 13, train_loss: 0.35367099, valid_loss: 0.37669544, time: [5.2], best model: 0\n",
      "Epoch: 14, train_loss: 0.34940157, valid_loss: 0.38155061, time: [5.07], best model: 0\n",
      "Epoch: 15, train_loss: 0.3501562, valid_loss: 0.36910022, time: [5.04], best model: 0\n",
      "Epoch: 16, train_loss: 0.34919299, valid_loss: 0.37873236, time: [5.09], best model: 0\n",
      "Epoch: 17, train_loss: 0.34349458, valid_loss: 0.37426037, time: [5.09], best model: 0\n",
      "Epoch: 18, train_loss: 0.34739798, valid_loss: 0.38167646, time: [5.06], best model: 0\n",
      "Epoch: 19, train_loss: 0.34333772, valid_loss: 0.38945883, time: [5.05], best model: 0\n",
      "Epoch: 20, train_loss: 0.33808799, valid_loss: 0.38868096, time: [5.1], best model: 0\n",
      "Epoch: 21, train_loss: 0.3401392, valid_loss: 0.39099115, time: [5.06], best model: 0\n",
      "Epoch: 22, train_loss: 0.34257717, valid_loss: 0.38979298, time: [5.16], best model: 0\n",
      "Early Stopped at Epoch: 23\n",
      "On sample 20 / 60 (hyperparams = {'cell_size': 101, 'hidden_size': 91, 'learning_rate': 0.011528805226080373, 'num_epochs': 136, 'patience': 11, 'batch_size': 128, 'early_stop_frac': 0.09893012881271257, 'seed': 6447})\n",
      "Model Structure:  GRUD(\n",
      "  (zl): Linear(in_features=299, out_features=91, bias=True)\n",
      "  (rl): Linear(in_features=299, out_features=91, bias=True)\n",
      "  (hl): Linear(in_features=299, out_features=91, bias=True)\n",
      "  (gamma_x_l): FilterLinear(in_features=104, out_features=104, bias=True)\n",
      "  (gamma_h_l): Linear(in_features=104, out_features=91, bias=True)\n",
      "  (fc): Linear(in_features=91, out_features=2, bias=True)\n",
      "  (bn): BatchNorm1d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (drop): Dropout(p=0.5, inplace=False)\n",
      ")\n",
      "Start Training ... \n",
      "Output type dermined by the model\n",
      "Epoch: 0, train_loss: 0.52179601, valid_loss: 0.50395124, time: [8.16], best model: 1\n",
      "Epoch: 1, train_loss: 0.38192964, valid_loss: 0.36657741, time: [8.06], best model: 1\n",
      "Epoch: 2, train_loss: 0.37156563, valid_loss: 0.35760547, time: [8.07], best model: 1\n",
      "Epoch: 3, train_loss: 0.37064221, valid_loss: 0.36595793, time: [8.09], best model: 0\n",
      "Epoch: 4, train_loss: 0.36623458, valid_loss: 0.3698675, time: [8.1], best model: 0\n",
      "Epoch: 5, train_loss: 0.3592693, valid_loss: 0.36403656, time: [8.08], best model: 0\n",
      "Epoch: 6, train_loss: 0.35862924, valid_loss: 0.36467443, time: [8.16], best model: 0\n",
      "Epoch: 7, train_loss: 0.35934259, valid_loss: 0.36664034, time: [8.04], best model: 0\n",
      "Epoch: 8, train_loss: 0.35518405, valid_loss: 0.36797303, time: [8.09], best model: 0\n",
      "Epoch: 9, train_loss: 0.3556424, valid_loss: 0.37323689, time: [8.1], best model: 0\n",
      "Epoch: 10, train_loss: 0.3529039, valid_loss: 0.37354536, time: [8.16], best model: 0\n",
      "Epoch: 11, train_loss: 0.34301448, valid_loss: 0.373183, time: [8.37], best model: 0\n",
      "Epoch: 12, train_loss: 0.34581662, valid_loss: 0.37982259, time: [8.11], best model: 0\n",
      "Early Stopped at Epoch: 13\n",
      "On sample 21 / 60 (hyperparams = {'cell_size': 153, 'hidden_size': 104, 'learning_rate': 0.030375580746525466, 'num_epochs': 79, 'patience': 10, 'batch_size': 256, 'early_stop_frac': 0.0760720019719452, 'seed': 1259})\n",
      "Model Structure:  GRUD(\n",
      "  (zl): Linear(in_features=312, out_features=104, bias=True)\n",
      "  (rl): Linear(in_features=312, out_features=104, bias=True)\n",
      "  (hl): Linear(in_features=312, out_features=104, bias=True)\n",
      "  (gamma_x_l): FilterLinear(in_features=104, out_features=104, bias=True)\n",
      "  (gamma_h_l): Linear(in_features=104, out_features=104, bias=True)\n",
      "  (fc): Linear(in_features=104, out_features=2, bias=True)\n",
      "  (bn): BatchNorm1d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (drop): Dropout(p=0.5, inplace=False)\n",
      ")\n",
      "Start Training ... \n",
      "Output type dermined by the model\n",
      "Epoch: 0, train_loss: 0.47968146, valid_loss: 0.47497934, time: [5.16], best model: 1\n",
      "Epoch: 1, train_loss: 0.38013426, valid_loss: 0.37527561, time: [5.18], best model: 1\n",
      "Epoch: 2, train_loss: 0.3749656, valid_loss: 0.37137753, time: [5.2], best model: 1\n",
      "Epoch: 3, train_loss: 0.37319876, valid_loss: 0.37713521, time: [5.16], best model: 0\n",
      "Epoch: 4, train_loss: 0.37092581, valid_loss: 0.37523836, time: [5.22], best model: 0\n",
      "Epoch: 5, train_loss: 0.37350642, valid_loss: 0.36940571, time: [5.14], best model: 1\n",
      "Epoch: 6, train_loss: 0.36209488, valid_loss: 0.37301493, time: [5.2], best model: 0\n",
      "Epoch: 7, train_loss: 0.35977656, valid_loss: 0.37196852, time: [5.17], best model: 0\n",
      "Epoch: 8, train_loss: 0.36360668, valid_loss: 0.37228069, time: [5.15], best model: 0\n",
      "Epoch: 9, train_loss: 0.36223507, valid_loss: 0.37591887, time: [5.23], best model: 0\n",
      "Epoch: 10, train_loss: 0.35977999, valid_loss: 0.37177083, time: [5.16], best model: 0\n",
      "Epoch: 11, train_loss: 0.35219959, valid_loss: 0.37151594, time: [5.19], best model: 0\n",
      "Epoch: 12, train_loss: 0.35453183, valid_loss: 0.37418006, time: [5.14], best model: 0\n",
      "Epoch: 13, train_loss: 0.35048978, valid_loss: 0.36995958, time: [5.11], best model: 0\n",
      "Epoch: 14, train_loss: 0.34820983, valid_loss: 0.37632818, time: [5.14], best model: 0\n",
      "Early Stopped at Epoch: 15\n",
      "On sample 22 / 60 (hyperparams = {'cell_size': 88, 'hidden_size': 128, 'learning_rate': 0.023492438413069527, 'num_epochs': 113, 'patience': 11, 'batch_size': 128, 'early_stop_frac': 0.09026379231331474, 'seed': 9594})\n",
      "Model Structure:  GRUD(\n",
      "  (zl): Linear(in_features=336, out_features=128, bias=True)\n",
      "  (rl): Linear(in_features=336, out_features=128, bias=True)\n",
      "  (hl): Linear(in_features=336, out_features=128, bias=True)\n",
      "  (gamma_x_l): FilterLinear(in_features=104, out_features=104, bias=True)\n",
      "  (gamma_h_l): Linear(in_features=104, out_features=128, bias=True)\n",
      "  (fc): Linear(in_features=128, out_features=2, bias=True)\n",
      "  (bn): BatchNorm1d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (drop): Dropout(p=0.5, inplace=False)\n",
      ")\n",
      "Start Training ... \n",
      "Output type dermined by the model\n",
      "Epoch: 0, train_loss: 0.45090154, valid_loss: 0.44076346, time: [8.62], best model: 1\n",
      "Epoch: 1, train_loss: 0.37227451, valid_loss: 0.3849712, time: [8.55], best model: 1\n",
      "Epoch: 2, train_loss: 0.37054123, valid_loss: 0.37581692, time: [8.57], best model: 1\n",
      "Epoch: 3, train_loss: 0.37040993, valid_loss: 0.38029249, time: [8.71], best model: 0\n",
      "Epoch: 4, train_loss: 0.36541613, valid_loss: 0.37667109, time: [8.59], best model: 0\n",
      "Epoch: 5, train_loss: 0.36817432, valid_loss: 0.37948586, time: [8.65], best model: 0\n",
      "Epoch: 6, train_loss: 0.36506582, valid_loss: 0.3798313, time: [8.56], best model: 0\n",
      "Epoch: 7, train_loss: 0.363761, valid_loss: 0.38801623, time: [8.66], best model: 0\n",
      "Epoch: 8, train_loss: 0.36248151, valid_loss: 0.37504013, time: [8.73], best model: 1\n",
      "Epoch: 9, train_loss: 0.35789612, valid_loss: 0.3791919, time: [8.85], best model: 0\n",
      "Epoch: 10, train_loss: 0.36433635, valid_loss: 0.37462651, time: [8.67], best model: 1\n",
      "Epoch: 11, train_loss: 0.38353771, valid_loss: 0.38965998, time: [8.64], best model: 0\n",
      "Epoch: 12, train_loss: 0.38151166, valid_loss: 0.39061824, time: [8.7], best model: 0\n",
      "Epoch: 13, train_loss: 0.3700959, valid_loss: 0.3795769, time: [8.74], best model: 0\n",
      "Epoch: 14, train_loss: 0.36849504, valid_loss: 0.3842476, time: [8.84], best model: 0\n",
      "Epoch: 15, train_loss: 0.36703959, valid_loss: 0.38715125, time: [9.11], best model: 0\n",
      "Epoch: 16, train_loss: 0.3656997, valid_loss: 0.38032416, time: [8.63], best model: 0\n",
      "Epoch: 17, train_loss: 0.36816839, valid_loss: 0.37663692, time: [8.57], best model: 0\n",
      "Epoch: 18, train_loss: 0.36416094, valid_loss: 0.37654261, time: [8.52], best model: 0\n",
      "Epoch: 19, train_loss: 0.36609393, valid_loss: 0.37688664, time: [8.56], best model: 0\n",
      "Epoch: 20, train_loss: 0.36338123, valid_loss: 0.3780548, time: [8.57], best model: 0\n",
      "Early Stopped at Epoch: 21\n",
      "On sample 23 / 60 (hyperparams = {'cell_size': 83, 'hidden_size': 165, 'learning_rate': 0.03056037339109023, 'num_epochs': 142, 'patience': 9, 'batch_size': 512, 'early_stop_frac': 0.09366698797270301, 'seed': 3297})\n",
      "Model Structure:  GRUD(\n",
      "  (zl): Linear(in_features=373, out_features=165, bias=True)\n",
      "  (rl): Linear(in_features=373, out_features=165, bias=True)\n",
      "  (hl): Linear(in_features=373, out_features=165, bias=True)\n",
      "  (gamma_x_l): FilterLinear(in_features=104, out_features=104, bias=True)\n",
      "  (gamma_h_l): Linear(in_features=104, out_features=165, bias=True)\n",
      "  (fc): Linear(in_features=165, out_features=2, bias=True)\n",
      "  (bn): BatchNorm1d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (drop): Dropout(p=0.5, inplace=False)\n",
      ")\n",
      "Start Training ... \n",
      "Output type dermined by the model\n",
      "Epoch: 0, train_loss: 0.55711371, valid_loss: 0.53706288, time: [3.93], best model: 1\n",
      "Epoch: 1, train_loss: 0.39113952, valid_loss: 0.37559759, time: [3.99], best model: 1\n",
      "Epoch: 2, train_loss: 0.36713659, valid_loss: 0.3688732, time: [3.96], best model: 1\n",
      "Epoch: 3, train_loss: 0.3748922, valid_loss: 0.36460906, time: [3.97], best model: 1\n",
      "Epoch: 4, train_loss: 0.36725038, valid_loss: 0.36655676, time: [3.99], best model: 0\n",
      "Epoch: 5, train_loss: 0.35784629, valid_loss: 0.3699109, time: [3.83], best model: 0\n",
      "Epoch: 6, train_loss: 0.3595611, valid_loss: 0.37158973, time: [3.95], best model: 0\n",
      "Epoch: 7, train_loss: 0.35708523, valid_loss: 0.37525019, time: [4.02], best model: 0\n",
      "Epoch: 8, train_loss: 0.34724042, valid_loss: 0.36609216, time: [4.03], best model: 0\n",
      "Epoch: 9, train_loss: 0.35447015, valid_loss: 0.37107481, time: [3.88], best model: 0\n",
      "Epoch: 10, train_loss: 0.35361033, valid_loss: 0.37299561, time: [4.], best model: 0\n",
      "Epoch: 11, train_loss: 0.34677262, valid_loss: 0.36697641, time: [3.93], best model: 0\n",
      "Early Stopped at Epoch: 12\n",
      "On sample 24 / 60 (hyperparams = {'cell_size': 108, 'hidden_size': 92, 'learning_rate': 0.0491409857469679, 'num_epochs': 68, 'patience': 8, 'batch_size': 64, 'early_stop_frac': 0.051505613424837005, 'seed': 3433})\n",
      "Model Structure:  GRUD(\n",
      "  (zl): Linear(in_features=300, out_features=92, bias=True)\n",
      "  (rl): Linear(in_features=300, out_features=92, bias=True)\n",
      "  (hl): Linear(in_features=300, out_features=92, bias=True)\n",
      "  (gamma_x_l): FilterLinear(in_features=104, out_features=104, bias=True)\n",
      "  (gamma_h_l): Linear(in_features=104, out_features=92, bias=True)\n",
      "  (fc): Linear(in_features=92, out_features=2, bias=True)\n",
      "  (bn): BatchNorm1d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (drop): Dropout(p=0.5, inplace=False)\n",
      ")\n",
      "Start Training ... \n",
      "Output type dermined by the model\n",
      "Epoch: 0, train_loss: 0.4073395, valid_loss: 0.43243088, time: [14.65], best model: 1\n",
      "Epoch: 1, train_loss: 0.37733189, valid_loss: 0.41254108, time: [14.39], best model: 1\n",
      "Epoch: 2, train_loss: 0.37472402, valid_loss: 0.41635504, time: [14.34], best model: 0\n",
      "Epoch: 3, train_loss: 0.37430692, valid_loss: 0.40977589, time: [14.29], best model: 1\n",
      "Epoch: 4, train_loss: 0.37758227, valid_loss: 0.40199886, time: [14.28], best model: 1\n",
      "Epoch: 5, train_loss: 0.37453024, valid_loss: 0.41448793, time: [14.4], best model: 0\n",
      "Epoch: 6, train_loss: 0.3748855, valid_loss: 0.41446427, time: [14.37], best model: 0\n",
      "Epoch: 7, train_loss: 0.37231464, valid_loss: 0.40647614, time: [14.42], best model: 0\n",
      "Epoch: 8, train_loss: 0.37620806, valid_loss: 0.41195294, time: [14.32], best model: 0\n",
      "Epoch: 9, train_loss: 0.37600963, valid_loss: 0.41436721, time: [14.3], best model: 0\n",
      "Epoch: 10, train_loss: 0.3723865, valid_loss: 0.41457751, time: [14.39], best model: 0\n",
      "Epoch: 11, train_loss: 0.3698939, valid_loss: 0.41413169, time: [14.37], best model: 0\n",
      "Early Stopped at Epoch: 12\n",
      "New Best Score: 73.89 @ hyperparams = {'cell_size': 108, 'hidden_size': 92, 'learning_rate': 0.0491409857469679, 'num_epochs': 68, 'patience': 8, 'batch_size': 64, 'early_stop_frac': 0.051505613424837005, 'seed': 3433}\n",
      "On sample 25 / 60 (hyperparams = {'cell_size': 174, 'hidden_size': 65, 'learning_rate': 0.056949682108840806, 'num_epochs': 71, 'patience': 8, 'batch_size': 64, 'early_stop_frac': 0.13929058830787158, 'seed': 8642})\n",
      "Model Structure:  GRUD(\n",
      "  (zl): Linear(in_features=273, out_features=65, bias=True)\n",
      "  (rl): Linear(in_features=273, out_features=65, bias=True)\n",
      "  (hl): Linear(in_features=273, out_features=65, bias=True)\n",
      "  (gamma_x_l): FilterLinear(in_features=104, out_features=104, bias=True)\n",
      "  (gamma_h_l): Linear(in_features=104, out_features=65, bias=True)\n",
      "  (fc): Linear(in_features=65, out_features=2, bias=True)\n",
      "  (bn): BatchNorm1d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (drop): Dropout(p=0.5, inplace=False)\n",
      ")\n",
      "Start Training ... \n",
      "Output type dermined by the model\n",
      "Epoch: 0, train_loss: 0.40385779, valid_loss: 0.40484853, time: [13.21], best model: 1\n",
      "Epoch: 1, train_loss: 0.38121653, valid_loss: 0.37839189, time: [13.25], best model: 1\n",
      "Epoch: 2, train_loss: 0.38995219, valid_loss: 0.37551053, time: [13.21], best model: 1\n",
      "Epoch: 3, train_loss: 0.37500929, valid_loss: 0.37402554, time: [13.31], best model: 1\n",
      "Epoch: 4, train_loss: 0.37834395, valid_loss: 0.38165473, time: [13.29], best model: 0\n",
      "Epoch: 5, train_loss: 0.38271793, valid_loss: 0.37834866, time: [13.36], best model: 0\n",
      "Epoch: 6, train_loss: 0.37632256, valid_loss: 0.38151886, time: [13.08], best model: 0\n",
      "Epoch: 7, train_loss: 0.38393382, valid_loss: 0.37773885, time: [13.11], best model: 0\n",
      "Epoch: 8, train_loss: 0.37767877, valid_loss: 0.37610847, time: [13.11], best model: 0\n",
      "Epoch: 9, train_loss: 0.37219323, valid_loss: 0.36917653, time: [13.08], best model: 1\n",
      "Epoch: 10, train_loss: 0.37792097, valid_loss: 0.3777868, time: [13.11], best model: 0\n",
      "Epoch: 11, train_loss: 0.37573378, valid_loss: 0.37911048, time: [13.11], best model: 0\n",
      "Epoch: 12, train_loss: 0.37829386, valid_loss: 0.37664181, time: [13.16], best model: 0\n",
      "Epoch: 13, train_loss: 0.36943105, valid_loss: 0.37653334, time: [13.18], best model: 0\n",
      "Epoch: 14, train_loss: 0.37028568, valid_loss: 0.37118351, time: [13.14], best model: 0\n",
      "Epoch: 15, train_loss: 0.37805518, valid_loss: 0.38120388, time: [13.16], best model: 0\n",
      "Epoch: 16, train_loss: 0.37081292, valid_loss: 0.37768745, time: [13.22], best model: 0\n",
      "Early Stopped at Epoch: 17\n",
      "On sample 26 / 60 (hyperparams = {'cell_size': 117, 'hidden_size': 127, 'learning_rate': 0.08651131155747016, 'num_epochs': 101, 'patience': 9, 'batch_size': 256, 'early_stop_frac': 0.05291493178475118, 'seed': 5499})\n",
      "Model Structure:  GRUD(\n",
      "  (zl): Linear(in_features=335, out_features=127, bias=True)\n",
      "  (rl): Linear(in_features=335, out_features=127, bias=True)\n",
      "  (hl): Linear(in_features=335, out_features=127, bias=True)\n",
      "  (gamma_x_l): FilterLinear(in_features=104, out_features=104, bias=True)\n",
      "  (gamma_h_l): Linear(in_features=104, out_features=127, bias=True)\n",
      "  (fc): Linear(in_features=127, out_features=2, bias=True)\n",
      "  (bn): BatchNorm1d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (drop): Dropout(p=0.5, inplace=False)\n",
      ")\n",
      "Start Training ... \n",
      "Output type dermined by the model\n",
      "Epoch: 0, train_loss: 0.43586949, valid_loss: 0.45097496, time: [5.54], best model: 1\n",
      "Epoch: 1, train_loss: 0.38389107, valid_loss: 0.41372139, time: [5.53], best model: 1\n",
      "Epoch: 2, train_loss: 0.37555975, valid_loss: 0.4013535, time: [5.51], best model: 1\n",
      "Epoch: 3, train_loss: 0.37684982, valid_loss: 0.40885113, time: [5.59], best model: 0\n",
      "Epoch: 4, train_loss: 0.37104847, valid_loss: 0.40924361, time: [5.54], best model: 0\n",
      "Epoch: 5, train_loss: 0.37208329, valid_loss: 0.40047993, time: [5.5], best model: 1\n",
      "Epoch: 6, train_loss: 0.37975102, valid_loss: 0.40384637, time: [5.55], best model: 0\n",
      "Epoch: 7, train_loss: 0.38335812, valid_loss: 0.41208778, time: [5.51], best model: 0\n",
      "Epoch: 8, train_loss: 0.37846319, valid_loss: 0.40629218, time: [5.49], best model: 0\n",
      "Epoch: 9, train_loss: 0.3797329, valid_loss: 0.41255606, time: [5.62], best model: 0\n",
      "Epoch: 10, train_loss: 0.37842947, valid_loss: 0.40371923, time: [5.53], best model: 0\n",
      "Epoch: 11, train_loss: 0.37528056, valid_loss: 0.4070633, time: [5.55], best model: 0\n",
      "Epoch: 12, train_loss: 0.37306869, valid_loss: 0.40449515, time: [5.6], best model: 0\n",
      "Epoch: 13, train_loss: 0.37362582, valid_loss: 0.40236159, time: [5.66], best model: 0\n",
      "Epoch: 14, train_loss: 0.3737705, valid_loss: 0.39992554, time: [5.7], best model: 1\n",
      "Epoch: 15, train_loss: 0.37125003, valid_loss: 0.40704256, time: [5.58], best model: 0\n",
      "Epoch: 16, train_loss: 0.37575377, valid_loss: 0.3951907, time: [5.57], best model: 1\n",
      "Epoch: 17, train_loss: 0.37143833, valid_loss: 0.39765699, time: [5.62], best model: 0\n",
      "Epoch: 18, train_loss: 0.36864868, valid_loss: 0.40006634, time: [5.76], best model: 0\n",
      "Epoch: 19, train_loss: 0.37242714, valid_loss: 0.40378048, time: [5.74], best model: 0\n",
      "Epoch: 20, train_loss: 0.36701802, valid_loss: 0.39669409, time: [5.61], best model: 0\n",
      "Epoch: 21, train_loss: 0.36807168, valid_loss: 0.40048692, time: [5.52], best model: 0\n",
      "Epoch: 22, train_loss: 0.36873122, valid_loss: 0.40351185, time: [5.52], best model: 0\n",
      "Epoch: 23, train_loss: 0.37723947, valid_loss: 0.39667585, time: [5.6], best model: 0\n",
      "Epoch: 24, train_loss: 0.3681468, valid_loss: 0.40376805, time: [5.85], best model: 0\n",
      "Early Stopped at Epoch: 25\n",
      "On sample 27 / 60 (hyperparams = {'cell_size': 119, 'hidden_size': 157, 'learning_rate': 0.10085097007841644, 'num_epochs': 118, 'patience': 10, 'batch_size': 256, 'early_stop_frac': 0.08728928840117262, 'seed': 658})\n",
      "Model Structure:  GRUD(\n",
      "  (zl): Linear(in_features=365, out_features=157, bias=True)\n",
      "  (rl): Linear(in_features=365, out_features=157, bias=True)\n",
      "  (hl): Linear(in_features=365, out_features=157, bias=True)\n",
      "  (gamma_x_l): FilterLinear(in_features=104, out_features=104, bias=True)\n",
      "  (gamma_h_l): Linear(in_features=104, out_features=157, bias=True)\n",
      "  (fc): Linear(in_features=157, out_features=2, bias=True)\n",
      "  (bn): BatchNorm1d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (drop): Dropout(p=0.5, inplace=False)\n",
      ")\n",
      "Start Training ... \n",
      "Output type dermined by the model\n",
      "Epoch: 0, train_loss: 0.42922996, valid_loss: 0.42647081, time: [6.1], best model: 1\n",
      "Epoch: 1, train_loss: 0.38703951, valid_loss: 0.39717871, time: [6.14], best model: 1\n",
      "Epoch: 2, train_loss: 0.38134067, valid_loss: 0.39348428, time: [6.02], best model: 1\n",
      "Epoch: 3, train_loss: 0.37937213, valid_loss: 0.39893917, time: [5.94], best model: 0\n",
      "Epoch: 4, train_loss: 0.3837076, valid_loss: 0.39804636, time: [6.1], best model: 0\n",
      "Epoch: 5, train_loss: 0.38769231, valid_loss: 0.39254147, time: [6.02], best model: 1\n",
      "Epoch: 6, train_loss: 0.38031572, valid_loss: 0.3921985, time: [5.89], best model: 1\n",
      "Epoch: 7, train_loss: 0.38067394, valid_loss: 0.39058472, time: [5.95], best model: 1\n",
      "Epoch: 8, train_loss: 0.38065425, valid_loss: 0.39129568, time: [6.08], best model: 0\n",
      "Epoch: 9, train_loss: 0.37441619, valid_loss: 0.39975228, time: [6.32], best model: 0\n",
      "Epoch: 10, train_loss: 0.37222355, valid_loss: 0.3929732, time: [6.54], best model: 0\n",
      "Epoch: 11, train_loss: 0.38031171, valid_loss: 0.39675486, time: [6.48], best model: 0\n",
      "Epoch: 12, train_loss: 0.37920195, valid_loss: 0.39455553, time: [6.35], best model: 0\n",
      "Epoch: 13, train_loss: 0.37099315, valid_loss: 0.39100653, time: [6.08], best model: 0\n",
      "Epoch: 14, train_loss: 0.36585753, valid_loss: 0.38859254, time: [6.23], best model: 1\n",
      "Epoch: 15, train_loss: 0.38517923, valid_loss: 0.39047923, time: [6.24], best model: 0\n",
      "Epoch: 16, train_loss: 0.38029583, valid_loss: 0.38897343, time: [6.29], best model: 0\n",
      "Epoch: 17, train_loss: 0.37093706, valid_loss: 0.39135503, time: [6.31], best model: 0\n",
      "Epoch: 18, train_loss: 0.37531943, valid_loss: 0.3901972, time: [6.32], best model: 0\n",
      "Epoch: 19, train_loss: 0.37519368, valid_loss: 0.3905188, time: [6.39], best model: 0\n",
      "Epoch: 20, train_loss: 0.38424233, valid_loss: 0.39708083, time: [6.21], best model: 0\n",
      "Epoch: 21, train_loss: 0.38226063, valid_loss: 0.39608002, time: [6.63], best model: 0\n",
      "Epoch: 22, train_loss: 0.37775453, valid_loss: 0.38518925, time: [6.47], best model: 1\n",
      "Epoch: 23, train_loss: 0.37575389, valid_loss: 0.39235791, time: [6.51], best model: 0\n",
      "Epoch: 24, train_loss: 0.38002738, valid_loss: 0.39281095, time: [6.5], best model: 0\n",
      "Epoch: 25, train_loss: 0.37003291, valid_loss: 0.38936447, time: [6.03], best model: 0\n",
      "Epoch: 26, train_loss: 0.37958763, valid_loss: 0.39423034, time: [6.34], best model: 0\n",
      "Epoch: 27, train_loss: 0.37660563, valid_loss: 0.3870366, time: [6.23], best model: 0\n",
      "Epoch: 28, train_loss: 0.37487541, valid_loss: 0.39496302, time: [6.17], best model: 0\n",
      "Epoch: 29, train_loss: 0.37125377, valid_loss: 0.38909889, time: [5.88], best model: 0\n",
      "Epoch: 30, train_loss: 0.36766249, valid_loss: 0.39460376, time: [6.05], best model: 0\n",
      "Epoch: 31, train_loss: 0.37108787, valid_loss: 0.38861934, time: [5.95], best model: 0\n",
      "Early Stopped at Epoch: 32\n",
      "On sample 28 / 60 (hyperparams = {'cell_size': 138, 'hidden_size': 101, 'learning_rate': 0.006886808622935135, 'num_epochs': 83, 'patience': 11, 'batch_size': 512, 'early_stop_frac': 0.05958733146927722, 'seed': 26})\n",
      "Model Structure:  GRUD(\n",
      "  (zl): Linear(in_features=309, out_features=101, bias=True)\n",
      "  (rl): Linear(in_features=309, out_features=101, bias=True)\n",
      "  (hl): Linear(in_features=309, out_features=101, bias=True)\n",
      "  (gamma_x_l): FilterLinear(in_features=104, out_features=104, bias=True)\n",
      "  (gamma_h_l): Linear(in_features=104, out_features=101, bias=True)\n",
      "  (fc): Linear(in_features=101, out_features=2, bias=True)\n",
      "  (bn): BatchNorm1d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (drop): Dropout(p=0.5, inplace=False)\n",
      ")\n",
      "Start Training ... \n",
      "Output type dermined by the model\n",
      "Epoch: 0, train_loss: 0.7789512, valid_loss: 0.76513208, time: [4.01], best model: 1\n",
      "Epoch: 1, train_loss: 0.55635643, valid_loss: 0.57960199, time: [3.95], best model: 1\n",
      "Epoch: 2, train_loss: 0.4912227, valid_loss: 0.49490414, time: [3.99], best model: 1\n",
      "Epoch: 3, train_loss: 0.45486635, valid_loss: 0.46720648, time: [4.05], best model: 1\n",
      "Epoch: 4, train_loss: 0.41271722, valid_loss: 0.43051154, time: [4.37], best model: 1\n",
      "Epoch: 5, train_loss: 0.38973729, valid_loss: 0.41031942, time: [4.18], best model: 1\n",
      "Epoch: 6, train_loss: 0.38053109, valid_loss: 0.39171419, time: [4.13], best model: 1\n",
      "Epoch: 7, train_loss: 0.36698154, valid_loss: 0.38507112, time: [4.05], best model: 1\n",
      "Epoch: 8, train_loss: 0.36441832, valid_loss: 0.3859203, time: [4.12], best model: 0\n",
      "Epoch: 9, train_loss: 0.36230768, valid_loss: 0.38937499, time: [4.39], best model: 0\n",
      "Epoch: 10, train_loss: 0.35580928, valid_loss: 0.38386917, time: [4.14], best model: 1\n",
      "Epoch: 11, train_loss: 0.3547733, valid_loss: 0.37793201, time: [4.33], best model: 1\n",
      "Epoch: 12, train_loss: 0.34664965, valid_loss: 0.38479007, time: [4.22], best model: 0\n",
      "Epoch: 13, train_loss: 0.33885749, valid_loss: 0.39320453, time: [4.31], best model: 0\n",
      "Epoch: 14, train_loss: 0.33180844, valid_loss: 0.39843435, time: [4.14], best model: 0\n",
      "Epoch: 15, train_loss: 0.32229071, valid_loss: 0.40362005, time: [4.13], best model: 0\n",
      "Epoch: 16, train_loss: 0.31829303, valid_loss: 0.3984127, time: [4.21], best model: 0\n",
      "Epoch: 17, train_loss: 0.31215582, valid_loss: 0.40708882, time: [4.01], best model: 0\n",
      "Epoch: 18, train_loss: 0.30576468, valid_loss: 0.42296336, time: [4.01], best model: 0\n",
      "Epoch: 19, train_loss: 0.29190114, valid_loss: 0.43238014, time: [4.03], best model: 0\n",
      "Epoch: 20, train_loss: 0.28621616, valid_loss: 0.43894583, time: [3.97], best model: 0\n",
      "Epoch: 21, train_loss: 0.27107935, valid_loss: 0.45053981, time: [3.92], best model: 0\n",
      "Early Stopped at Epoch: 22\n",
      "On sample 29 / 60 (hyperparams = {'cell_size': 96, 'hidden_size': 128, 'learning_rate': 0.025211825143616397, 'num_epochs': 87, 'patience': 10, 'batch_size': 64, 'early_stop_frac': 0.06969643203500386, 'seed': 1123})\n",
      "Model Structure:  GRUD(\n",
      "  (zl): Linear(in_features=336, out_features=128, bias=True)\n",
      "  (rl): Linear(in_features=336, out_features=128, bias=True)\n",
      "  (hl): Linear(in_features=336, out_features=128, bias=True)\n",
      "  (gamma_x_l): FilterLinear(in_features=104, out_features=104, bias=True)\n",
      "  (gamma_h_l): Linear(in_features=104, out_features=128, bias=True)\n",
      "  (fc): Linear(in_features=128, out_features=2, bias=True)\n",
      "  (bn): BatchNorm1d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (drop): Dropout(p=0.5, inplace=False)\n",
      ")\n",
      "Start Training ... \n",
      "Output type dermined by the model\n",
      "Epoch: 0, train_loss: 0.41100336, valid_loss: 0.39793578, time: [15.22], best model: 1\n",
      "Epoch: 1, train_loss: 0.37674437, valid_loss: 0.36574611, time: [15.13], best model: 1\n",
      "Epoch: 2, train_loss: 0.37823417, valid_loss: 0.36417794, time: [15.15], best model: 1\n",
      "Epoch: 3, train_loss: 0.37359054, valid_loss: 0.36708559, time: [15.19], best model: 0\n",
      "Epoch: 4, train_loss: 0.37138018, valid_loss: 0.36951123, time: [15.28], best model: 0\n",
      "Epoch: 5, train_loss: 0.37514367, valid_loss: 0.37166872, time: [15.27], best model: 0\n",
      "Epoch: 6, train_loss: 0.36999951, valid_loss: 0.36982708, time: [15.06], best model: 0\n",
      "Epoch: 7, train_loss: 0.35868487, valid_loss: 0.36936153, time: [15.21], best model: 0\n",
      "Epoch: 8, train_loss: 0.37206472, valid_loss: 0.36985769, time: [15.2], best model: 0\n",
      "Epoch: 9, train_loss: 0.36842456, valid_loss: 0.37178947, time: [15.31], best model: 0\n",
      "Epoch: 10, train_loss: 0.36892911, valid_loss: 0.37014683, time: [15.2], best model: 0\n",
      "Epoch: 11, train_loss: 0.36225769, valid_loss: 0.3770811, time: [15.31], best model: 0\n",
      "Early Stopped at Epoch: 12\n",
      "On sample 30 / 60 (hyperparams = {'cell_size': 145, 'hidden_size': 140, 'learning_rate': 0.06633114272482353, 'num_epochs': 118, 'patience': 10, 'batch_size': 256, 'early_stop_frac': 0.14424206123971434, 'seed': 9667})\n",
      "Model Structure:  GRUD(\n",
      "  (zl): Linear(in_features=348, out_features=140, bias=True)\n",
      "  (rl): Linear(in_features=348, out_features=140, bias=True)\n",
      "  (hl): Linear(in_features=348, out_features=140, bias=True)\n",
      "  (gamma_x_l): FilterLinear(in_features=104, out_features=104, bias=True)\n",
      "  (gamma_h_l): Linear(in_features=104, out_features=140, bias=True)\n",
      "  (fc): Linear(in_features=140, out_features=2, bias=True)\n",
      "  (bn): BatchNorm1d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (drop): Dropout(p=0.5, inplace=False)\n",
      ")\n",
      "Start Training ... \n",
      "Output type dermined by the model\n",
      "Epoch: 0, train_loss: 0.44496492, valid_loss: 0.43366439, time: [5.68], best model: 1\n",
      "Epoch: 1, train_loss: 0.38376028, valid_loss: 0.39012766, time: [5.7], best model: 1\n",
      "Epoch: 2, train_loss: 0.38314094, valid_loss: 0.390456, time: [5.84], best model: 0\n",
      "Epoch: 3, train_loss: 0.37729788, valid_loss: 0.38672883, time: [5.57], best model: 1\n",
      "Epoch: 4, train_loss: 0.38098982, valid_loss: 0.38971986, time: [5.53], best model: 0\n",
      "Epoch: 5, train_loss: 0.37781177, valid_loss: 0.39116042, time: [5.72], best model: 0\n",
      "Epoch: 6, train_loss: 0.37867178, valid_loss: 0.39375796, time: [6.62], best model: 0\n",
      "Epoch: 7, train_loss: 0.37541209, valid_loss: 0.38863019, time: [6.44], best model: 0\n",
      "Epoch: 8, train_loss: 0.3698584, valid_loss: 0.38799596, time: [6.24], best model: 0\n",
      "Epoch: 9, train_loss: 0.37760186, valid_loss: 0.38989922, time: [6.15], best model: 0\n",
      "Epoch: 10, train_loss: 0.37329006, valid_loss: 0.39486282, time: [5.58], best model: 0\n",
      "Epoch: 11, train_loss: 0.37614008, valid_loss: 0.38638898, time: [5.98], best model: 1\n",
      "Epoch: 12, train_loss: 0.37514172, valid_loss: 0.38722372, time: [5.96], best model: 0\n",
      "Epoch: 13, train_loss: 0.37431008, valid_loss: 0.38898676, time: [5.75], best model: 0\n",
      "Epoch: 14, train_loss: 0.37496618, valid_loss: 0.38486539, time: [5.72], best model: 1\n",
      "Epoch: 15, train_loss: 0.36911147, valid_loss: 0.39370159, time: [5.68], best model: 0\n",
      "Epoch: 16, train_loss: 0.37003643, valid_loss: 0.38523425, time: [5.74], best model: 0\n",
      "Epoch: 17, train_loss: 0.37333894, valid_loss: 0.39124128, time: [5.77], best model: 0\n",
      "Epoch: 18, train_loss: 0.3656357, valid_loss: 0.39680137, time: [5.7], best model: 0\n",
      "Epoch: 19, train_loss: 0.36675532, valid_loss: 0.38705836, time: [5.77], best model: 0\n",
      "Epoch: 20, train_loss: 0.3664841, valid_loss: 0.38954983, time: [5.71], best model: 0\n",
      "Epoch: 21, train_loss: 0.36521101, valid_loss: 0.38856574, time: [5.73], best model: 0\n",
      "Epoch: 22, train_loss: 0.36322369, valid_loss: 0.39550611, time: [5.86], best model: 0\n",
      "Epoch: 23, train_loss: 0.37403008, valid_loss: 0.3944322, time: [5.75], best model: 0\n",
      "Epoch: 24, train_loss: 0.3738138, valid_loss: 0.38406542, time: [5.84], best model: 1\n",
      "Epoch: 25, train_loss: 0.36594187, valid_loss: 0.38895757, time: [5.99], best model: 0\n",
      "Epoch: 26, train_loss: 0.36577014, valid_loss: 0.38976635, time: [5.73], best model: 0\n",
      "Epoch: 27, train_loss: 0.36483857, valid_loss: 0.39115235, time: [5.78], best model: 0\n",
      "Epoch: 28, train_loss: 0.36955803, valid_loss: 0.38585029, time: [5.68], best model: 0\n",
      "Epoch: 29, train_loss: 0.3672689, valid_loss: 0.39138232, time: [5.73], best model: 0\n",
      "Epoch: 30, train_loss: 0.36828375, valid_loss: 0.39086052, time: [5.77], best model: 0\n",
      "Epoch: 31, train_loss: 0.372673, valid_loss: 0.3921098, time: [5.99], best model: 0\n",
      "Epoch: 32, train_loss: 0.36322079, valid_loss: 0.38469063, time: [5.75], best model: 0\n",
      "Epoch: 33, train_loss: 0.36809298, valid_loss: 0.39015722, time: [5.84], best model: 0\n",
      "Early Stopped at Epoch: 34\n",
      "On sample 31 / 60 (hyperparams = {'cell_size': 171, 'hidden_size': 175, 'learning_rate': 0.018146656289167673, 'num_epochs': 120, 'patience': 9, 'batch_size': 256, 'early_stop_frac': 0.08712711716678964, 'seed': 4843})\n",
      "Model Structure:  GRUD(\n",
      "  (zl): Linear(in_features=383, out_features=175, bias=True)\n",
      "  (rl): Linear(in_features=383, out_features=175, bias=True)\n",
      "  (hl): Linear(in_features=383, out_features=175, bias=True)\n",
      "  (gamma_x_l): FilterLinear(in_features=104, out_features=104, bias=True)\n",
      "  (gamma_h_l): Linear(in_features=104, out_features=175, bias=True)\n",
      "  (fc): Linear(in_features=175, out_features=2, bias=True)\n",
      "  (bn): BatchNorm1d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (drop): Dropout(p=0.5, inplace=False)\n",
      ")\n",
      "Start Training ... \n",
      "Output type dermined by the model\n",
      "Epoch: 0, train_loss: 0.55078953, valid_loss: 0.54337692, time: [6.05], best model: 1\n",
      "Epoch: 1, train_loss: 0.38744742, valid_loss: 0.39665151, time: [5.95], best model: 1\n",
      "Epoch: 2, train_loss: 0.3723258, valid_loss: 0.38357347, time: [6.17], best model: 1\n",
      "Epoch: 3, train_loss: 0.37103579, valid_loss: 0.3756431, time: [5.98], best model: 1\n",
      "Epoch: 4, train_loss: 0.37073507, valid_loss: 0.37762367, time: [5.97], best model: 0\n",
      "Epoch: 5, train_loss: 0.3614168, valid_loss: 0.37990602, time: [5.94], best model: 0\n",
      "Epoch: 6, train_loss: 0.36517418, valid_loss: 0.37513151, time: [6.1], best model: 1\n",
      "Epoch: 7, train_loss: 0.36176096, valid_loss: 0.3852637, time: [6.07], best model: 0\n",
      "Epoch: 8, train_loss: 0.35580115, valid_loss: 0.37721456, time: [6.06], best model: 0\n",
      "Epoch: 9, train_loss: 0.35186855, valid_loss: 0.39128029, time: [6.02], best model: 0\n",
      "Epoch: 10, train_loss: 0.35635334, valid_loss: 0.38643937, time: [6.06], best model: 0\n",
      "Epoch: 11, train_loss: 0.35227734, valid_loss: 0.38873068, time: [6.], best model: 0\n",
      "Epoch: 12, train_loss: 0.34640493, valid_loss: 0.39557412, time: [6.15], best model: 0\n",
      "Epoch: 13, train_loss: 0.34309549, valid_loss: 0.39645968, time: [6.07], best model: 0\n",
      "Epoch: 14, train_loss: 0.33030562, valid_loss: 0.40753988, time: [6.07], best model: 0\n",
      "Early Stopped at Epoch: 15\n",
      "On sample 32 / 60 (hyperparams = {'cell_size': 81, 'hidden_size': 115, 'learning_rate': 0.08901458933690015, 'num_epochs': 76, 'patience': 10, 'batch_size': 64, 'early_stop_frac': 0.12290008018214771, 'seed': 137})\n",
      "Model Structure:  GRUD(\n",
      "  (zl): Linear(in_features=323, out_features=115, bias=True)\n",
      "  (rl): Linear(in_features=323, out_features=115, bias=True)\n",
      "  (hl): Linear(in_features=323, out_features=115, bias=True)\n",
      "  (gamma_x_l): FilterLinear(in_features=104, out_features=104, bias=True)\n",
      "  (gamma_h_l): Linear(in_features=104, out_features=115, bias=True)\n",
      "  (fc): Linear(in_features=115, out_features=2, bias=True)\n",
      "  (bn): BatchNorm1d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (drop): Dropout(p=0.5, inplace=False)\n",
      ")\n",
      "Start Training ... \n",
      "Output type dermined by the model\n",
      "Epoch: 0, train_loss: 0.40998447, valid_loss: 0.40895534, time: [14.36], best model: 1\n",
      "Epoch: 1, train_loss: 0.39029757, valid_loss: 0.39272871, time: [14.48], best model: 1\n",
      "Epoch: 2, train_loss: 0.38113197, valid_loss: 0.39683236, time: [14.3], best model: 0\n",
      "Epoch: 3, train_loss: 0.38527683, valid_loss: 0.39034301, time: [14.26], best model: 1\n",
      "Epoch: 4, train_loss: 0.38750501, valid_loss: 0.39187659, time: [14.81], best model: 0\n",
      "Epoch: 5, train_loss: 0.38907793, valid_loss: 0.3915979, time: [14.35], best model: 0\n",
      "Epoch: 6, train_loss: 0.3888808, valid_loss: 0.39313754, time: [14.3], best model: 0\n",
      "Epoch: 7, train_loss: 0.38515802, valid_loss: 0.39226049, time: [14.26], best model: 0\n",
      "Epoch: 8, train_loss: 0.38902199, valid_loss: 0.39035867, time: [14.36], best model: 0\n",
      "Epoch: 9, train_loss: 0.38401974, valid_loss: 0.39297669, time: [14.22], best model: 0\n",
      "Epoch: 10, train_loss: 0.39320783, valid_loss: 0.39398996, time: [14.39], best model: 0\n",
      "Epoch: 11, train_loss: 0.38494277, valid_loss: 0.39164078, time: [14.35], best model: 0\n",
      "Epoch: 12, train_loss: 0.38516022, valid_loss: 0.39552957, time: [14.3], best model: 0\n",
      "Early Stopped at Epoch: 13\n",
      "On sample 33 / 60 (hyperparams = {'cell_size': 130, 'hidden_size': 147, 'learning_rate': 0.023740242630502596, 'num_epochs': 64, 'patience': 9, 'batch_size': 64, 'early_stop_frac': 0.06261601086290215, 'seed': 2755})\n",
      "Model Structure:  GRUD(\n",
      "  (zl): Linear(in_features=355, out_features=147, bias=True)\n",
      "  (rl): Linear(in_features=355, out_features=147, bias=True)\n",
      "  (hl): Linear(in_features=355, out_features=147, bias=True)\n",
      "  (gamma_x_l): FilterLinear(in_features=104, out_features=104, bias=True)\n",
      "  (gamma_h_l): Linear(in_features=104, out_features=147, bias=True)\n",
      "  (fc): Linear(in_features=147, out_features=2, bias=True)\n",
      "  (bn): BatchNorm1d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (drop): Dropout(p=0.5, inplace=False)\n",
      ")\n",
      "Start Training ... \n",
      "Output type dermined by the model\n",
      "Epoch: 0, train_loss: 0.4172812, valid_loss: 0.40619999, time: [15.42], best model: 1\n",
      "Epoch: 1, train_loss: 0.38460123, valid_loss: 0.36389708, time: [15.36], best model: 1\n",
      "Epoch: 2, train_loss: 0.37190362, valid_loss: 0.36298641, time: [15.61], best model: 1\n",
      "Epoch: 3, train_loss: 0.376084, valid_loss: 0.37369382, time: [15.59], best model: 0\n",
      "Epoch: 4, train_loss: 0.37289198, valid_loss: 0.36880705, time: [15.69], best model: 0\n",
      "Epoch: 5, train_loss: 0.38615695, valid_loss: 0.37103281, time: [15.64], best model: 0\n",
      "Epoch: 6, train_loss: 0.37288759, valid_loss: 0.36732558, time: [15.47], best model: 0\n",
      "Epoch: 7, train_loss: 0.36976465, valid_loss: 0.36660608, time: [15.52], best model: 0\n",
      "Epoch: 8, train_loss: 0.37104368, valid_loss: 0.3613119, time: [15.47], best model: 1\n",
      "Epoch: 9, train_loss: 0.37098189, valid_loss: 0.36534284, time: [15.52], best model: 0\n",
      "Epoch: 10, train_loss: 0.36887148, valid_loss: 0.36091337, time: [15.53], best model: 1\n",
      "Epoch: 11, train_loss: 0.37277275, valid_loss: 0.3650489, time: [15.62], best model: 0\n",
      "Epoch: 12, train_loss: 0.37438205, valid_loss: 0.36811022, time: [15.67], best model: 0\n",
      "Epoch: 13, train_loss: 0.3686099, valid_loss: 0.36751787, time: [15.4], best model: 0\n",
      "Epoch: 14, train_loss: 0.36255668, valid_loss: 0.36513423, time: [15.42], best model: 0\n",
      "Epoch: 15, train_loss: 0.36824229, valid_loss: 0.3698358, time: [15.29], best model: 0\n",
      "Epoch: 16, train_loss: 0.36629084, valid_loss: 0.362623, time: [15.35], best model: 0\n",
      "Epoch: 17, train_loss: 0.36683026, valid_loss: 0.36410002, time: [15.36], best model: 0\n",
      "Epoch: 18, train_loss: 0.36740305, valid_loss: 0.36438212, time: [15.35], best model: 0\n",
      "Early Stopped at Epoch: 19\n",
      "On sample 34 / 60 (hyperparams = {'cell_size': 102, 'hidden_size': 194, 'learning_rate': 0.0761755038883449, 'num_epochs': 107, 'patience': 11, 'batch_size': 512, 'early_stop_frac': 0.07512829217072094, 'seed': 6198})\n",
      "Model Structure:  GRUD(\n",
      "  (zl): Linear(in_features=402, out_features=194, bias=True)\n",
      "  (rl): Linear(in_features=402, out_features=194, bias=True)\n",
      "  (hl): Linear(in_features=402, out_features=194, bias=True)\n",
      "  (gamma_x_l): FilterLinear(in_features=104, out_features=104, bias=True)\n",
      "  (gamma_h_l): Linear(in_features=104, out_features=194, bias=True)\n",
      "  (fc): Linear(in_features=194, out_features=2, bias=True)\n",
      "  (bn): BatchNorm1d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (drop): Dropout(p=0.5, inplace=False)\n",
      ")\n",
      "Start Training ... \n",
      "Output type dermined by the model\n",
      "Epoch: 0, train_loss: 0.47185783, valid_loss: 0.45674016, time: [4.12], best model: 1\n",
      "Epoch: 1, train_loss: 0.39663099, valid_loss: 0.39156955, time: [4.05], best model: 1\n",
      "Epoch: 2, train_loss: 0.3816843, valid_loss: 0.37775545, time: [4.04], best model: 1\n",
      "Epoch: 3, train_loss: 0.37906532, valid_loss: 0.38181181, time: [4.14], best model: 0\n",
      "Epoch: 4, train_loss: 0.38227139, valid_loss: 0.38668191, time: [4.03], best model: 0\n",
      "Epoch: 5, train_loss: 0.3805439, valid_loss: 0.38062569, time: [4.01], best model: 0\n",
      "Epoch: 6, train_loss: 0.38441016, valid_loss: 0.38158042, time: [4.03], best model: 0\n",
      "Epoch: 7, train_loss: 0.37764015, valid_loss: 0.3792182, time: [3.99], best model: 0\n",
      "Epoch: 8, train_loss: 0.37422768, valid_loss: 0.36999957, time: [3.99], best model: 1\n",
      "Epoch: 9, train_loss: 0.37830795, valid_loss: 0.37860708, time: [4.01], best model: 0\n",
      "Epoch: 10, train_loss: 0.3732769, valid_loss: 0.37962262, time: [4.05], best model: 0\n",
      "Epoch: 11, train_loss: 0.38090862, valid_loss: 0.38576797, time: [4.], best model: 0\n",
      "Epoch: 12, train_loss: 0.38189869, valid_loss: 0.38751777, time: [4.04], best model: 0\n",
      "Epoch: 13, train_loss: 0.3709094, valid_loss: 0.37893305, time: [4.07], best model: 0\n",
      "Epoch: 14, train_loss: 0.37552376, valid_loss: 0.37871602, time: [4.02], best model: 0\n",
      "Epoch: 15, train_loss: 0.37432623, valid_loss: 0.38043346, time: [4.03], best model: 0\n",
      "Epoch: 16, train_loss: 0.36985121, valid_loss: 0.37567012, time: [4.11], best model: 0\n",
      "Epoch: 17, train_loss: 0.37500575, valid_loss: 0.37473221, time: [4.04], best model: 0\n",
      "Epoch: 18, train_loss: 0.37119929, valid_loss: 0.376909, time: [4.08], best model: 0\n",
      "Early Stopped at Epoch: 19\n",
      "On sample 35 / 60 (hyperparams = {'cell_size': 100, 'hidden_size': 114, 'learning_rate': 0.06730205132311011, 'num_epochs': 136, 'patience': 10, 'batch_size': 512, 'early_stop_frac': 0.13812352971212316, 'seed': 4055})\n",
      "Model Structure:  GRUD(\n",
      "  (zl): Linear(in_features=322, out_features=114, bias=True)\n",
      "  (rl): Linear(in_features=322, out_features=114, bias=True)\n",
      "  (hl): Linear(in_features=322, out_features=114, bias=True)\n",
      "  (gamma_x_l): FilterLinear(in_features=104, out_features=104, bias=True)\n",
      "  (gamma_h_l): Linear(in_features=104, out_features=114, bias=True)\n",
      "  (fc): Linear(in_features=114, out_features=2, bias=True)\n",
      "  (bn): BatchNorm1d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (drop): Dropout(p=0.5, inplace=False)\n",
      ")\n",
      "Start Training ... \n",
      "Output type dermined by the model\n",
      "Epoch: 0, train_loss: 0.48956677, valid_loss: 0.45673466, time: [3.72], best model: 1\n",
      "Epoch: 1, train_loss: 0.39388401, valid_loss: 0.37839522, time: [3.71], best model: 1\n",
      "Epoch: 2, train_loss: 0.38285341, valid_loss: 0.3757768, time: [3.67], best model: 1\n",
      "Epoch: 3, train_loss: 0.37910271, valid_loss: 0.37442895, time: [3.77], best model: 1\n",
      "Epoch: 4, train_loss: 0.37515269, valid_loss: 0.36983466, time: [3.79], best model: 1\n",
      "Epoch: 5, train_loss: 0.37467183, valid_loss: 0.3718402, time: [3.78], best model: 0\n",
      "Epoch: 6, train_loss: 0.37353144, valid_loss: 0.37345573, time: [3.75], best model: 0\n",
      "Epoch: 7, train_loss: 0.36534081, valid_loss: 0.36922976, time: [3.71], best model: 1\n",
      "Epoch: 8, train_loss: 0.37199756, valid_loss: 0.37055247, time: [3.8], best model: 0\n",
      "Epoch: 9, train_loss: 0.37201749, valid_loss: 0.37382327, time: [3.68], best model: 0\n",
      "Epoch: 10, train_loss: 0.37368253, valid_loss: 0.37387817, time: [3.7], best model: 0\n",
      "Epoch: 11, train_loss: 0.37202624, valid_loss: 0.36378976, time: [3.75], best model: 1\n",
      "Epoch: 12, train_loss: 0.37398968, valid_loss: 0.35978787, time: [3.7], best model: 1\n",
      "Epoch: 13, train_loss: 0.36661373, valid_loss: 0.37118568, time: [3.73], best model: 0\n",
      "Epoch: 14, train_loss: 0.37551066, valid_loss: 0.36492981, time: [3.69], best model: 0\n",
      "Epoch: 15, train_loss: 0.38119766, valid_loss: 0.37115475, time: [3.73], best model: 0\n",
      "Epoch: 16, train_loss: 0.3839565, valid_loss: 0.37705891, time: [3.73], best model: 0\n",
      "Epoch: 17, train_loss: 0.37223949, valid_loss: 0.37083336, time: [3.74], best model: 0\n",
      "Epoch: 18, train_loss: 0.37766501, valid_loss: 0.37583269, time: [3.72], best model: 0\n",
      "Epoch: 19, train_loss: 0.37524482, valid_loss: 0.37395896, time: [3.69], best model: 0\n",
      "Epoch: 20, train_loss: 0.37669519, valid_loss: 0.36828818, time: [3.7], best model: 0\n",
      "Epoch: 21, train_loss: 0.37140332, valid_loss: 0.36416698, time: [3.74], best model: 0\n",
      "Early Stopped at Epoch: 22\n",
      "On sample 36 / 60 (hyperparams = {'cell_size': 182, 'hidden_size': 105, 'learning_rate': 0.08188855115046297, 'num_epochs': 121, 'patience': 10, 'batch_size': 512, 'early_stop_frac': 0.14032961504890157, 'seed': 2087})\n",
      "Model Structure:  GRUD(\n",
      "  (zl): Linear(in_features=313, out_features=105, bias=True)\n",
      "  (rl): Linear(in_features=313, out_features=105, bias=True)\n",
      "  (hl): Linear(in_features=313, out_features=105, bias=True)\n",
      "  (gamma_x_l): FilterLinear(in_features=104, out_features=104, bias=True)\n",
      "  (gamma_h_l): Linear(in_features=104, out_features=105, bias=True)\n",
      "  (fc): Linear(in_features=105, out_features=2, bias=True)\n",
      "  (bn): BatchNorm1d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (drop): Dropout(p=0.5, inplace=False)\n",
      ")\n",
      "Start Training ... \n",
      "Output type dermined by the model\n",
      "Epoch: 0, train_loss: 0.47957424, valid_loss: 0.45938294, time: [3.67], best model: 1\n",
      "Epoch: 1, train_loss: 0.38957306, valid_loss: 0.40162679, time: [3.64], best model: 1\n",
      "Epoch: 2, train_loss: 0.38716105, valid_loss: 0.392866, time: [3.73], best model: 1\n",
      "Epoch: 3, train_loss: 0.37555671, valid_loss: 0.38268467, time: [3.58], best model: 1\n",
      "Epoch: 4, train_loss: 0.38117017, valid_loss: 0.38381107, time: [3.65], best model: 0\n",
      "Epoch: 5, train_loss: 0.37572653, valid_loss: 0.38817351, time: [3.69], best model: 0\n",
      "Epoch: 6, train_loss: 0.37372824, valid_loss: 0.38830335, time: [3.58], best model: 0\n",
      "Epoch: 7, train_loss: 0.37571658, valid_loss: 0.38832896, time: [3.69], best model: 0\n",
      "Epoch: 8, train_loss: 0.37384735, valid_loss: 0.38747896, time: [3.64], best model: 0\n",
      "Epoch: 9, train_loss: 0.37548222, valid_loss: 0.38473797, time: [3.65], best model: 0\n",
      "Epoch: 10, train_loss: 0.37051858, valid_loss: 0.38654661, time: [3.62], best model: 0\n",
      "Epoch: 11, train_loss: 0.37358621, valid_loss: 0.38760315, time: [3.65], best model: 0\n",
      "Epoch: 12, train_loss: 0.3662294, valid_loss: 0.38404778, time: [3.71], best model: 0\n",
      "Epoch: 13, train_loss: 0.36487242, valid_loss: 0.38251683, time: [3.65], best model: 1\n",
      "Epoch: 14, train_loss: 0.37245005, valid_loss: 0.38824115, time: [3.66], best model: 0\n",
      "Epoch: 15, train_loss: 0.37150962, valid_loss: 0.38479284, time: [3.64], best model: 0\n",
      "Epoch: 16, train_loss: 0.36830017, valid_loss: 0.38217923, time: [3.6], best model: 1\n",
      "Epoch: 17, train_loss: 0.36785872, valid_loss: 0.38944241, time: [3.62], best model: 0\n",
      "Epoch: 18, train_loss: 0.36438322, valid_loss: 0.38527496, time: [3.67], best model: 0\n",
      "Epoch: 19, train_loss: 0.36363319, valid_loss: 0.38582812, time: [3.69], best model: 0\n",
      "Epoch: 20, train_loss: 0.35984097, valid_loss: 0.38684191, time: [3.6], best model: 0\n",
      "Epoch: 21, train_loss: 0.36315772, valid_loss: 0.39019847, time: [3.67], best model: 0\n",
      "Epoch: 22, train_loss: 0.35707085, valid_loss: 0.39172748, time: [3.65], best model: 0\n",
      "Epoch: 23, train_loss: 0.35601401, valid_loss: 0.39315677, time: [3.61], best model: 0\n",
      "Epoch: 24, train_loss: 0.35491828, valid_loss: 0.39618502, time: [3.64], best model: 0\n",
      "Epoch: 25, train_loss: 0.35889057, valid_loss: 0.40390403, time: [3.76], best model: 0\n",
      "Early Stopped at Epoch: 26\n",
      "On sample 37 / 60 (hyperparams = {'cell_size': 113, 'hidden_size': 173, 'learning_rate': 0.00512475622652616, 'num_epochs': 83, 'patience': 10, 'batch_size': 512, 'early_stop_frac': 0.0787635258215888, 'seed': 5126})\n",
      "Model Structure:  GRUD(\n",
      "  (zl): Linear(in_features=381, out_features=173, bias=True)\n",
      "  (rl): Linear(in_features=381, out_features=173, bias=True)\n",
      "  (hl): Linear(in_features=381, out_features=173, bias=True)\n",
      "  (gamma_x_l): FilterLinear(in_features=104, out_features=104, bias=True)\n",
      "  (gamma_h_l): Linear(in_features=104, out_features=173, bias=True)\n",
      "  (fc): Linear(in_features=173, out_features=2, bias=True)\n",
      "  (bn): BatchNorm1d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (drop): Dropout(p=0.5, inplace=False)\n",
      ")\n",
      "Start Training ... \n",
      "Output type dermined by the model\n",
      "Epoch: 0, train_loss: 0.76216106, valid_loss: 0.76600774, time: [4.02], best model: 1\n",
      "Epoch: 1, train_loss: 0.61762206, valid_loss: 0.60486406, time: [4.01], best model: 1\n",
      "Epoch: 2, train_loss: 0.52012959, valid_loss: 0.51203136, time: [4.05], best model: 1\n",
      "Epoch: 3, train_loss: 0.47763789, valid_loss: 0.47367496, time: [4.], best model: 1\n",
      "Epoch: 4, train_loss: 0.46004343, valid_loss: 0.44266373, time: [4.01], best model: 1\n",
      "Epoch: 5, train_loss: 0.42143021, valid_loss: 0.43466797, time: [4.], best model: 1\n",
      "Epoch: 6, train_loss: 0.41224871, valid_loss: 0.40744896, time: [4.07], best model: 1\n",
      "Epoch: 7, train_loss: 0.39209242, valid_loss: 0.39224316, time: [3.98], best model: 1\n",
      "Epoch: 8, train_loss: 0.38182707, valid_loss: 0.38330641, time: [4.07], best model: 1\n",
      "Epoch: 9, train_loss: 0.37323233, valid_loss: 0.37338629, time: [3.98], best model: 1\n",
      "Epoch: 10, train_loss: 0.36819782, valid_loss: 0.36474756, time: [3.96], best model: 1\n",
      "Epoch: 11, train_loss: 0.3627992, valid_loss: 0.36778584, time: [3.96], best model: 0\n",
      "Epoch: 12, train_loss: 0.35606712, valid_loss: 0.37027222, time: [4.], best model: 0\n",
      "Epoch: 13, train_loss: 0.35033089, valid_loss: 0.36617854, time: [3.97], best model: 0\n",
      "Epoch: 14, train_loss: 0.35209519, valid_loss: 0.36757933, time: [3.99], best model: 0\n",
      "Epoch: 15, train_loss: 0.34137402, valid_loss: 0.36888911, time: [3.96], best model: 0\n",
      "Epoch: 16, train_loss: 0.34286852, valid_loss: 0.36980057, time: [3.99], best model: 0\n",
      "Epoch: 17, train_loss: 0.33494994, valid_loss: 0.37884938, time: [4.], best model: 0\n",
      "Epoch: 18, train_loss: 0.34063969, valid_loss: 0.37553997, time: [3.95], best model: 0\n",
      "Epoch: 19, train_loss: 0.33177865, valid_loss: 0.38686364, time: [4.01], best model: 0\n",
      "Early Stopped at Epoch: 20\n",
      "On sample 38 / 60 (hyperparams = {'cell_size': 99, 'hidden_size': 111, 'learning_rate': 0.02495740287443452, 'num_epochs': 79, 'patience': 10, 'batch_size': 512, 'early_stop_frac': 0.14671131315122965, 'seed': 417})\n",
      "Model Structure:  GRUD(\n",
      "  (zl): Linear(in_features=319, out_features=111, bias=True)\n",
      "  (rl): Linear(in_features=319, out_features=111, bias=True)\n",
      "  (hl): Linear(in_features=319, out_features=111, bias=True)\n",
      "  (gamma_x_l): FilterLinear(in_features=104, out_features=104, bias=True)\n",
      "  (gamma_h_l): Linear(in_features=104, out_features=111, bias=True)\n",
      "  (fc): Linear(in_features=111, out_features=2, bias=True)\n",
      "  (bn): BatchNorm1d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (drop): Dropout(p=0.5, inplace=False)\n",
      ")\n",
      "Start Training ... \n",
      "Output type dermined by the model\n",
      "Epoch: 0, train_loss: 0.62127255, valid_loss: 0.59281116, time: [3.49], best model: 1\n",
      "Epoch: 1, train_loss: 0.39932346, valid_loss: 0.40323508, time: [3.44], best model: 1\n",
      "Epoch: 2, train_loss: 0.37726879, valid_loss: 0.37268526, time: [3.39], best model: 1\n",
      "Epoch: 3, train_loss: 0.36787439, valid_loss: 0.3627894, time: [3.47], best model: 1\n",
      "Epoch: 4, train_loss: 0.37352463, valid_loss: 0.37300647, time: [3.48], best model: 0\n",
      "Epoch: 5, train_loss: 0.36948374, valid_loss: 0.36965911, time: [3.48], best model: 0\n",
      "Epoch: 6, train_loss: 0.35412333, valid_loss: 0.37312402, time: [3.46], best model: 0\n",
      "Epoch: 7, train_loss: 0.36287283, valid_loss: 0.37454785, time: [3.51], best model: 0\n",
      "Epoch: 8, train_loss: 0.36926252, valid_loss: 0.37130151, time: [3.42], best model: 0\n",
      "Epoch: 9, train_loss: 0.35840854, valid_loss: 0.36581774, time: [3.62], best model: 0\n",
      "Epoch: 10, train_loss: 0.35096197, valid_loss: 0.3699219, time: [3.5], best model: 0\n",
      "Epoch: 11, train_loss: 0.35424137, valid_loss: 0.37339638, time: [3.78], best model: 0\n",
      "Epoch: 12, train_loss: 0.34977009, valid_loss: 0.37065873, time: [4.07], best model: 0\n",
      "Early Stopped at Epoch: 13\n",
      "On sample 39 / 60 (hyperparams = {'cell_size': 89, 'hidden_size': 138, 'learning_rate': 0.07246274991204592, 'num_epochs': 91, 'patience': 9, 'batch_size': 64, 'early_stop_frac': 0.1168099335625191, 'seed': 7563})\n",
      "Model Structure:  GRUD(\n",
      "  (zl): Linear(in_features=346, out_features=138, bias=True)\n",
      "  (rl): Linear(in_features=346, out_features=138, bias=True)\n",
      "  (hl): Linear(in_features=346, out_features=138, bias=True)\n",
      "  (gamma_x_l): FilterLinear(in_features=104, out_features=104, bias=True)\n",
      "  (gamma_h_l): Linear(in_features=104, out_features=138, bias=True)\n",
      "  (fc): Linear(in_features=138, out_features=2, bias=True)\n",
      "  (bn): BatchNorm1d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (drop): Dropout(p=0.5, inplace=False)\n",
      ")\n",
      "Start Training ... \n",
      "Output type dermined by the model\n",
      "Epoch: 0, train_loss: 0.40572783, valid_loss: 0.40892835, time: [14.88], best model: 1\n",
      "Epoch: 1, train_loss: 0.39141816, valid_loss: 0.39349907, time: [14.8], best model: 1\n",
      "Epoch: 2, train_loss: 0.3845842, valid_loss: 0.39036421, time: [14.71], best model: 1\n",
      "Epoch: 3, train_loss: 0.38779899, valid_loss: 0.39794311, time: [14.67], best model: 0\n",
      "Epoch: 4, train_loss: 0.38429273, valid_loss: 0.39716815, time: [15.05], best model: 0\n",
      "Epoch: 5, train_loss: 0.38568462, valid_loss: 0.39037224, time: [14.69], best model: 0\n",
      "Epoch: 6, train_loss: 0.38591334, valid_loss: 0.39114945, time: [14.7], best model: 0\n",
      "Epoch: 7, train_loss: 0.38614476, valid_loss: 0.38961475, time: [14.68], best model: 1\n",
      "Epoch: 8, train_loss: 0.38242056, valid_loss: 0.38478422, time: [14.77], best model: 1\n",
      "Epoch: 9, train_loss: 0.37804631, valid_loss: 0.38059238, time: [14.77], best model: 1\n",
      "Epoch: 10, train_loss: 0.37688013, valid_loss: 0.38665283, time: [14.97], best model: 0\n",
      "Epoch: 11, train_loss: 0.37910567, valid_loss: 0.38423692, time: [14.66], best model: 0\n",
      "Epoch: 12, train_loss: 0.37964207, valid_loss: 0.37787546, time: [14.66], best model: 1\n",
      "Epoch: 13, train_loss: 0.38267491, valid_loss: 0.38449021, time: [14.92], best model: 0\n",
      "Epoch: 14, train_loss: 0.3833815, valid_loss: 0.39251227, time: [14.68], best model: 0\n",
      "Epoch: 15, train_loss: 0.38775087, valid_loss: 0.39266964, time: [14.72], best model: 0\n",
      "Epoch: 16, train_loss: 0.39037924, valid_loss: 0.39288274, time: [14.68], best model: 0\n",
      "Epoch: 17, train_loss: 0.38256205, valid_loss: 0.39371164, time: [14.69], best model: 0\n",
      "Epoch: 18, train_loss: 0.38354889, valid_loss: 0.38726192, time: [14.81], best model: 0\n",
      "Epoch: 19, train_loss: 0.37802372, valid_loss: 0.38360024, time: [14.86], best model: 0\n",
      "Epoch: 20, train_loss: 0.37955128, valid_loss: 0.37979466, time: [14.87], best model: 0\n",
      "Early Stopped at Epoch: 21\n",
      "On sample 40 / 60 (hyperparams = {'cell_size': 186, 'hidden_size': 143, 'learning_rate': 0.010756250900112284, 'num_epochs': 141, 'patience': 8, 'batch_size': 64, 'early_stop_frac': 0.10030067735343266, 'seed': 3370})\n",
      "Model Structure:  GRUD(\n",
      "  (zl): Linear(in_features=351, out_features=143, bias=True)\n",
      "  (rl): Linear(in_features=351, out_features=143, bias=True)\n",
      "  (hl): Linear(in_features=351, out_features=143, bias=True)\n",
      "  (gamma_x_l): FilterLinear(in_features=104, out_features=104, bias=True)\n",
      "  (gamma_h_l): Linear(in_features=104, out_features=143, bias=True)\n",
      "  (fc): Linear(in_features=143, out_features=2, bias=True)\n",
      "  (bn): BatchNorm1d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (drop): Dropout(p=0.5, inplace=False)\n",
      ")\n",
      "Start Training ... \n",
      "Output type dermined by the model\n",
      "Epoch: 0, train_loss: 0.47089344, valid_loss: 0.47108073, time: [15.18], best model: 1\n",
      "Epoch: 1, train_loss: 0.38551616, valid_loss: 0.40805836, time: [15.14], best model: 1\n",
      "Epoch: 2, train_loss: 0.37890881, valid_loss: 0.39034287, time: [15.11], best model: 1\n",
      "Epoch: 3, train_loss: 0.37090191, valid_loss: 0.38415771, time: [15.05], best model: 1\n",
      "Epoch: 4, train_loss: 0.36682548, valid_loss: 0.3908244, time: [15.04], best model: 0\n",
      "Epoch: 5, train_loss: 0.36512714, valid_loss: 0.39286967, time: [14.96], best model: 0\n",
      "Epoch: 6, train_loss: 0.37155544, valid_loss: 0.39051208, time: [15.02], best model: 0\n",
      "Epoch: 7, train_loss: 0.36129563, valid_loss: 0.38715525, time: [15.2], best model: 0\n",
      "Epoch: 8, train_loss: 0.35940428, valid_loss: 0.38813246, time: [15.06], best model: 0\n",
      "Epoch: 9, train_loss: 0.35474584, valid_loss: 0.39008786, time: [14.99], best model: 0\n",
      "Epoch: 10, train_loss: 0.35932513, valid_loss: 0.39564985, time: [15.59], best model: 0\n",
      "Early Stopped at Epoch: 11\n",
      "On sample 41 / 60 (hyperparams = {'cell_size': 65, 'hidden_size': 175, 'learning_rate': 0.005058948319431931, 'num_epochs': 149, 'patience': 11, 'batch_size': 512, 'early_stop_frac': 0.08780024086485555, 'seed': 3185})\n",
      "Model Structure:  GRUD(\n",
      "  (zl): Linear(in_features=383, out_features=175, bias=True)\n",
      "  (rl): Linear(in_features=383, out_features=175, bias=True)\n",
      "  (hl): Linear(in_features=383, out_features=175, bias=True)\n",
      "  (gamma_x_l): FilterLinear(in_features=104, out_features=104, bias=True)\n",
      "  (gamma_h_l): Linear(in_features=104, out_features=175, bias=True)\n",
      "  (fc): Linear(in_features=175, out_features=2, bias=True)\n",
      "  (bn): BatchNorm1d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (drop): Dropout(p=0.5, inplace=False)\n",
      ")\n",
      "Start Training ... \n",
      "Output type dermined by the model\n",
      "Epoch: 0, train_loss: 0.7511867, valid_loss: 0.75136112, time: [4.37], best model: 1\n",
      "Epoch: 1, train_loss: 0.59570411, valid_loss: 0.57967508, time: [4.07], best model: 1\n",
      "Epoch: 2, train_loss: 0.52077172, valid_loss: 0.51853032, time: [4.05], best model: 1\n",
      "Epoch: 3, train_loss: 0.49115809, valid_loss: 0.4804871, time: [4.21], best model: 1\n",
      "Epoch: 4, train_loss: 0.45730509, valid_loss: 0.46614811, time: [4.1], best model: 1\n",
      "Epoch: 5, train_loss: 0.44589411, valid_loss: 0.45610283, time: [4.08], best model: 1\n",
      "Epoch: 6, train_loss: 0.42851987, valid_loss: 0.44030193, time: [4.09], best model: 1\n",
      "Epoch: 7, train_loss: 0.39953903, valid_loss: 0.41122749, time: [4.14], best model: 1\n",
      "Epoch: 8, train_loss: 0.38664542, valid_loss: 0.4058631, time: [4.06], best model: 1\n",
      "Epoch: 9, train_loss: 0.37895666, valid_loss: 0.3969744, time: [4.1], best model: 1\n",
      "Epoch: 10, train_loss: 0.36767877, valid_loss: 0.39244155, time: [4.11], best model: 1\n",
      "Epoch: 11, train_loss: 0.36248845, valid_loss: 0.39490562, time: [4.08], best model: 0\n",
      "Epoch: 12, train_loss: 0.35982316, valid_loss: 0.39412637, time: [4.07], best model: 0\n",
      "Epoch: 13, train_loss: 0.35416307, valid_loss: 0.39096684, time: [4.07], best model: 1\n",
      "Epoch: 14, train_loss: 0.35151071, valid_loss: 0.39339046, time: [4.01], best model: 0\n",
      "Epoch: 15, train_loss: 0.34469016, valid_loss: 0.3951982, time: [4.01], best model: 0\n",
      "Epoch: 16, train_loss: 0.3403929, valid_loss: 0.39524647, time: [4.09], best model: 0\n",
      "Epoch: 17, train_loss: 0.33376884, valid_loss: 0.40111897, time: [4.14], best model: 0\n",
      "Epoch: 18, train_loss: 0.32396642, valid_loss: 0.40708627, time: [4.11], best model: 0\n",
      "Epoch: 19, train_loss: 0.31867794, valid_loss: 0.4177501, time: [4.1], best model: 0\n",
      "Epoch: 20, train_loss: 0.30890596, valid_loss: 0.42253412, time: [4.06], best model: 0\n",
      "Epoch: 21, train_loss: 0.30226438, valid_loss: 0.42059829, time: [4.03], best model: 0\n",
      "Epoch: 22, train_loss: 0.29972698, valid_loss: 0.42506517, time: [4.16], best model: 0\n",
      "Epoch: 23, train_loss: 0.30004373, valid_loss: 0.45946759, time: [4.03], best model: 0\n",
      "Early Stopped at Epoch: 24\n",
      "On sample 42 / 60 (hyperparams = {'cell_size': 186, 'hidden_size': 160, 'learning_rate': 0.03771349336995607, 'num_epochs': 133, 'patience': 10, 'batch_size': 128, 'early_stop_frac': 0.08373682942964583, 'seed': 6040})\n",
      "Model Structure:  GRUD(\n",
      "  (zl): Linear(in_features=368, out_features=160, bias=True)\n",
      "  (rl): Linear(in_features=368, out_features=160, bias=True)\n",
      "  (hl): Linear(in_features=368, out_features=160, bias=True)\n",
      "  (gamma_x_l): FilterLinear(in_features=104, out_features=104, bias=True)\n",
      "  (gamma_h_l): Linear(in_features=104, out_features=160, bias=True)\n",
      "  (fc): Linear(in_features=160, out_features=2, bias=True)\n",
      "  (bn): BatchNorm1d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (drop): Dropout(p=0.5, inplace=False)\n",
      ")\n",
      "Start Training ... \n",
      "Output type dermined by the model\n",
      "Epoch: 0, train_loss: 0.423899, valid_loss: 0.39418142, time: [8.78], best model: 1\n",
      "Epoch: 1, train_loss: 0.38068611, valid_loss: 0.35550295, time: [8.77], best model: 1\n",
      "Epoch: 2, train_loss: 0.37925015, valid_loss: 0.35900421, time: [8.78], best model: 0\n",
      "Epoch: 3, train_loss: 0.37957232, valid_loss: 0.35927072, time: [8.93], best model: 0\n",
      "Epoch: 4, train_loss: 0.37311047, valid_loss: 0.35567247, time: [9.02], best model: 0\n",
      "Epoch: 5, train_loss: 0.37331749, valid_loss: 0.35916942, time: [9.54], best model: 0\n",
      "Epoch: 6, train_loss: 0.3770952, valid_loss: 0.36203208, time: [9.12], best model: 0\n",
      "Epoch: 7, train_loss: 0.37936453, valid_loss: 0.35541589, time: [9.21], best model: 1\n",
      "Epoch: 8, train_loss: 0.37368813, valid_loss: 0.3527999, time: [8.76], best model: 1\n",
      "Epoch: 9, train_loss: 0.37669145, valid_loss: 0.36048549, time: [8.9], best model: 0\n",
      "Epoch: 10, train_loss: 0.37205945, valid_loss: 0.35856334, time: [8.72], best model: 0\n",
      "Epoch: 11, train_loss: 0.3760257, valid_loss: 0.36702126, time: [9.43], best model: 0\n",
      "Epoch: 12, train_loss: 0.37858566, valid_loss: 0.36514561, time: [10.01], best model: 0\n",
      "Epoch: 13, train_loss: 0.37366902, valid_loss: 0.35771804, time: [9.6], best model: 0\n",
      "Epoch: 14, train_loss: 0.37487319, valid_loss: 0.36752399, time: [9.01], best model: 0\n",
      "Epoch: 15, train_loss: 0.36918993, valid_loss: 0.36682007, time: [8.83], best model: 0\n",
      "Epoch: 16, train_loss: 0.36734781, valid_loss: 0.36694153, time: [8.76], best model: 0\n",
      "Epoch: 17, train_loss: 0.3730656, valid_loss: 0.35962959, time: [8.87], best model: 0\n",
      "Early Stopped at Epoch: 18\n",
      "On sample 43 / 60 (hyperparams = {'cell_size': 195, 'hidden_size': 97, 'learning_rate': 0.060978199147176386, 'num_epochs': 119, 'patience': 11, 'batch_size': 256, 'early_stop_frac': 0.1452010705083001, 'seed': 4311})\n",
      "Model Structure:  GRUD(\n",
      "  (zl): Linear(in_features=305, out_features=97, bias=True)\n",
      "  (rl): Linear(in_features=305, out_features=97, bias=True)\n",
      "  (hl): Linear(in_features=305, out_features=97, bias=True)\n",
      "  (gamma_x_l): FilterLinear(in_features=104, out_features=104, bias=True)\n",
      "  (gamma_h_l): Linear(in_features=104, out_features=97, bias=True)\n",
      "  (fc): Linear(in_features=97, out_features=2, bias=True)\n",
      "  (bn): BatchNorm1d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (drop): Dropout(p=0.5, inplace=False)\n",
      ")\n",
      "Start Training ... \n",
      "Output type dermined by the model\n",
      "Epoch: 0, train_loss: 0.4430473, valid_loss: 0.4397093, time: [5.11], best model: 1\n",
      "Epoch: 1, train_loss: 0.37105494, valid_loss: 0.38934871, time: [4.97], best model: 1\n",
      "Epoch: 2, train_loss: 0.36762865, valid_loss: 0.39252888, time: [5.08], best model: 0\n",
      "Epoch: 3, train_loss: 0.36809353, valid_loss: 0.38526025, time: [5.], best model: 1\n",
      "Epoch: 4, train_loss: 0.37211196, valid_loss: 0.39194919, time: [4.94], best model: 0\n",
      "Epoch: 5, train_loss: 0.36421169, valid_loss: 0.38034765, time: [4.75], best model: 1\n",
      "Epoch: 6, train_loss: 0.36483501, valid_loss: 0.38400598, time: [4.78], best model: 0\n",
      "Epoch: 7, train_loss: 0.36235008, valid_loss: 0.38761344, time: [4.85], best model: 0\n",
      "Epoch: 8, train_loss: 0.36518756, valid_loss: 0.38810869, time: [4.75], best model: 0\n",
      "Epoch: 9, train_loss: 0.36417625, valid_loss: 0.39141384, time: [4.76], best model: 0\n",
      "Epoch: 10, train_loss: 0.3610363, valid_loss: 0.38903212, time: [4.77], best model: 0\n",
      "Epoch: 11, train_loss: 0.36916608, valid_loss: 0.39442936, time: [4.74], best model: 0\n",
      "Epoch: 12, train_loss: 0.37505351, valid_loss: 0.39473038, time: [4.77], best model: 0\n",
      "Epoch: 13, train_loss: 0.37636476, valid_loss: 0.38781405, time: [4.8], best model: 0\n",
      "Epoch: 14, train_loss: 0.37514097, valid_loss: 0.38923305, time: [4.78], best model: 0\n",
      "Epoch: 15, train_loss: 0.37407171, valid_loss: 0.39060659, time: [5.06], best model: 0\n",
      "Early Stopped at Epoch: 16\n",
      "On sample 44 / 60 (hyperparams = {'cell_size': 167, 'hidden_size': 184, 'learning_rate': 0.007222272738416023, 'num_epochs': 60, 'patience': 10, 'batch_size': 256, 'early_stop_frac': 0.1193333828589223, 'seed': 928})\n",
      "Model Structure:  GRUD(\n",
      "  (zl): Linear(in_features=392, out_features=184, bias=True)\n",
      "  (rl): Linear(in_features=392, out_features=184, bias=True)\n",
      "  (hl): Linear(in_features=392, out_features=184, bias=True)\n",
      "  (gamma_x_l): FilterLinear(in_features=104, out_features=104, bias=True)\n",
      "  (gamma_h_l): Linear(in_features=104, out_features=184, bias=True)\n",
      "  (fc): Linear(in_features=184, out_features=2, bias=True)\n",
      "  (bn): BatchNorm1d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (drop): Dropout(p=0.5, inplace=False)\n",
      ")\n",
      "Start Training ... \n",
      "Output type dermined by the model\n",
      "Epoch: 0, train_loss: 0.68190712, valid_loss: 0.67519713, time: [5.81], best model: 1\n",
      "Epoch: 1, train_loss: 0.47826265, valid_loss: 0.48124166, time: [6.17], best model: 1\n",
      "Epoch: 2, train_loss: 0.40550747, valid_loss: 0.39676536, time: [6.28], best model: 1\n",
      "Epoch: 3, train_loss: 0.38218194, valid_loss: 0.37696996, time: [6.27], best model: 1\n",
      "Epoch: 4, train_loss: 0.3764619, valid_loss: 0.36920166, time: [5.97], best model: 1\n",
      "Epoch: 5, train_loss: 0.37293464, valid_loss: 0.36072627, time: [5.67], best model: 1\n",
      "Epoch: 6, train_loss: 0.36615087, valid_loss: 0.36400397, time: [5.63], best model: 0\n",
      "Epoch: 7, train_loss: 0.35902997, valid_loss: 0.37339083, time: [5.6], best model: 0\n",
      "Epoch: 8, train_loss: 0.34913913, valid_loss: 0.36991514, time: [5.65], best model: 0\n",
      "Epoch: 9, train_loss: 0.34880591, valid_loss: 0.36896953, time: [5.77], best model: 0\n",
      "Epoch: 10, train_loss: 0.34537807, valid_loss: 0.37439504, time: [5.72], best model: 0\n",
      "Epoch: 11, train_loss: 0.3412917, valid_loss: 0.37335935, time: [5.61], best model: 0\n",
      "Epoch: 12, train_loss: 0.33159591, valid_loss: 0.38509998, time: [5.66], best model: 0\n",
      "Epoch: 13, train_loss: 0.32773252, valid_loss: 0.38842315, time: [5.58], best model: 0\n",
      "Epoch: 14, train_loss: 0.31622013, valid_loss: 0.39345049, time: [5.65], best model: 0\n",
      "Early Stopped at Epoch: 15\n",
      "On sample 45 / 60 (hyperparams = {'cell_size': 123, 'hidden_size': 81, 'learning_rate': 0.008566366620637754, 'num_epochs': 68, 'patience': 9, 'batch_size': 256, 'early_stop_frac': 0.10341017000733373, 'seed': 6310})\n",
      "Model Structure:  GRUD(\n",
      "  (zl): Linear(in_features=289, out_features=81, bias=True)\n",
      "  (rl): Linear(in_features=289, out_features=81, bias=True)\n",
      "  (hl): Linear(in_features=289, out_features=81, bias=True)\n",
      "  (gamma_x_l): FilterLinear(in_features=104, out_features=104, bias=True)\n",
      "  (gamma_h_l): Linear(in_features=104, out_features=81, bias=True)\n",
      "  (fc): Linear(in_features=81, out_features=2, bias=True)\n",
      "  (bn): BatchNorm1d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (drop): Dropout(p=0.5, inplace=False)\n",
      ")\n",
      "Start Training ... \n",
      "Output type dermined by the model\n",
      "Epoch: 0, train_loss: 0.66262147, valid_loss: 0.62949457, time: [5.17], best model: 1\n",
      "Epoch: 1, train_loss: 0.45898549, valid_loss: 0.44302608, time: [4.98], best model: 1\n",
      "Epoch: 2, train_loss: 0.39992573, valid_loss: 0.3748878, time: [4.96], best model: 1\n",
      "Epoch: 3, train_loss: 0.37976837, valid_loss: 0.35677288, time: [4.98], best model: 1\n",
      "Epoch: 4, train_loss: 0.37035613, valid_loss: 0.34867214, time: [4.95], best model: 1\n",
      "Epoch: 5, train_loss: 0.37435949, valid_loss: 0.34030543, time: [4.97], best model: 1\n",
      "Epoch: 6, train_loss: 0.36439882, valid_loss: 0.33989683, time: [4.96], best model: 1\n",
      "Epoch: 7, train_loss: 0.35759992, valid_loss: 0.34078674, time: [4.92], best model: 0\n",
      "Epoch: 8, train_loss: 0.36238088, valid_loss: 0.34201237, time: [4.9], best model: 0\n",
      "Epoch: 9, train_loss: 0.3520395, valid_loss: 0.34256675, time: [4.95], best model: 0\n",
      "Epoch: 10, train_loss: 0.34293783, valid_loss: 0.34087079, time: [4.93], best model: 0\n",
      "Epoch: 11, train_loss: 0.33688831, valid_loss: 0.34096169, time: [4.95], best model: 0\n",
      "Epoch: 12, train_loss: 0.32586529, valid_loss: 0.3549122, time: [4.91], best model: 0\n",
      "Epoch: 13, train_loss: 0.31266854, valid_loss: 0.35690169, time: [4.91], best model: 0\n",
      "Epoch: 14, train_loss: 0.31226691, valid_loss: 0.35886097, time: [4.91], best model: 0\n",
      "Early Stopped at Epoch: 15\n",
      "On sample 46 / 60 (hyperparams = {'cell_size': 155, 'hidden_size': 123, 'learning_rate': 0.006350118605971565, 'num_epochs': 70, 'patience': 11, 'batch_size': 256, 'early_stop_frac': 0.054348969793627744, 'seed': 5768})\n",
      "Model Structure:  GRUD(\n",
      "  (zl): Linear(in_features=331, out_features=123, bias=True)\n",
      "  (rl): Linear(in_features=331, out_features=123, bias=True)\n",
      "  (hl): Linear(in_features=331, out_features=123, bias=True)\n",
      "  (gamma_x_l): FilterLinear(in_features=104, out_features=104, bias=True)\n",
      "  (gamma_h_l): Linear(in_features=104, out_features=123, bias=True)\n",
      "  (fc): Linear(in_features=123, out_features=2, bias=True)\n",
      "  (bn): BatchNorm1d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (drop): Dropout(p=0.5, inplace=False)\n",
      ")\n",
      "Start Training ... \n",
      "Output type dermined by the model\n",
      "Epoch: 0, train_loss: 0.66333702, valid_loss: 0.66478886, time: [5.45], best model: 1\n",
      "Epoch: 1, train_loss: 0.49735914, valid_loss: 0.48700254, time: [5.74], best model: 1\n",
      "Epoch: 2, train_loss: 0.41959659, valid_loss: 0.40711556, time: [5.7], best model: 1\n",
      "Epoch: 3, train_loss: 0.38314726, valid_loss: 0.38477485, time: [5.52], best model: 1\n",
      "Epoch: 4, train_loss: 0.37180972, valid_loss: 0.37110757, time: [5.65], best model: 1\n",
      "Epoch: 5, train_loss: 0.36626084, valid_loss: 0.3689296, time: [5.57], best model: 1\n",
      "Epoch: 6, train_loss: 0.36568785, valid_loss: 0.37247173, time: [5.53], best model: 0\n",
      "Epoch: 7, train_loss: 0.36265702, valid_loss: 0.37489281, time: [5.38], best model: 0\n",
      "Epoch: 8, train_loss: 0.35615508, valid_loss: 0.37387895, time: [5.36], best model: 0\n",
      "Epoch: 9, train_loss: 0.3549508, valid_loss: 0.37598485, time: [5.36], best model: 0\n",
      "Epoch: 10, train_loss: 0.34971162, valid_loss: 0.38351256, time: [5.39], best model: 0\n",
      "Epoch: 11, train_loss: 0.34250313, valid_loss: 0.38468592, time: [5.35], best model: 0\n",
      "Epoch: 12, train_loss: 0.33693845, valid_loss: 0.38399587, time: [5.37], best model: 0\n",
      "Epoch: 13, train_loss: 0.32976075, valid_loss: 0.39326352, time: [5.37], best model: 0\n",
      "Epoch: 14, train_loss: 0.3290844, valid_loss: 0.3946531, time: [5.41], best model: 0\n",
      "Epoch: 15, train_loss: 0.32718199, valid_loss: 0.41319847, time: [5.33], best model: 0\n",
      "Early Stopped at Epoch: 16\n",
      "On sample 47 / 60 (hyperparams = {'cell_size': 160, 'hidden_size': 86, 'learning_rate': 0.041515075846750384, 'num_epochs': 68, 'patience': 9, 'batch_size': 256, 'early_stop_frac': 0.07475508756225406, 'seed': 7741})\n",
      "Model Structure:  GRUD(\n",
      "  (zl): Linear(in_features=294, out_features=86, bias=True)\n",
      "  (rl): Linear(in_features=294, out_features=86, bias=True)\n",
      "  (hl): Linear(in_features=294, out_features=86, bias=True)\n",
      "  (gamma_x_l): FilterLinear(in_features=104, out_features=104, bias=True)\n",
      "  (gamma_h_l): Linear(in_features=104, out_features=86, bias=True)\n",
      "  (fc): Linear(in_features=86, out_features=2, bias=True)\n",
      "  (bn): BatchNorm1d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (drop): Dropout(p=0.5, inplace=False)\n",
      ")\n",
      "Start Training ... \n",
      "Output type dermined by the model\n",
      "Epoch: 0, train_loss: 0.45615625, valid_loss: 0.44759696, time: [5.16], best model: 1\n",
      "Epoch: 1, train_loss: 0.36915932, valid_loss: 0.37571166, time: [5.12], best model: 1\n",
      "Epoch: 2, train_loss: 0.36382456, valid_loss: 0.37720321, time: [5.11], best model: 0\n",
      "Epoch: 3, train_loss: 0.36311855, valid_loss: 0.37421433, time: [5.11], best model: 1\n",
      "Epoch: 4, train_loss: 0.36885074, valid_loss: 0.37782675, time: [5.13], best model: 0\n",
      "Epoch: 5, train_loss: 0.36116021, valid_loss: 0.37989286, time: [5.11], best model: 0\n",
      "Epoch: 6, train_loss: 0.36659549, valid_loss: 0.38400955, time: [5.11], best model: 0\n",
      "Epoch: 7, train_loss: 0.36531213, valid_loss: 0.37504047, time: [5.11], best model: 0\n",
      "Epoch: 8, train_loss: 0.37358885, valid_loss: 0.38253371, time: [5.12], best model: 0\n",
      "Epoch: 9, train_loss: 0.36857595, valid_loss: 0.38658514, time: [5.11], best model: 0\n",
      "Epoch: 10, train_loss: 0.36911167, valid_loss: 0.39228919, time: [5.16], best model: 0\n",
      "Epoch: 11, train_loss: 0.36131776, valid_loss: 0.38715941, time: [5.12], best model: 0\n",
      "Early Stopped at Epoch: 12\n",
      "On sample 48 / 60 (hyperparams = {'cell_size': 133, 'hidden_size': 157, 'learning_rate': 0.06884270460160578, 'num_epochs': 106, 'patience': 8, 'batch_size': 512, 'early_stop_frac': 0.14431707226672083, 'seed': 4586})\n",
      "Model Structure:  GRUD(\n",
      "  (zl): Linear(in_features=365, out_features=157, bias=True)\n",
      "  (rl): Linear(in_features=365, out_features=157, bias=True)\n",
      "  (hl): Linear(in_features=365, out_features=157, bias=True)\n",
      "  (gamma_x_l): FilterLinear(in_features=104, out_features=104, bias=True)\n",
      "  (gamma_h_l): Linear(in_features=104, out_features=157, bias=True)\n",
      "  (fc): Linear(in_features=157, out_features=2, bias=True)\n",
      "  (bn): BatchNorm1d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (drop): Dropout(p=0.5, inplace=False)\n",
      ")\n",
      "Start Training ... \n",
      "Output type dermined by the model\n",
      "Epoch: 0, train_loss: 0.48543085, valid_loss: 0.46323674, time: [3.8], best model: 1\n",
      "Epoch: 1, train_loss: 0.40270547, valid_loss: 0.40543859, time: [3.71], best model: 1\n",
      "Epoch: 2, train_loss: 0.39557549, valid_loss: 0.40849829, time: [3.74], best model: 0\n",
      "Epoch: 3, train_loss: 0.37464939, valid_loss: 0.39351187, time: [3.66], best model: 1\n",
      "Epoch: 4, train_loss: 0.38328392, valid_loss: 0.38450588, time: [3.74], best model: 1\n",
      "Epoch: 5, train_loss: 0.37182522, valid_loss: 0.39078144, time: [3.71], best model: 0\n",
      "Epoch: 6, train_loss: 0.36516534, valid_loss: 0.38649191, time: [3.68], best model: 0\n",
      "Epoch: 7, train_loss: 0.37749652, valid_loss: 0.38908666, time: [3.7], best model: 0\n",
      "Epoch: 8, train_loss: 0.3713993, valid_loss: 0.38632655, time: [3.72], best model: 0\n",
      "Epoch: 9, train_loss: 0.37393693, valid_loss: 0.3817046, time: [3.67], best model: 1\n",
      "Epoch: 10, train_loss: 0.37000012, valid_loss: 0.39319706, time: [3.74], best model: 0\n",
      "Epoch: 11, train_loss: 0.35532723, valid_loss: 0.38217235, time: [3.81], best model: 0\n",
      "Epoch: 12, train_loss: 0.36252935, valid_loss: 0.39269921, time: [3.74], best model: 0\n",
      "Epoch: 13, train_loss: 0.36481524, valid_loss: 0.39414474, time: [3.72], best model: 0\n",
      "Epoch: 14, train_loss: 0.35663704, valid_loss: 0.3901575, time: [3.71], best model: 0\n",
      "Epoch: 15, train_loss: 0.3615552, valid_loss: 0.39944346, time: [3.84], best model: 0\n",
      "Epoch: 16, train_loss: 0.35672787, valid_loss: 0.39235892, time: [3.68], best model: 0\n",
      "Early Stopped at Epoch: 17\n",
      "On sample 49 / 60 (hyperparams = {'cell_size': 146, 'hidden_size': 116, 'learning_rate': 0.02180271118161696, 'num_epochs': 95, 'patience': 10, 'batch_size': 128, 'early_stop_frac': 0.10568601662432534, 'seed': 7836})\n",
      "Model Structure:  GRUD(\n",
      "  (zl): Linear(in_features=324, out_features=116, bias=True)\n",
      "  (rl): Linear(in_features=324, out_features=116, bias=True)\n",
      "  (hl): Linear(in_features=324, out_features=116, bias=True)\n",
      "  (gamma_x_l): FilterLinear(in_features=104, out_features=104, bias=True)\n",
      "  (gamma_h_l): Linear(in_features=104, out_features=116, bias=True)\n",
      "  (fc): Linear(in_features=116, out_features=2, bias=True)\n",
      "  (bn): BatchNorm1d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (drop): Dropout(p=0.5, inplace=False)\n",
      ")\n",
      "Start Training ... \n",
      "Output type dermined by the model\n",
      "Epoch: 0, train_loss: 0.45853881, valid_loss: 0.44002478, time: [8.55], best model: 1\n",
      "Epoch: 1, train_loss: 0.37798185, valid_loss: 0.36463244, time: [8.45], best model: 1\n",
      "Epoch: 2, train_loss: 0.37234885, valid_loss: 0.34991612, time: [8.48], best model: 1\n",
      "Epoch: 3, train_loss: 0.36901513, valid_loss: 0.35360033, time: [8.43], best model: 0\n",
      "Epoch: 4, train_loss: 0.37116453, valid_loss: 0.3532649, time: [8.48], best model: 0\n",
      "Epoch: 5, train_loss: 0.36848287, valid_loss: 0.3543737, time: [8.47], best model: 0\n",
      "Epoch: 6, train_loss: 0.3665195, valid_loss: 0.35956492, time: [8.42], best model: 0\n",
      "Epoch: 7, train_loss: 0.35408548, valid_loss: 0.3530381, time: [8.41], best model: 0\n",
      "Epoch: 8, train_loss: 0.37064632, valid_loss: 0.35323846, time: [8.34], best model: 0\n",
      "Epoch: 9, train_loss: 0.36259783, valid_loss: 0.35518379, time: [8.39], best model: 0\n",
      "Epoch: 10, train_loss: 0.36071132, valid_loss: 0.34986281, time: [8.86], best model: 1\n",
      "Epoch: 11, train_loss: 0.36417298, valid_loss: 0.35510948, time: [8.71], best model: 0\n",
      "Epoch: 12, train_loss: 0.35739534, valid_loss: 0.35789842, time: [8.36], best model: 0\n",
      "Epoch: 13, train_loss: 0.3583883, valid_loss: 0.36288005, time: [8.61], best model: 0\n",
      "Epoch: 14, train_loss: 0.35567142, valid_loss: 0.36343482, time: [8.55], best model: 0\n",
      "Epoch: 15, train_loss: 0.36478, valid_loss: 0.36124769, time: [8.43], best model: 0\n",
      "Epoch: 16, train_loss: 0.36205295, valid_loss: 0.35460832, time: [8.49], best model: 0\n",
      "Epoch: 17, train_loss: 0.36759013, valid_loss: 0.35553686, time: [8.49], best model: 0\n",
      "Epoch: 18, train_loss: 0.35840786, valid_loss: 0.35909314, time: [9.08], best model: 0\n",
      "Epoch: 19, train_loss: 0.35966554, valid_loss: 0.35523794, time: [8.8], best model: 0\n",
      "Early Stopped at Epoch: 20\n",
      "On sample 50 / 60 (hyperparams = {'cell_size': 93, 'hidden_size': 162, 'learning_rate': 0.08962664517041591, 'num_epochs': 138, 'patience': 8, 'batch_size': 256, 'early_stop_frac': 0.08575182323552322, 'seed': 2695})\n",
      "Model Structure:  GRUD(\n",
      "  (zl): Linear(in_features=370, out_features=162, bias=True)\n",
      "  (rl): Linear(in_features=370, out_features=162, bias=True)\n",
      "  (hl): Linear(in_features=370, out_features=162, bias=True)\n",
      "  (gamma_x_l): FilterLinear(in_features=104, out_features=104, bias=True)\n",
      "  (gamma_h_l): Linear(in_features=104, out_features=162, bias=True)\n",
      "  (fc): Linear(in_features=162, out_features=2, bias=True)\n",
      "  (bn): BatchNorm1d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (drop): Dropout(p=0.5, inplace=False)\n",
      ")\n",
      "Start Training ... \n",
      "Output type dermined by the model\n",
      "Epoch: 0, train_loss: 0.42517859, valid_loss: 0.44055163, time: [6.7], best model: 1\n",
      "Epoch: 1, train_loss: 0.38050167, valid_loss: 0.40925647, time: [6.61], best model: 1\n",
      "Epoch: 2, train_loss: 0.3762036, valid_loss: 0.40569955, time: [6.95], best model: 1\n",
      "Epoch: 3, train_loss: 0.38216536, valid_loss: 0.40604456, time: [7.69], best model: 0\n",
      "Epoch: 4, train_loss: 0.38031872, valid_loss: 0.41475225, time: [7.01], best model: 0\n",
      "Epoch: 5, train_loss: 0.38374474, valid_loss: 0.41528123, time: [6.82], best model: 0\n",
      "Epoch: 6, train_loss: 0.37245605, valid_loss: 0.40293603, time: [6.87], best model: 1\n",
      "Epoch: 7, train_loss: 0.3827558, valid_loss: 0.40718945, time: [6.98], best model: 0\n",
      "Epoch: 8, train_loss: 0.3839701, valid_loss: 0.3983634, time: [6.81], best model: 1\n",
      "Epoch: 9, train_loss: 0.38639337, valid_loss: 0.4096155, time: [7.02], best model: 0\n",
      "Epoch: 10, train_loss: 0.37798258, valid_loss: 0.4087183, time: [6.95], best model: 0\n",
      "Epoch: 11, train_loss: 0.38015288, valid_loss: 0.40874526, time: [7.22], best model: 0\n",
      "Epoch: 12, train_loss: 0.36997265, valid_loss: 0.40567356, time: [7.07], best model: 0\n",
      "Epoch: 13, train_loss: 0.37690195, valid_loss: 0.40203689, time: [6.98], best model: 0\n",
      "Epoch: 14, train_loss: 0.36898849, valid_loss: 0.40706114, time: [7.16], best model: 0\n",
      "Epoch: 15, train_loss: 0.37117402, valid_loss: 0.4046101, time: [7.15], best model: 0\n",
      "Early Stopped at Epoch: 16\n",
      "On sample 51 / 60 (hyperparams = {'cell_size': 82, 'hidden_size': 73, 'learning_rate': 0.04523890954448474, 'num_epochs': 139, 'patience': 10, 'batch_size': 64, 'early_stop_frac': 0.05094503741378993, 'seed': 7921})\n",
      "Model Structure:  GRUD(\n",
      "  (zl): Linear(in_features=281, out_features=73, bias=True)\n",
      "  (rl): Linear(in_features=281, out_features=73, bias=True)\n",
      "  (hl): Linear(in_features=281, out_features=73, bias=True)\n",
      "  (gamma_x_l): FilterLinear(in_features=104, out_features=104, bias=True)\n",
      "  (gamma_h_l): Linear(in_features=104, out_features=73, bias=True)\n",
      "  (fc): Linear(in_features=73, out_features=2, bias=True)\n",
      "  (bn): BatchNorm1d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (drop): Dropout(p=0.5, inplace=False)\n",
      ")\n",
      "Start Training ... \n",
      "Output type dermined by the model\n",
      "Epoch: 0, train_loss: 0.40157537, valid_loss: 0.38824952, time: [23.31], best model: 1\n",
      "Epoch: 1, train_loss: 0.38283004, valid_loss: 0.37273936, time: [39.22], best model: 1\n",
      "Epoch: 2, train_loss: 0.38384388, valid_loss: 0.36751584, time: [39.25], best model: 1\n",
      "Epoch: 3, train_loss: 0.37984537, valid_loss: 0.36236535, time: [39.26], best model: 1\n",
      "Epoch: 4, train_loss: 0.37633284, valid_loss: 0.37073175, time: [34.52], best model: 0\n",
      "Epoch: 5, train_loss: 0.3790354, valid_loss: 0.36599624, time: [20.74], best model: 0\n",
      "Epoch: 6, train_loss: 0.37812756, valid_loss: 0.36285579, time: [14.61], best model: 0\n",
      "Epoch: 7, train_loss: 0.37812371, valid_loss: 0.36580095, time: [14.83], best model: 0\n",
      "Epoch: 8, train_loss: 0.36749606, valid_loss: 0.36517771, time: [14.59], best model: 0\n",
      "Epoch: 9, train_loss: 0.37487408, valid_loss: 0.36039054, time: [14.82], best model: 1\n",
      "Epoch: 10, train_loss: 0.37515671, valid_loss: 0.36745825, time: [14.49], best model: 0\n",
      "Epoch: 11, train_loss: 0.37489396, valid_loss: 0.36748757, time: [14.65], best model: 0\n",
      "Epoch: 12, train_loss: 0.37374736, valid_loss: 0.3611668, time: [14.49], best model: 0\n",
      "Epoch: 13, train_loss: 0.37666222, valid_loss: 0.36808072, time: [14.57], best model: 0\n",
      "Epoch: 14, train_loss: 0.37494752, valid_loss: 0.35914741, time: [14.61], best model: 1\n",
      "Epoch: 15, train_loss: 0.3756584, valid_loss: 0.35936211, time: [14.66], best model: 0\n",
      "Epoch: 16, train_loss: 0.37058763, valid_loss: 0.36935702, time: [14.7], best model: 0\n",
      "Epoch: 17, train_loss: 0.37380729, valid_loss: 0.36319806, time: [14.89], best model: 0\n",
      "Epoch: 18, train_loss: 0.37359238, valid_loss: 0.36547421, time: [15.43], best model: 0\n",
      "Epoch: 19, train_loss: 0.37274724, valid_loss: 0.36280103, time: [14.84], best model: 0\n",
      "Epoch: 20, train_loss: 0.37399354, valid_loss: 0.36454733, time: [14.67], best model: 0\n",
      "Epoch: 21, train_loss: 0.36964081, valid_loss: 0.35111744, time: [14.76], best model: 1\n",
      "Epoch: 22, train_loss: 0.36658496, valid_loss: 0.36205436, time: [14.97], best model: 0\n",
      "Epoch: 23, train_loss: 0.37253537, valid_loss: 0.35899793, time: [14.72], best model: 0\n",
      "Epoch: 24, train_loss: 0.3704339, valid_loss: 0.35602114, time: [14.83], best model: 0\n",
      "Epoch: 25, train_loss: 0.37019988, valid_loss: 0.35852715, time: [14.74], best model: 0\n",
      "Epoch: 26, train_loss: 0.37224151, valid_loss: 0.35903205, time: [14.63], best model: 0\n",
      "Epoch: 27, train_loss: 0.37048374, valid_loss: 0.36318358, time: [14.8], best model: 0\n",
      "Epoch: 28, train_loss: 0.37384805, valid_loss: 0.36714446, time: [14.93], best model: 0\n",
      "Epoch: 29, train_loss: 0.37093676, valid_loss: 0.36900231, time: [15.24], best model: 0\n",
      "Epoch: 30, train_loss: 0.36817292, valid_loss: 0.36484488, time: [17.47], best model: 0\n",
      "Early Stopped at Epoch: 31\n",
      "On sample 52 / 60 (hyperparams = {'cell_size': 76, 'hidden_size': 172, 'learning_rate': 0.06396414637099647, 'num_epochs': 114, 'patience': 11, 'batch_size': 256, 'early_stop_frac': 0.0753548267224923, 'seed': 1139})\n",
      "Model Structure:  GRUD(\n",
      "  (zl): Linear(in_features=380, out_features=172, bias=True)\n",
      "  (rl): Linear(in_features=380, out_features=172, bias=True)\n",
      "  (hl): Linear(in_features=380, out_features=172, bias=True)\n",
      "  (gamma_x_l): FilterLinear(in_features=104, out_features=104, bias=True)\n",
      "  (gamma_h_l): Linear(in_features=104, out_features=172, bias=True)\n",
      "  (fc): Linear(in_features=172, out_features=2, bias=True)\n",
      "  (bn): BatchNorm1d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (drop): Dropout(p=0.5, inplace=False)\n",
      ")\n",
      "Start Training ... \n",
      "Output type dermined by the model\n",
      "Epoch: 0, train_loss: 0.44140272, valid_loss: 0.4072807, time: [6.48], best model: 1\n",
      "Epoch: 1, train_loss: 0.38503326, valid_loss: 0.3583533, time: [6.42], best model: 1\n",
      "Epoch: 2, train_loss: 0.37710698, valid_loss: 0.35488726, time: [6.31], best model: 1\n",
      "Epoch: 3, train_loss: 0.38122473, valid_loss: 0.35594371, time: [6.81], best model: 0\n",
      "Epoch: 4, train_loss: 0.3706433, valid_loss: 0.36271652, time: [6.55], best model: 0\n",
      "Epoch: 5, train_loss: 0.37788048, valid_loss: 0.36343625, time: [6.41], best model: 0\n",
      "Epoch: 6, train_loss: 0.38663104, valid_loss: 0.35924632, time: [6.51], best model: 0\n",
      "Epoch: 7, train_loss: 0.37843075, valid_loss: 0.35924444, time: [6.42], best model: 0\n",
      "Epoch: 8, train_loss: 0.38351145, valid_loss: 0.36000913, time: [6.5], best model: 0\n",
      "Epoch: 9, train_loss: 0.3808548, valid_loss: 0.36059904, time: [6.7], best model: 0\n",
      "Epoch: 10, train_loss: 0.38437316, valid_loss: 0.36368786, time: [6.52], best model: 0\n",
      "Epoch: 11, train_loss: 0.38386453, valid_loss: 0.36109215, time: [6.71], best model: 0\n",
      "Epoch: 12, train_loss: 0.3806606, valid_loss: 0.36211484, time: [6.39], best model: 0\n",
      "Epoch: 13, train_loss: 0.38278602, valid_loss: 0.35083663, time: [6.51], best model: 1\n",
      "Epoch: 14, train_loss: 0.37350496, valid_loss: 0.35487947, time: [6.46], best model: 0\n",
      "Epoch: 15, train_loss: 0.37861408, valid_loss: 0.36307433, time: [6.35], best model: 0\n",
      "Epoch: 16, train_loss: 0.38900649, valid_loss: 0.35582387, time: [6.69], best model: 0\n",
      "Epoch: 17, train_loss: 0.38028018, valid_loss: 0.36476876, time: [6.84], best model: 0\n",
      "Epoch: 18, train_loss: 0.37800372, valid_loss: 0.36143684, time: [6.77], best model: 0\n",
      "Epoch: 19, train_loss: 0.36718108, valid_loss: 0.35591269, time: [6.8], best model: 0\n",
      "Epoch: 20, train_loss: 0.37442973, valid_loss: 0.35405248, time: [6.59], best model: 0\n",
      "Epoch: 21, train_loss: 0.37272698, valid_loss: 0.35712611, time: [6.55], best model: 0\n",
      "Epoch: 22, train_loss: 0.38074748, valid_loss: 0.35256872, time: [6.65], best model: 0\n",
      "Epoch: 23, train_loss: 0.37936319, valid_loss: 0.35601486, time: [6.49], best model: 0\n",
      "Early Stopped at Epoch: 24\n",
      "On sample 53 / 60 (hyperparams = {'cell_size': 186, 'hidden_size': 151, 'learning_rate': 0.031042674293498843, 'num_epochs': 109, 'patience': 11, 'batch_size': 64, 'early_stop_frac': 0.07542266901505368, 'seed': 3079})\n",
      "Model Structure:  GRUD(\n",
      "  (zl): Linear(in_features=359, out_features=151, bias=True)\n",
      "  (rl): Linear(in_features=359, out_features=151, bias=True)\n",
      "  (hl): Linear(in_features=359, out_features=151, bias=True)\n",
      "  (gamma_x_l): FilterLinear(in_features=104, out_features=104, bias=True)\n",
      "  (gamma_h_l): Linear(in_features=104, out_features=151, bias=True)\n",
      "  (fc): Linear(in_features=151, out_features=2, bias=True)\n",
      "  (bn): BatchNorm1d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (drop): Dropout(p=0.5, inplace=False)\n",
      ")\n",
      "Start Training ... \n",
      "Output type dermined by the model\n",
      "Epoch: 0, train_loss: 0.40669809, valid_loss: 0.40366417, time: [15.74], best model: 1\n",
      "Epoch: 1, train_loss: 0.38359344, valid_loss: 0.38376684, time: [15.71], best model: 1\n",
      "Epoch: 2, train_loss: 0.38035886, valid_loss: 0.37912129, time: [15.8], best model: 1\n",
      "Epoch: 3, train_loss: 0.37413835, valid_loss: 0.3807653, time: [15.6], best model: 0\n",
      "Epoch: 4, train_loss: 0.38244805, valid_loss: 0.38303025, time: [15.87], best model: 0\n",
      "Epoch: 5, train_loss: 0.37029638, valid_loss: 0.38146579, time: [16.55], best model: 0\n",
      "Epoch: 6, train_loss: 0.37178758, valid_loss: 0.38009997, time: [16.71], best model: 0\n",
      "Epoch: 7, train_loss: 0.37471828, valid_loss: 0.3785104, time: [16.24], best model: 1\n",
      "Epoch: 8, train_loss: 0.38018159, valid_loss: 0.38572614, time: [16.55], best model: 0\n",
      "Epoch: 9, train_loss: 0.37776219, valid_loss: 0.38136868, time: [16.08], best model: 0\n",
      "Epoch: 10, train_loss: 0.37726208, valid_loss: 0.38654674, time: [16.22], best model: 0\n",
      "Epoch: 11, train_loss: 0.37071165, valid_loss: 0.38378585, time: [16.24], best model: 0\n",
      "Epoch: 12, train_loss: 0.37545682, valid_loss: 0.38330302, time: [16.07], best model: 0\n",
      "Epoch: 13, train_loss: 0.37461065, valid_loss: 0.38324035, time: [16.16], best model: 0\n",
      "Epoch: 14, train_loss: 0.37301942, valid_loss: 0.38366043, time: [16.26], best model: 0\n",
      "Epoch: 15, train_loss: 0.3748663, valid_loss: 0.38521529, time: [16.12], best model: 0\n",
      "Epoch: 16, train_loss: 0.37252013, valid_loss: 0.38357724, time: [16.56], best model: 0\n",
      "Epoch: 17, train_loss: 0.37439018, valid_loss: 0.38517169, time: [16.25], best model: 0\n",
      "Early Stopped at Epoch: 18\n",
      "On sample 54 / 60 (hyperparams = {'cell_size': 126, 'hidden_size': 153, 'learning_rate': 0.06352545734642763, 'num_epochs': 66, 'patience': 9, 'batch_size': 512, 'early_stop_frac': 0.06706855260340261, 'seed': 5773})\n",
      "Model Structure:  GRUD(\n",
      "  (zl): Linear(in_features=361, out_features=153, bias=True)\n",
      "  (rl): Linear(in_features=361, out_features=153, bias=True)\n",
      "  (hl): Linear(in_features=361, out_features=153, bias=True)\n",
      "  (gamma_x_l): FilterLinear(in_features=104, out_features=104, bias=True)\n",
      "  (gamma_h_l): Linear(in_features=104, out_features=153, bias=True)\n",
      "  (fc): Linear(in_features=153, out_features=2, bias=True)\n",
      "  (bn): BatchNorm1d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (drop): Dropout(p=0.5, inplace=False)\n",
      ")\n",
      "Start Training ... \n",
      "Output type dermined by the model\n",
      "Epoch: 0, train_loss: 0.49558115, valid_loss: 0.45258439, time: [4.76], best model: 1\n",
      "Epoch: 1, train_loss: 0.39822267, valid_loss: 0.37622541, time: [4.72], best model: 1\n",
      "Epoch: 2, train_loss: 0.39767405, valid_loss: 0.37465111, time: [4.71], best model: 1\n",
      "Epoch: 3, train_loss: 0.39278564, valid_loss: 0.3712512, time: [4.74], best model: 1\n",
      "Epoch: 4, train_loss: 0.38455578, valid_loss: 0.36690299, time: [4.65], best model: 1\n",
      "Epoch: 5, train_loss: 0.37618961, valid_loss: 0.36430677, time: [4.67], best model: 1\n",
      "Epoch: 6, train_loss: 0.36737512, valid_loss: 0.3569918, time: [4.72], best model: 1\n",
      "Epoch: 7, train_loss: 0.37538627, valid_loss: 0.35633974, time: [4.68], best model: 1\n",
      "Epoch: 8, train_loss: 0.36195583, valid_loss: 0.35659974, time: [4.67], best model: 0\n",
      "Epoch: 9, train_loss: 0.37059771, valid_loss: 0.36212425, time: [4.79], best model: 0\n",
      "Epoch: 10, train_loss: 0.36897764, valid_loss: 0.36634684, time: [4.65], best model: 0\n",
      "Epoch: 11, train_loss: 0.36795238, valid_loss: 0.36040087, time: [4.72], best model: 0\n",
      "Epoch: 12, train_loss: 0.35567268, valid_loss: 0.36516708, time: [4.86], best model: 0\n",
      "Epoch: 13, train_loss: 0.36306744, valid_loss: 0.35980759, time: [4.66], best model: 0\n",
      "Epoch: 14, train_loss: 0.36051696, valid_loss: 0.35701841, time: [4.71], best model: 0\n",
      "Epoch: 15, train_loss: 0.36077042, valid_loss: 0.36338902, time: [4.91], best model: 0\n",
      "Early Stopped at Epoch: 16\n",
      "On sample 55 / 60 (hyperparams = {'cell_size': 188, 'hidden_size': 176, 'learning_rate': 0.09736599623823228, 'num_epochs': 109, 'patience': 9, 'batch_size': 512, 'early_stop_frac': 0.08449799596771912, 'seed': 5471})\n",
      "Model Structure:  GRUD(\n",
      "  (zl): Linear(in_features=384, out_features=176, bias=True)\n",
      "  (rl): Linear(in_features=384, out_features=176, bias=True)\n",
      "  (hl): Linear(in_features=384, out_features=176, bias=True)\n",
      "  (gamma_x_l): FilterLinear(in_features=104, out_features=104, bias=True)\n",
      "  (gamma_h_l): Linear(in_features=104, out_features=176, bias=True)\n",
      "  (fc): Linear(in_features=176, out_features=2, bias=True)\n",
      "  (bn): BatchNorm1d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (drop): Dropout(p=0.5, inplace=False)\n",
      ")\n",
      "Start Training ... \n",
      "Output type dermined by the model\n",
      "Epoch: 0, train_loss: 0.47520927, valid_loss: 0.45132545, time: [4.42], best model: 1\n",
      "Epoch: 1, train_loss: 0.40309377, valid_loss: 0.41142381, time: [4.57], best model: 1\n",
      "Epoch: 2, train_loss: 0.38981231, valid_loss: 0.40626871, time: [4.47], best model: 1\n",
      "Epoch: 3, train_loss: 0.3916772, valid_loss: 0.40537976, time: [4.38], best model: 1\n",
      "Epoch: 4, train_loss: 0.39082623, valid_loss: 0.40906844, time: [4.74], best model: 0\n",
      "Epoch: 5, train_loss: 0.39422048, valid_loss: 0.39906101, time: [5.6], best model: 1\n",
      "Epoch: 6, train_loss: 0.39491782, valid_loss: 0.40239143, time: [5.12], best model: 0\n",
      "Epoch: 7, train_loss: 0.38989613, valid_loss: 0.40217834, time: [5.8], best model: 0\n",
      "Epoch: 8, train_loss: 0.38211563, valid_loss: 0.39366433, time: [5.58], best model: 1\n",
      "Epoch: 9, train_loss: 0.37421996, valid_loss: 0.38793209, time: [4.91], best model: 1\n",
      "Epoch: 10, train_loss: 0.37753217, valid_loss: 0.3843047, time: [4.66], best model: 1\n",
      "Epoch: 11, train_loss: 0.38129451, valid_loss: 0.39199596, time: [4.92], best model: 0\n",
      "Epoch: 12, train_loss: 0.37685085, valid_loss: 0.39242587, time: [5.18], best model: 0\n",
      "Epoch: 13, train_loss: 0.38223457, valid_loss: 0.39326931, time: [5.53], best model: 0\n",
      "Epoch: 14, train_loss: 0.37117652, valid_loss: 0.39674736, time: [5.29], best model: 0\n",
      "Epoch: 15, train_loss: 0.37312041, valid_loss: 0.38948115, time: [5.04], best model: 0\n",
      "Epoch: 16, train_loss: 0.3798614, valid_loss: 0.38918051, time: [4.84], best model: 0\n",
      "Epoch: 17, train_loss: 0.37656656, valid_loss: 0.40105613, time: [4.96], best model: 0\n",
      "Epoch: 18, train_loss: 0.37746867, valid_loss: 0.38896669, time: [4.99], best model: 0\n",
      "Early Stopped at Epoch: 19\n",
      "On sample 56 / 60 (hyperparams = {'cell_size': 90, 'hidden_size': 66, 'learning_rate': 0.04680147165240897, 'num_epochs': 89, 'patience': 11, 'batch_size': 512, 'early_stop_frac': 0.07026490513477239, 'seed': 2678})\n",
      "Model Structure:  GRUD(\n",
      "  (zl): Linear(in_features=274, out_features=66, bias=True)\n",
      "  (rl): Linear(in_features=274, out_features=66, bias=True)\n",
      "  (hl): Linear(in_features=274, out_features=66, bias=True)\n",
      "  (gamma_x_l): FilterLinear(in_features=104, out_features=104, bias=True)\n",
      "  (gamma_h_l): Linear(in_features=104, out_features=66, bias=True)\n",
      "  (fc): Linear(in_features=66, out_features=2, bias=True)\n",
      "  (bn): BatchNorm1d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (drop): Dropout(p=0.5, inplace=False)\n",
      ")\n",
      "Start Training ... \n",
      "Output type dermined by the model\n",
      "Epoch: 0, train_loss: 0.50822655, valid_loss: 0.50090952, time: [5.07], best model: 1\n",
      "Epoch: 1, train_loss: 0.37813899, valid_loss: 0.38813238, time: [4.95], best model: 1\n",
      "Epoch: 2, train_loss: 0.37052542, valid_loss: 0.38178161, time: [4.61], best model: 1\n",
      "Epoch: 3, train_loss: 0.36304798, valid_loss: 0.38226576, time: [4.52], best model: 0\n",
      "Epoch: 4, train_loss: 0.35507669, valid_loss: 0.37747154, time: [4.67], best model: 1\n",
      "Epoch: 5, train_loss: 0.35753441, valid_loss: 0.37819579, time: [4.82], best model: 0\n",
      "Epoch: 6, train_loss: 0.35955362, valid_loss: 0.3860823, time: [4.65], best model: 0\n",
      "Epoch: 7, train_loss: 0.358732, valid_loss: 0.38043372, time: [4.58], best model: 0\n",
      "Epoch: 8, train_loss: 0.35233905, valid_loss: 0.37810243, time: [4.68], best model: 0\n",
      "Epoch: 9, train_loss: 0.35628688, valid_loss: 0.38989951, time: [4.88], best model: 0\n",
      "Epoch: 10, train_loss: 0.35919628, valid_loss: 0.38593661, time: [4.73], best model: 0\n",
      "Epoch: 11, train_loss: 0.36577307, valid_loss: 0.38339793, time: [4.53], best model: 0\n",
      "Epoch: 12, train_loss: 0.36276925, valid_loss: 0.37557236, time: [4.65], best model: 1\n",
      "Epoch: 13, train_loss: 0.34911677, valid_loss: 0.37500661, time: [4.75], best model: 1\n",
      "Epoch: 14, train_loss: 0.3561003, valid_loss: 0.390603, time: [4.66], best model: 0\n",
      "Epoch: 15, train_loss: 0.3577096, valid_loss: 0.3808232, time: [4.54], best model: 0\n",
      "Epoch: 16, train_loss: 0.3494675, valid_loss: 0.38757261, time: [4.72], best model: 0\n",
      "Epoch: 17, train_loss: 0.35683626, valid_loss: 0.40378669, time: [4.66], best model: 0\n",
      "Epoch: 18, train_loss: 0.35675131, valid_loss: 0.39777222, time: [4.75], best model: 0\n",
      "Epoch: 19, train_loss: 0.34909668, valid_loss: 0.38830563, time: [4.9], best model: 0\n",
      "Epoch: 20, train_loss: 0.34501699, valid_loss: 0.4080225, time: [4.91], best model: 0\n",
      "Epoch: 21, train_loss: 0.33876292, valid_loss: 0.41226384, time: [4.96], best model: 0\n",
      "Epoch: 22, train_loss: 0.34162283, valid_loss: 0.3952404, time: [4.76], best model: 0\n",
      "Epoch: 23, train_loss: 0.33644689, valid_loss: 0.40680447, time: [5.04], best model: 0\n",
      "Early Stopped at Epoch: 24\n",
      "On sample 57 / 60 (hyperparams = {'cell_size': 84, 'hidden_size': 124, 'learning_rate': 0.022704983825331426, 'num_epochs': 94, 'patience': 8, 'batch_size': 64, 'early_stop_frac': 0.056290154018084106, 'seed': 3051})\n",
      "Model Structure:  GRUD(\n",
      "  (zl): Linear(in_features=332, out_features=124, bias=True)\n",
      "  (rl): Linear(in_features=332, out_features=124, bias=True)\n",
      "  (hl): Linear(in_features=332, out_features=124, bias=True)\n",
      "  (gamma_x_l): FilterLinear(in_features=104, out_features=104, bias=True)\n",
      "  (gamma_h_l): Linear(in_features=104, out_features=124, bias=True)\n",
      "  (fc): Linear(in_features=124, out_features=2, bias=True)\n",
      "  (bn): BatchNorm1d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (drop): Dropout(p=0.5, inplace=False)\n",
      ")\n",
      "Start Training ... \n",
      "Output type dermined by the model\n",
      "Epoch: 0, train_loss: 0.41693467, valid_loss: 0.40114331, time: [18.7], best model: 1\n",
      "Epoch: 1, train_loss: 0.37646179, valid_loss: 0.36682731, time: [18.59], best model: 1\n",
      "Epoch: 2, train_loss: 0.37147114, valid_loss: 0.36279461, time: [18.78], best model: 1\n",
      "Epoch: 3, train_loss: 0.38270467, valid_loss: 0.37103695, time: [18.9], best model: 0\n",
      "Epoch: 4, train_loss: 0.37630444, valid_loss: 0.36580624, time: [18.89], best model: 0\n",
      "Epoch: 5, train_loss: 0.37124285, valid_loss: 0.36813388, time: [18.72], best model: 0\n",
      "Epoch: 6, train_loss: 0.38094654, valid_loss: 0.36481726, time: [18.37], best model: 0\n",
      "Epoch: 7, train_loss: 0.37277574, valid_loss: 0.36484299, time: [18.58], best model: 0\n",
      "Epoch: 8, train_loss: 0.36948089, valid_loss: 0.36525658, time: [18.87], best model: 0\n",
      "Epoch: 9, train_loss: 0.37003592, valid_loss: 0.36986452, time: [18.57], best model: 0\n",
      "Early Stopped at Epoch: 10\n",
      "On sample 58 / 60 (hyperparams = {'cell_size': 110, 'hidden_size': 128, 'learning_rate': 0.04453672919053865, 'num_epochs': 114, 'patience': 11, 'batch_size': 64, 'early_stop_frac': 0.059796039588625866, 'seed': 6894})\n",
      "Model Structure:  GRUD(\n",
      "  (zl): Linear(in_features=336, out_features=128, bias=True)\n",
      "  (rl): Linear(in_features=336, out_features=128, bias=True)\n",
      "  (hl): Linear(in_features=336, out_features=128, bias=True)\n",
      "  (gamma_x_l): FilterLinear(in_features=104, out_features=104, bias=True)\n",
      "  (gamma_h_l): Linear(in_features=104, out_features=128, bias=True)\n",
      "  (fc): Linear(in_features=128, out_features=2, bias=True)\n",
      "  (bn): BatchNorm1d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (drop): Dropout(p=0.5, inplace=False)\n",
      ")\n",
      "Start Training ... \n",
      "Output type dermined by the model\n",
      "Epoch: 0, train_loss: 0.40729653, valid_loss: 0.39461573, time: [18.11], best model: 1\n",
      "Epoch: 1, train_loss: 0.3862113, valid_loss: 0.37647281, time: [17.73], best model: 1\n",
      "Epoch: 2, train_loss: 0.38088295, valid_loss: 0.36920715, time: [18.31], best model: 1\n",
      "Epoch: 3, train_loss: 0.37902841, valid_loss: 0.37385758, time: [18.86], best model: 0\n",
      "Epoch: 4, train_loss: 0.37184196, valid_loss: 0.37115265, time: [18.82], best model: 0\n",
      "Epoch: 5, train_loss: 0.37938464, valid_loss: 0.37396333, time: [18.56], best model: 0\n",
      "Epoch: 6, train_loss: 0.37789843, valid_loss: 0.37678342, time: [18.66], best model: 0\n",
      "Epoch: 7, train_loss: 0.37500763, valid_loss: 0.37784186, time: [18.51], best model: 0\n",
      "Epoch: 8, train_loss: 0.37379942, valid_loss: 0.3841099, time: [18.42], best model: 0\n",
      "Epoch: 9, train_loss: 0.37657029, valid_loss: 0.37384145, time: [18.4], best model: 0\n",
      "Epoch: 10, train_loss: 0.38182651, valid_loss: 0.37600671, time: [18.34], best model: 0\n",
      "Epoch: 11, train_loss: 0.38109933, valid_loss: 0.37623168, time: [18.31], best model: 0\n",
      "Epoch: 12, train_loss: 0.37546006, valid_loss: 0.3878733, time: [18.31], best model: 0\n",
      "Early Stopped at Epoch: 13\n",
      "On sample 59 / 60 (hyperparams = {'cell_size': 187, 'hidden_size': 145, 'learning_rate': 0.046457426476375775, 'num_epochs': 119, 'patience': 9, 'batch_size': 512, 'early_stop_frac': 0.09967275023141152, 'seed': 4770})\n",
      "Model Structure:  GRUD(\n",
      "  (zl): Linear(in_features=353, out_features=145, bias=True)\n",
      "  (rl): Linear(in_features=353, out_features=145, bias=True)\n",
      "  (hl): Linear(in_features=353, out_features=145, bias=True)\n",
      "  (gamma_x_l): FilterLinear(in_features=104, out_features=104, bias=True)\n",
      "  (gamma_h_l): Linear(in_features=104, out_features=145, bias=True)\n",
      "  (fc): Linear(in_features=145, out_features=2, bias=True)\n",
      "  (bn): BatchNorm1d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (drop): Dropout(p=0.5, inplace=False)\n",
      ")\n",
      "Start Training ... \n",
      "Output type dermined by the model\n",
      "Epoch: 0, train_loss: 0.52296398, valid_loss: 0.50452857, time: [4.68], best model: 1\n",
      "Epoch: 1, train_loss: 0.38595354, valid_loss: 0.38237371, time: [4.83], best model: 1\n",
      "Epoch: 2, train_loss: 0.36736176, valid_loss: 0.39097191, time: [4.6], best model: 0\n",
      "Epoch: 3, train_loss: 0.36844776, valid_loss: 0.38963837, time: [4.78], best model: 0\n",
      "Epoch: 4, train_loss: 0.37038908, valid_loss: 0.38390225, time: [4.83], best model: 0\n",
      "Epoch: 5, train_loss: 0.3678631, valid_loss: 0.39351394, time: [4.66], best model: 0\n",
      "Epoch: 6, train_loss: 0.36682547, valid_loss: 0.39191618, time: [4.79], best model: 0\n",
      "Epoch: 7, train_loss: 0.36433953, valid_loss: 0.38893897, time: [4.89], best model: 0\n",
      "Epoch: 8, train_loss: 0.36099809, valid_loss: 0.39312593, time: [4.86], best model: 0\n",
      "Epoch: 9, train_loss: 0.36130076, valid_loss: 0.39441645, time: [4.83], best model: 0\n",
      "Early Stopped at Epoch: 10\n",
      "On sample 60 / 60 (hyperparams = {'cell_size': 120, 'hidden_size': 170, 'learning_rate': 0.05276174866719614, 'num_epochs': 73, 'patience': 9, 'batch_size': 64, 'early_stop_frac': 0.05696605904124455, 'seed': 3234})\n",
      "Model Structure:  GRUD(\n",
      "  (zl): Linear(in_features=378, out_features=170, bias=True)\n",
      "  (rl): Linear(in_features=378, out_features=170, bias=True)\n",
      "  (hl): Linear(in_features=378, out_features=170, bias=True)\n",
      "  (gamma_x_l): FilterLinear(in_features=104, out_features=104, bias=True)\n",
      "  (gamma_h_l): Linear(in_features=104, out_features=170, bias=True)\n",
      "  (fc): Linear(in_features=170, out_features=2, bias=True)\n",
      "  (bn): BatchNorm1d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (drop): Dropout(p=0.5, inplace=False)\n",
      ")\n",
      "Start Training ... \n",
      "Output type dermined by the model\n",
      "Epoch: 0, train_loss: 0.40670674, valid_loss: 0.41249562, time: [18.54], best model: 1\n",
      "Epoch: 1, train_loss: 0.39376899, valid_loss: 0.39886958, time: [18.73], best model: 1\n",
      "Epoch: 2, train_loss: 0.39113366, valid_loss: 0.39697824, time: [18.52], best model: 1\n",
      "Epoch: 3, train_loss: 0.38544176, valid_loss: 0.40295522, time: [18.5], best model: 0\n",
      "Epoch: 4, train_loss: 0.39330155, valid_loss: 0.39736399, time: [18.38], best model: 0\n",
      "Epoch: 5, train_loss: 0.37817516, valid_loss: 0.40465657, time: [18.55], best model: 0\n",
      "Epoch: 6, train_loss: 0.38967623, valid_loss: 0.38827574, time: [18.5], best model: 1\n",
      "Epoch: 7, train_loss: 0.38093685, valid_loss: 0.39080817, time: [18.26], best model: 0\n",
      "Epoch: 8, train_loss: 0.37993827, valid_loss: 0.39830969, time: [18.14], best model: 0\n",
      "Epoch: 9, train_loss: 0.38739491, valid_loss: 0.39976384, time: [18.89], best model: 0\n",
      "Epoch: 10, train_loss: 0.38478575, valid_loss: 0.4036151, time: [18.45], best model: 0\n",
      "Epoch: 11, train_loss: 0.38290104, valid_loss: 0.40344983, time: [18.54], best model: 0\n",
      "Epoch: 12, train_loss: 0.38671196, valid_loss: 0.40416758, time: [18.29], best model: 0\n",
      "Epoch: 13, train_loss: 0.38156053, valid_loss: 0.40352392, time: [18.78], best model: 0\n",
      "Epoch: 14, train_loss: 0.3869713, valid_loss: 0.40128699, time: [18.39], best model: 0\n",
      "Early Stopped at Epoch: 15\n",
      "Model Structure:  GRUD(\n",
      "  (zl): Linear(in_features=300, out_features=92, bias=True)\n",
      "  (rl): Linear(in_features=300, out_features=92, bias=True)\n",
      "  (hl): Linear(in_features=300, out_features=92, bias=True)\n",
      "  (gamma_x_l): FilterLinear(in_features=104, out_features=104, bias=True)\n",
      "  (gamma_h_l): Linear(in_features=104, out_features=92, bias=True)\n",
      "  (fc): Linear(in_features=92, out_features=2, bias=True)\n",
      "  (bn): BatchNorm1d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (drop): Dropout(p=0.5, inplace=False)\n",
      ")\n",
      "Start Training ... \n",
      "Output type dermined by the model\n",
      "Epoch: 0, train_loss: 0.40184754, valid_loss: 0.41305192, time: [19.51], best model: 1\n",
      "Epoch: 1, train_loss: 0.38260203, valid_loss: 0.39920923, time: [19.62], best model: 1\n",
      "Epoch: 2, train_loss: 0.38647669, valid_loss: 0.39688097, time: [19.93], best model: 1\n",
      "Epoch: 3, train_loss: 0.39045729, valid_loss: 0.40212538, time: [19.91], best model: 0\n",
      "Epoch: 4, train_loss: 0.37599554, valid_loss: 0.39952209, time: [19.93], best model: 0\n",
      "Epoch: 5, train_loss: 0.37544552, valid_loss: 0.40541654, time: [19.27], best model: 0\n",
      "Epoch: 6, train_loss: 0.3801585, valid_loss: 0.40883248, time: [19.97], best model: 0\n",
      "Epoch: 7, train_loss: 0.38653357, valid_loss: 0.40046786, time: [20.11], best model: 0\n",
      "Epoch: 8, train_loss: 0.37502558, valid_loss: 0.40294976, time: [20.17], best model: 0\n",
      "Epoch: 9, train_loss: 0.3806674, valid_loss: 0.40800258, time: [19.96], best model: 0\n",
      "Early Stopped at Epoch: 10\n",
      "Final results for model GRU-D on target los_7 with representation data\n",
      "0.716077905485668 0.20115511334161348 0.9294763513513513 0.08241758241758242\n"
     ]
    }
   ],
   "source": [
    "%autoreload\n",
    "from mmd_grud_utils import *\n",
    "\n",
    "model_name       = 'GRU-D'\n",
    "hyperparams_list = GRU_D_hyperparams_list\n",
    "RERUN            = False\n",
    "results = {}\n",
    "\n",
    "if model_name not in results: \n",
    "    results[model_name] = {}\n",
    "\n",
    "for t in ['los_3', 'los_7']:\n",
    "    if t not in results[model_name]: \n",
    "        results[model_name][t] = {}\n",
    "    n, X_train, X_dev, X_test = ('data', data_train, data_dev, data_test)\n",
    "    \n",
    "    print(\"Running model %s on target %s with representation %s\" % (model_name, t, n))\n",
    "    tensor = to_3D_tensor(\n",
    "            X_train.loc[:, pd.IndexSlice[:, 'mean']] * \n",
    "            np.where((X_train.loc[:, pd.IndexSlice[:, 'mask']] == 1).values, 1, np.NaN)\n",
    "        )\n",
    "    X_mean = np.nanmean(tensor, axis=0, keepdims=True).transpose([0, 2, 1])\n",
    "    X_mean[X_mean != X_mean] = 0  # THIS IS EXTREME BODGE. We should not set NaN values to 0, as that wrongly influences training\n",
    "    base_params = {'X_mean': X_mean, 'output_last': True, 'input_size': X_mean.shape[2]}\n",
    "\n",
    "    if n in results[model_name][t]:\n",
    "        if not RERUN: \n",
    "            print(\"Final results for model %s on target %s with representation %s\" % (model_name, t, n))\n",
    "            print(results[model_name][t][n])\n",
    "            continue\n",
    "        best_s, best_hyperparams = results[model_name][t][n][-1], results[model_name][t][n][1]\n",
    "        print(\"Loading best hyperparams\", best_hyperparams)\n",
    "    \n",
    "    else:\n",
    "        best_s, best_hyperparams = -np.Inf, None\n",
    "        for i, hyperparams in enumerate(hyperparams_list):\n",
    "            print(\"On sample %d / %d (hyperparams = %s)\" % (i+1, len(hyperparams_list), repr((hyperparams))))\n",
    "\n",
    "            early_stop_frac,batch_size,seed = [hyperparams[k] for k in ('early_stop_frac','batch_size','seed')]\n",
    "\n",
    "            batch_size = int(batch_size)\n",
    "\n",
    "            np.random.seed(seed)\n",
    "            all_train_subjects = list(\n",
    "                np.random.permutation(Ys_train.index.get_level_values('subject_id').values)\n",
    "            )\n",
    "            N_early_stop        = int(len(all_train_subjects) * early_stop_frac)\n",
    "            train_subjects      = all_train_subjects[:-N_early_stop]\n",
    "            early_stop_subjects = all_train_subjects[-N_early_stop:]\n",
    "            X_train_obs         = X_train[X_train.index.get_level_values('subject_id').isin(train_subjects)]\n",
    "            Ys_train_obs        = Ys_train[Ys_train.index.get_level_values('subject_id').isin(train_subjects)]\n",
    "\n",
    "            X_train_early_stop  = X_train[X_train.index.get_level_values('subject_id').isin(early_stop_subjects)]\n",
    "            Ys_train_early_stop = Ys_train[\n",
    "                Ys_train.index.get_level_values('subject_id').isin(early_stop_subjects)\n",
    "            ]\n",
    "\n",
    "            train_dataloader      = prepare_dataloader(X_train_obs, Ys_train_obs[t], batch_size=batch_size)\n",
    "            early_stop_dataloader = prepare_dataloader(\n",
    "                X_train_early_stop, Ys_train_early_stop[t], batch_size=batch_size\n",
    "            )\n",
    "            dev_dataloader        = prepare_dataloader(X_dev, Ys_dev[t], batch_size=batch_size)\n",
    "            test_dataloader       = prepare_dataloader(X_test, Ys_test[t], batch_size=batch_size)\n",
    "\n",
    "            model_hyperparams = copy.copy(base_params)\n",
    "            model_hyperparams.update(\n",
    "                {k: v for k, v in hyperparams.items() if k in ('cell_size', 'hidden_size', 'batch_size')}\n",
    "            )\n",
    "            model = GRUD(**model_hyperparams)\n",
    "\n",
    "            best_model, _ = Train_Model(\n",
    "                model, train_dataloader, early_stop_dataloader,\n",
    "                **{k: v for k, v in hyperparams.items() if k in (\n",
    "                    'num_epochs', 'patience', 'learning_rate', 'batch_size'\n",
    "                )}\n",
    "            )\n",
    "\n",
    "            probabilities_dev, labels_dev = predict_proba(best_model, dev_dataloader)\n",
    "            probabilities_dev = np.concatenate(probabilities_dev)[:, 1]\n",
    "            labels_dev        = np.concatenate(labels_dev)\n",
    "            s = roc_auc_score(labels_dev, probabilities_dev)\n",
    "            if s > best_s:\n",
    "                best_s, best_hyperparams = s, hyperparams\n",
    "                print(\"New Best Score: %.2f @ hyperparams = %s\" % (100*best_s, repr((best_hyperparams))))\n",
    "                \n",
    "    ## Test set\n",
    "    np.random.seed(seed)\n",
    "    early_stop_frac,batch_size,seed = [best_hyperparams[k] for k in ('early_stop_frac','batch_size','seed')]\n",
    "    \n",
    "    batch_size = int(batch_size)\n",
    "\n",
    "    X_train_concat, Ys_train_concat = pd.concat((X_train, X_dev)), pd.concat((Ys_train, Ys_dev))\n",
    "\n",
    "    all_train_subjects = list(np.random.permutation(Ys_train_concat.index.get_level_values('subject_id').values))\n",
    "    N_early_stop = int(len(all_train_subjects) * early_stop_frac)\n",
    "    train_subjects, early_stop_subjects = all_train_subjects[:-N_early_stop], all_train_subjects[-N_early_stop:]\n",
    "    X_train_obs         = X_train_concat[X_train_concat.index.get_level_values('subject_id').isin(train_subjects)]\n",
    "    Ys_train_obs        = Ys_train_concat[Ys_train_concat.index.get_level_values('subject_id').isin(train_subjects)]\n",
    "\n",
    "    X_train_early_stop  = X_train_concat[X_train_concat.index.get_level_values('subject_id').isin(early_stop_subjects)]\n",
    "    Ys_train_early_stop = Ys_train_concat[Ys_train_concat.index.get_level_values('subject_id').isin(early_stop_subjects)]\n",
    "\n",
    "    train_dataloader      = prepare_dataloader(X_train_obs, Ys_train_obs[t], batch_size=batch_size)\n",
    "    early_stop_dataloader = prepare_dataloader(X_train_early_stop, Ys_train_early_stop[t], batch_size=batch_size)\n",
    "    test_dataloader       = prepare_dataloader(X_test, Ys_test[t], batch_size=batch_size)\n",
    "\n",
    "    model_hyperparams = copy.copy(base_params)\n",
    "    model_hyperparams.update(\n",
    "        {k: v for k, v in best_hyperparams.items() if k in ('cell_size', 'hidden_size', 'batch_size')}\n",
    "    )\n",
    "    model = GRUD(**model_hyperparams)\n",
    "\n",
    "    best_model, (losses_train, losses_early_stop, losses_epochs_train, losses_epochs_early_stop) = Train_Model(\n",
    "        model, train_dataloader, early_stop_dataloader,\n",
    "        **{k: v for k, v in best_hyperparams.items() if k in (\n",
    "            'num_epochs', 'patience', 'learning_rate', 'batch_size'\n",
    "        )}\n",
    "    )\n",
    "\n",
    "    probabilities_test, labels_test = predict_proba(best_model, test_dataloader)\n",
    "\n",
    "    y_score = np.concatenate(probabilities_test)[:, 1]\n",
    "    y_pred  = np.concatenate(probabilities_test).argmax(axis=1)\n",
    "    y_true  = np.concatenate(labels_test)\n",
    "\n",
    "    auc   = roc_auc_score(y_true, y_score)\n",
    "    auprc = average_precision_score(y_true, y_score)\n",
    "    acc   = accuracy_score(y_true, y_pred)\n",
    "    F1    = f1_score(y_true, y_pred)\n",
    "    print(\"Final results for model %s on target %s with representation %s\" % (model_name, t, n))\n",
    "    print(auc, auprc, acc, F1)\n",
    "\n",
    "    results[model_name][t][n] = None, best_hyperparams, auc, auprc, acc, F1, best_s\n",
    "    # with open('/scratch/mmd/extraction_baselines_gru-d.pkl', mode='wb') as f: pickle.dump(results, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
